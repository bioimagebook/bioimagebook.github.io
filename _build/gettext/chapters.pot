# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2022-2023
# This file is distributed under the same license as the Python package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Python \n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-12-08 07:26-0500\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:1
msgid "Acknowledgements"
msgstr ""

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:4
msgid "Much of this book started out in Heidelberg, when I worked in the [Nikon Imaging Center](https://www.uni-heidelberg.de/nic/) at Heidelberg University. Thanks must go to Ulrike, Nico, Christian, Astrid & Carlo for all their help, support, insights and ideas -- both during my three years working alongside them, and in the years since."
msgstr ""

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:7
msgid "Thanks must also go to Wayne Rasband, for changing the face of bioimage analysis by creating ImageJ in the first place, and to the Fiji and ImageJ2 teams for their fantastic efforts in continuing to support and extend the software. I've no idea what I'd be doing in my career, were it not for their magnificent work."
msgstr ""

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:10
msgid "Most figures included here were created from my original drawings, or from sample images obtained directly from Fiji under {menuselection}`File --> Open Samples` (also available at <https://imagej.nih.gov/ij/images/>), apart from:"
msgstr ""

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:12
msgid "The sunny cell (shown below), thanks to Astrid Marx"
msgstr ""

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:13
msgid "The fluorescent beads (in {ref}`chap_formation_spatial`), thanks to Ulrike Engel"
msgstr ""

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:14
msgid "The *CMU-1-Small-Region.svs* image (in {ref}`chap_colors`), from https://openslide.org (CC0)"
msgstr ""

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:16
msgid "Finally, a huge personal thanks goes to Yvonne for her support and patience with someone who spends far too much time at a computer -- including the many holidays spent working on this."
msgstr ""

#: ../../chapters/0-preamble/acknowledgements/acknowledgements.md:22
msgid "Astrid's sunny cell."
msgstr ""

#: ../../chapters/0-preamble/disclaimer.md:1
msgid "Disclaimer"
msgstr ""

#: ../../chapters/0-preamble/disclaimer.md:3
msgid "Bioimage analysis is often misunderstood. Including by me."
msgstr ""

#: ../../chapters/0-preamble/disclaimer.md:6
msgid "This book attempts to demystify the parts of it that I (think I) understand. But although I've tried to ensure that everything here is accurate at the time of writing, please keep in mind the possibility of errors and treat the content with suitable caution."
msgstr ""

#: ../../chapters/0-preamble/disclaimer.md:9
msgid "Or to put it in the kind of words seen in open licenses: *this text is made available as-is and without warranties of any kind*."
msgstr ""

#: ../../chapters/0-preamble/disclaimer.md:11
msgid "If you do find a mistake, please let me know on [image.sc](https://forum.image.sc/tags/bioimage-book) so that I can fix it."
msgstr ""

#: ../../chapters/0-preamble/license.md:1
msgid "License & Reuse"
msgstr ""

#: ../../chapters/0-preamble/license.md:3
msgid "<a rel=\"license\" href=\"https://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />All original content by the author is licensed under a <a rel=\"license\" href=\"https://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
msgstr ""

#: ../../chapters/0-preamble/license.md:3
msgid "Creative Commons Licence"
msgstr ""

#: ../../chapters/0-preamble/license.md:5
msgid "This includes all text and drawings, unless otherwise noted."
msgstr ""

#: ../../chapters/0-preamble/license.md:7
msgid "My aim is to make the content easy to reuse. Content from others is used sparingly to keep things simple."
msgstr ""

#: ../../chapters/0-preamble/license.md:10
msgid "The main exception is that I'm not a microscopist, so the original microscopy images are always from others. Please check the [acknowledgements](acknowledgements/acknowledgements) for more specific information."
msgstr ""

#: ../../chapters/0-preamble/license.md:13
msgid "If you want to recreate similar figures using your *own* microscopy images, you can use [the code in the book](sec-live-notebooks) to do that."
msgstr ""

#: ../../chapters/0-preamble/license.md:15
msgid "And if you find any attribution is missing or incorrect, please [create a PR or open an issue on GitHub](https://github.com/bioimagebook/bioimagebook.github.io) so it can be fixed."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:1
msgid "Preface"
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:4
msgid "**I find bioimage analysis hard.**"
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:12
msgid "After working in the field for over 15 years, developing algorithms, software and workshops, I feel like I *should* have amassed some level of expertise -- but I still find pretty much every new project I attempt to be difficult. It remains common to find me wandering around the house, mumbling and grumbling to myself, while grappling with some tricky analysis problem whose solution eludes me."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:15
msgid "If you want to read a book by someone who is pretty confident in their ability to quantitatively analyse whatever images come their way, this isn't the one for you."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:17
msgid "I'm self-reflective enough to recognize that I might just not be very good at what I (try to) do. Perhaps I'm ill-suited to a career that I tumbled into almost entirely by accident. However, I take some comfort in the fact that, as I get to know more and more image analysts, it seems that most (if not all?) of us find many aspects of our work pretty difficult."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:21
msgid "This isn't to say that *no one* finds analysing biological and biomedical images easy. I've encountered plenty of people who believe it's really quite simple: you can see the stuff in the image, now just detect it and quantify it. With ImageJ. Or AI. Or something. Set a threshold? Do whatever they did in that paper. Just have the summary plots for the group meeting next week, ok?"
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:30
msgid "The trouble is that, in my experience at least, this attitude tends to be found exclusively among people who are either too early or too late in their careers to actually have to sit in front of a computer and wrestle meaningful information from a billion uncooperative pixels. Those of us who *do* need to sit at the computer know that it's not that straightforward."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:33
msgid "But I don't want to get too gloomy. Image analysis is hard, but there are good reasons not to give up."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:36
msgid "I would argue that the problem is *not* that the concepts are difficult. In fact, the most important ones are remarkably straightforward -- once you know about them. A lot of the maths is basic arithmetic."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:40
msgid "Rather, I'd say that image analysis is hard for two main reasons:"
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:42
msgid "**Images in biology are *enormously* varied.** Almost nothing 'just works'. I might find a paper describing a marvellous method to detect, classify and track cells -- but there is no guarantee the method will work to detect, classify and track *my* cells. Maybe I have a different type of cell. Imaged on a different kind of microscope. At a different spatial and temporal resolution. To answer a different question. In short, I have a very different computational challenge from the one described in the paper -- even if the shared theme of 'tracking cells' initially made it sound similar."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:51
msgid "**Bioimage analysis involves a lot of disciplines**. Analysing images in a scientifically justifiable way typically requires (at least a bit of) knowledge across a lot of domains. Of course it's necessary to know about the scientific question, e.g. the biology. But to really understand the data, you also need to know about the experimental setup, the imaging hardware, fundamental limits like noise and diffraction, and also how digital images are represented, stored and (sometimes) compressed. Then there are a plethora of image processing techniques that might help answer your scientific questions. You need to know not only what these are, but also how to assemble them together into a sequence of steps that work reliably and with minimal bias -- either using existing software or by writing new computer code. And finally statistics to bring it all together. It's a lot."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:59
msgid "But amidst all this variety lurk some of the positive things about image analysis: it's **creative**, it's **challenging** (most of the time in a good way), and -- because it's rare for any individual to be an expert in all the related domains -- it's usually **collaborative** (or at least it should be)."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:61
msgid "The fact that bioimage analysis is so cross-disciplinary means that pretty much everyone can have valuable insights to contribute."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:63
msgid "This underpins my motivation in writing this book: I want to explain the concepts I use every day as an image analyst to people who spend their days differently. No matter who you are, you know a huge amount of stuff I don't know. My hope is that if we put the stuff we know together, we'll do better research, faster."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:67
msgid "The one instruction is: **be prepared to think hard.**"
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:69
msgid "When I'm confronted by an image analysis problem, my goal is never really to find the *right* way to do the analysis. That generally doesn't exist."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:72
msgid "Instead, my goal is to find the *least wrong* way to do the analysis -- and to be able to understand and explain whatever lingering limitations and biases can't be entirely overcome. It can be frustrating, I still don't feel terribly good at it, but it is -- in its own strange way -- kind of *enjoyable*. There's always something new to learn, and some new angle from which to look at the problem. And each new angle can help us wring more drops of knowledge out of our data."
msgstr ""

#: ../../chapters/0-preamble/preface/preface.md:77
msgid "My hope is that this book will help introduce others find the weird, frustrating pleasure of thinking more deeply about scientific images. Through this, I hope it might make a small contribution towards helping us do image analysis a bit better."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:16
msgid "How to read this book"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:18
msgid "Practical data"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:21
msgid "**Download the images used in the practical exercises [here](https://github.com/bioimagebook/practical-data/archive/refs/heads/main.zip).**"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:25
msgid "Each chapter in this book starts with a main section that describes one or more key concepts in bioimage analysis. This is intended for all readers. Working through these sections should be enough to become familiar with the main ideas of the book."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:29
msgid "However, actually *doing* bioimage analysis requires software. And the same concepts can surface in different software in different ways."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:32
msgid "For that reason, all the chapters in Part 1 each contain two extra subsections:"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:33
msgid "**ImageJ:** This describes how the concepts relate to the popular bioimage analysis software, [ImageJ](https://imagej.nih.gov/ij/index.html), including the [Fiji distribution](https://fiji.sc)."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:34
msgid "**Python:** This shows the concepts through code in the Python language, using tools like [NumPy](https://numpy.org), [SciPy](https://scipy.org) and [scikit-image](https://scikit-image.org)."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:36
msgid "ImageJ sections continue to feature in Part 2, but Python is dropped because *the whole book is written using Python code anyway*. So once you have the main ideas, any time you want to see some Python code you can just press the {guilabel}`Click to show` buttons found next to almost every figure."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:39
msgid "This means that you can read the book in different ways:"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:40
msgid "As an **ImageJ primer**, skipping all the bits that involve looking at Python code"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:41
msgid "As a **Python-for-image-analysis manual**, skipping all the ImageJ-specific sections"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:42
msgid "As a **conceptual overview**, just reading the main chapters and skipping anything specific involving ImageJ and Python"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:43
msgid "As a **full introduction to image analysis, ImageJ and Python**, skipping nothing"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:46
msgid "My advice is to read the book focussing on the concepts and ImageJ first, to get a fairly quick overview of everything -- without worrying too much about Python."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:48
msgid "You can always return to work through the Python sections later. However, be warned that the Python code is intended for people who already reasonably comfortable with programming, so if the language is entirely new to you then you might want to work through an introductory Python course first."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:53
msgid "Interactivity"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:55
msgid "It is *strongly* recommended to not only read the text, but also to put what you read into practice by exploring and experimenting."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:57
msgid "This handbook is designed to be interactive in two main ways:"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:59
msgid "[How to read this book](how-to-read-this-book)"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:60
msgid "[Interactivity](interactivity)"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:61
msgid "[Questions \\& practicals](questions-and-practicals)"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:62
msgid "[Live Jupyter notebooks ](sec-live-notebooks)"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:65
msgid "Questions & practicals"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:67
msgid "Various questions and practical exercises are scattered throughout the text. To make the most of these, please follow the instructions below."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:0
#: ../../chapters/1-concepts/2-measurements/measurements.md:0
#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:0
#: ../../chapters/1-concepts/3-bit_depths/imagej.md:0
#: ../../chapters/1-concepts/4-colors/imagej.md:0
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:0
#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:0
#: ../../chapters/1-concepts/6-files/files.md:0
#: ../../chapters/2-processing/2-point_operations/point_operations.md:0
#: ../../chapters/2-processing/3-thresholding/imagej.md:0
#: ../../chapters/2-processing/3-thresholding/thresholding.md:0
#: ../../chapters/2-processing/4-filters/filters.md:0
#: ../../chapters/2-processing/4-filters/imagej.md:0
#: ../../chapters/2-processing/5-morph/imagej.md:0
#: ../../chapters/2-processing/5-morph/morph.md:0
#: ../../chapters/2-processing/6-transforms/imagej.md:0
#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:0
#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:0
#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:0
#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:0
#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:0
msgid "Question"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:73
msgid "When you see a question, try to come up with your own answer first."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:75
msgid "Then, if you want to compare your answer with mine, click on the *Answer* tab."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:0
#: ../../chapters/1-concepts/2-measurements/measurements.md:0
#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:0
#: ../../chapters/1-concepts/3-bit_depths/imagej.md:0
#: ../../chapters/1-concepts/4-colors/imagej.md:0
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:0
#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:0
#: ../../chapters/1-concepts/6-files/files.md:0
#: ../../chapters/2-processing/2-point_operations/imagej.md:0
#: ../../chapters/2-processing/2-point_operations/point_operations.md:0
#: ../../chapters/2-processing/3-thresholding/imagej.md:0
#: ../../chapters/2-processing/3-thresholding/thresholding.md:0
#: ../../chapters/2-processing/4-filters/filters.md:0
#: ../../chapters/2-processing/4-filters/imagej.md:0
#: ../../chapters/2-processing/5-morph/imagej.md:0
#: ../../chapters/2-processing/5-morph/morph.md:0
#: ../../chapters/2-processing/6-transforms/imagej.md:0
#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:0
#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:0
#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:0
#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:0
#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:0
msgid "Answer"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:79
msgid "Good! This is my answer."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:84
msgid "Live Jupyter notebooks <a name=\"jupyter-notebooks\" />"
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:91
msgid "This text exists as [Jupyter notebooks](https://jupyter.org) -- which can be made interactive with the help of [Binder](https://mybinder.org)."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:93
msgid "You can activate a 'Live' version by clicking on the rocket icon on the top right, and choosing {guilabel}`Binder` or {guilabel}`Live code`."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:95
msgid "It will take a bit of time to start up Binder, but once it's ready you should see that the page is divided into different sections, called 'cells'."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:97
msgid "Some of these cells contain explanations (like this one), and some contain code. You can run each cell by clicking inside it and either a) clicking the *Run* button in the live toolbar, or b) pressing {kbd}`Shift+Enter`."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:100
msgid "This is how the Python sections should be used. With live Jupyter notebooks, you can run all the code yourself interactively. This includes making changes to the code within cells, and exploring how these changes impact the output."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:104
msgid "But this isn't restricted *only* to the Python sections, because the figures in the main text are generated using Python code as well. This means you can use the {guilabel}`Click to show` buttons, like the one below, to see exactly how the figure was made -- and even modify the figures in a live notebook."
msgstr ""

#: ../../chapters/0-preamble/reading/reading.md:156
msgid "An example figure."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:16
msgid "ImageJ: Images & pixels"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:20
#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:51
#: ../../chapters/1-concepts/2-measurements/imagej.md:34
#: ../../chapters/1-concepts/2-measurements/measurements.md:42
#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:46
#: ../../chapters/1-concepts/3-bit_depths/imagej.md:36
#: ../../chapters/1-concepts/4-colors/colors.md:43
#: ../../chapters/1-concepts/4-colors/imagej.md:34
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:32
#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:42
#: ../../chapters/1-concepts/6-files/files.md:45
#: ../../chapters/1-concepts/6-files/imagej.md:19
#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:41
#: ../../chapters/2-processing/2-point_operations/imagej.md:19
#: ../../chapters/2-processing/2-point_operations/point_operations.md:42
#: ../../chapters/2-processing/3-thresholding/imagej.md:33
#: ../../chapters/2-processing/3-thresholding/thresholding.md:44
#: ../../chapters/2-processing/4-filters/filters.md:43
#: ../../chapters/2-processing/4-filters/imagej.md:36
#: ../../chapters/2-processing/5-morph/imagej.md:33
#: ../../chapters/2-processing/5-morph/morph.md:43
#: ../../chapters/2-processing/6-transforms/imagej.md:33
#: ../../chapters/2-processing/6-transforms/transforms.md:42
#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:42
#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:41
#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:41
#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:45
#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:43
#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:41
#: ../../chapters/appendices/macros/macro_dog.md:34
#: ../../chapters/appendices/macros/macro_intro.md:42
#: ../../chapters/appendices/macros/macro_simulating.md:34
msgid "Introduction"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:22
msgid "This is the first section that takes the ideas described in the main chapter and shows how they relate to software: in this case **ImageJ**."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:24
msgid "We begin with a brief introduction to what ImageJ is, how to get it, and how to navigate the interface to open and display images."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:28
msgid "What is ImageJ?"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:30
msgid "**ImageJ** is open-source software for image analysis."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:32
msgid "Created by **Wayne Rasband** at the National Institutes of Health, ImageJ has become indispensable to the research community over more than 20 years. It continues to be updated regularly and is by far the most discussed topic on the [Scientific Community Image Forum](https://forum.image.sc) -- with [more than 10,000 topics](https://forum.image.sc/tags) at the time of writing, and more added every day."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:35
msgid "ImageJ's success is due not only to the features of the software itself, but to its openness and extensibility. The source code is in the public domain, meaning that others can adapt it as needed. But usually this isn't necessary, because users can write (and share) custom macros, plugins or scripts to add new functionality -- without changing ImageJ itself."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:39
msgid "I personally have found ImageJ phenomenally useful throughout my career, to the extent that I am convinced that *anyone* working with biomedical images benefits if they know how to use it. Even if you ultimately use other software for your analysis, or even write your own, the ability to quickly check things in ImageJ is extremely helpful."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:42
msgid "These sections are intended to help any interested reader develop a strong working knowledge of ImageJ itself, while simultaneously gaining a deeper understanding of image analysis in general."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:46
msgid "Getting ImageJ"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:48
msgid "ImageJ is available in multiple forms. Three of the most important ones for our purposes are:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:51
msgid "1. ImageJ"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:55
msgid "**Download from https://imagej.nih.gov/ij/**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:57
msgid "The 'original' download of ImageJ contains all the core functionality, but no extra user plugins."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:59
msgid "The core of the application is a tiny file *ij.jar* (~2.5 MB) that runs on Java. You can download a platform-specific package that includes both ImageJ and Java for Windows, Mac or Linux. Including Java makes the download bigger, but makes the application self-contained and easy to run."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:63
msgid "2. Fiji"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:67
msgid "**Download from https://fiji.sc/**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:69
msgid "**Fiji**, which stands for _**F**iji **I**s **J**ust **I**mageJ_, is a distribution of ImageJ that comes bundled with a plethora of plugins and extra features that are especially useful for life scientists. It also has a powerful script editor that helps a lot when developing macros or scripts, an updater to help manage all the additions, and even a ['Big Data Viewer'](https://imagej.net/plugins/bdv/) for particularly huge images."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:72
msgid "3. ImageJ.JS"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:76
msgid "**Run at https://ij.imjoy.io**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:78
msgid "ImageJ.JS is a web version of the original ImageJ, capable of running in a browser. It has a few extra features, but not as many as Fiji. It was put together and is maintained by the [ImJoy team](https://github.com/imjoy-team) led by Wei Ouyang."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:82
msgid "For more information, see https://imagej.net/software/imagej-js"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:84
msgid "More interactivity with ImageJ.JS!"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:88
msgid "Whenever you see a button like this [![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/launch-imagej-js-badge.svg)](https://ij.imjoy.io?open=https://github.com/bioimagebook/practical-data/blob/main/images/happy_cell.tif) it can be used to launch ImageJ.JS directly from this book, often with a relevant image opened."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:88
#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:263
#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:316
#: ../../chapters/1-concepts/2-measurements/imagej.md:59
#: ../../chapters/1-concepts/2-measurements/imagej.md:89
#: ../../chapters/1-concepts/2-measurements/imagej.md:365
#: ../../chapters/1-concepts/2-measurements/imagej.md:455
#: ../../chapters/1-concepts/2-measurements/imagej.md:487
#: ../../chapters/1-concepts/3-bit_depths/imagej.md:247
#: ../../chapters/1-concepts/4-colors/imagej.md:108
#: ../../chapters/1-concepts/4-colors/imagej.md:297
#: ../../chapters/1-concepts/4-colors/imagej.md:315
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:239
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:304
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:391
#: ../../chapters/2-processing/2-point_operations/imagej.md:98
#: ../../chapters/2-processing/2-point_operations/imagej.md:155
#: ../../chapters/2-processing/2-point_operations/imagej.md:200
#: ../../chapters/2-processing/2-point_operations/imagej.md:247
#: ../../chapters/2-processing/3-thresholding/imagej.md:204
#: ../../chapters/2-processing/3-thresholding/imagej.md:250
#: ../../chapters/2-processing/3-thresholding/imagej.md:284
#: ../../chapters/2-processing/3-thresholding/imagej.md:357
#: ../../chapters/2-processing/3-thresholding/imagej.md:392
#: ../../chapters/2-processing/4-filters/imagej.md:141
#: ../../chapters/2-processing/4-filters/imagej.md:187
#: ../../chapters/2-processing/4-filters/imagej.md:246
#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:223
#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:851
msgid "launch ImageJ.JS"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:92
msgid "By default, ImageJ.JS will open in the same browser tab. If you want it to open in a new tab, then there's probably an easy trick in your browser to do that (on a computer, my guess is that it'll be pressing {kbd}`Ctrl` or {kbd}`⌘` when clicking the link)."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:97
msgid "Which ImageJ do I choose?"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:99
msgid "I would say: *all of them*. I always install both ImageJ and Fiji on any computer I will use regularly. ImageJ.JS doesn't require any installation: just a modern web browser."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:103
msgid "Everything ImageJ can do can also be accomplished in Fiji (because Fiji contains the full ImageJ inside it), but the converse is not true (because Fiji contains many extra bits) Therefore Fiji is my first choice for more extensive analysis tasks. Its main disadvantage is that it's a lot bigger: taking longer to start up and run update checks, and containing a lot of commands that I don't always need."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:107
msgid "By contrast, the original ImageJ is very small and lightweight. On my computer, it starts almost instantly. It remains my first choice for quick, common tasks with images."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:111
msgid "*Most* ImageJ-related practicals in this course only use core features, and so can be done using any of ImageJ, Fiji or ImageJ.JS. Sometimes in this book I will refer to explicitly to Fiji, indicating that the relevant command is *only* available in Fiji."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:116
msgid "Remember to cite the software you use!"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:119
msgid "A lot of open-source software is developed and supported by academics, who invest a huge amount of time into development and support. They need funding to continue that work[^fn_1], and paper citations to help get that funding."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:122
msgid "If you use software for research you plan to publish, please spend a few minutes searching for how the developers of the software want it to be cited."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:124
msgid "For ImageJ & Fiji, see https://imagej.net/contribute/citing"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:125
msgid "For other software, search for *citing [software name]*"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:133
msgid "The ImageJ Interface"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:135
msgid "ImageJ's user interface is rather minimalistic. It's centered around a toolbar. Everything else (images, histograms, measurement tables, dialogs) appears within separate windows."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:144
#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:152
msgid "The main ImageJ user interface."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:155
msgid "But despite the simple appearance, ImageJ is powerful. The depth of the software is evident from its abundance of menus and submenus."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:158
msgid "Which leads to the **most important tip for using ImageJ**:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:161
msgid "Don't memorize the menus -- search!"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:165
msgid "ImageJ has a lot of options, buried in a lot of menus... and submenus... and sometimes sub-submenus."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:167
msgid "Fortunately, there's no reason to memorize where they all are to be found. Rather, just remember one shortcut key: {kbd}`L`"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:170
msgid "Pressing {kbd}`L` effectively brings up at **list** of all the commands from the menus, ready for each search."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:172
msgid "For ImageJ, you see the *Command Finder* window where you can begin to type the name of the command you want. You can then run it either by double-clicking on the entry, or by using the up or down arrow keys followed by {kbd}`Enter`."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:179
msgid "The *Command Finder* dialog"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:182
msgid "In Fiji, you might see the *Command Finder* or you can alternatively switch on a *search bar* by selecting it under {menuselection}`Edit --> Options --> Search Bar...`. The idea is the same. The search bar can also be activated using {kbd}`L` and used to find and run commands."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:192
msgid "{menuselection}`Edit --> Options --> Misc...` dialog"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:195
msgid "Losing control"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:199
msgid "In most software, shortcut keys often require pressing {kbd}`Ctrl` (on Windows, Linux) or {kbd}`⌘` (Mac). Therefore the shortcut to search for a command would be {kbd}`Ctrl+L` or {kbd}`⌘ + L`."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:202
msgid "This works in ImageJ, but isn't necessary. Under {menuselection}`Edit --> Options --> Misc...`, you can specify whether the {kbd}`Ctrl` or {kbd}`⌘` key is needed along with the letter for the shortcut."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:205
msgid "By default, this option is turned off -- so pressing {kbd}`L` alone is enough. You may find this might make it too easy to accidentally run commands, in which case you should select the option to turn it on."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:212
msgid "Opening images & viewing pixels"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:214
msgid "I am always taken aback when I see someone open an image in ImageJ through the menus, by choosing {menuselection}`File --> Open...`."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:216
msgid "Although this can work, it's unnecessarily slow and awkward. The more elegant way to open an image is to simply drag the image file onto ImageJ's toolbar."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:219
msgid "As the cursor is then moved over the image, the value for the pixel under the cursor is displayed in ImageJ's status bar. Images can be navigated as follows:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:222
msgid "**Zoom in**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:224
msgid "Select the <img src=\"../../../images/imagej/icons/zoom.png\" /> tool, then **left-click** on the image, or"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:225
msgid "Press the {kbd}`+` key"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:227
msgid "**Zoom out**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:229
msgid "Select the <img src=\"../../../images/imagej/icons/zoom.png\" /> tool, then **right-click** on the image, or"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:230
msgid "Press the {kbd}`-` key"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:232
msgid "**Pan**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:234
msgid "Select the <img src=\"../../../images/imagej/icons/hand.png\" /> tool, then click and drag on the image, or"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:235
msgid "Press the {kbd}`spacebar`, then click and drag on the image"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:237
msgid "When the image is larger than the visible region, a small (purple) overview appears in the top left to indicate which part can currently be seen."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:0
#: ../../chapters/1-concepts/2-measurements/imagej.md:0
#: ../../chapters/1-concepts/3-bit_depths/imagej.md:0
#: ../../chapters/1-concepts/4-colors/imagej.md:0
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:0
#: ../../chapters/1-concepts/6-files/imagej.md:0
#: ../../chapters/2-processing/2-point_operations/imagej.md:0
#: ../../chapters/2-processing/3-thresholding/imagej.md:0
#: ../../chapters/2-processing/4-filters/imagej.md:0
#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:0
#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:0
msgid "Practical"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:250
msgid "The status bar also shows the x and y coordinates for the pixel under the cursor. However, to interpret these you need to know the *origin*, i.e. the location of the pixel at x=0, y=0."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:253
msgid "Where is the origin of the image in ImageJ?"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:255
msgid "Top left corner"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:256
msgid "Top right corner"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:257
msgid "Bottom left corner"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:258
msgid "Bottom right corner"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:259
msgid "Image center"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:261
msgid "**Tip:** You should be able to answer this question by opening an image in ImageJ, and observing the coordinates in the toolbar as you move the cursor over the image."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:263
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/happy_cell.tif)"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:0
#: ../../chapters/1-concepts/2-measurements/imagej.md:0
#: ../../chapters/1-concepts/3-bit_depths/imagej.md:0
#: ../../chapters/1-concepts/4-colors/imagej.md:0
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:0
#: ../../chapters/1-concepts/6-files/imagej.md:0
#: ../../chapters/2-processing/2-point_operations/imagej.md:0
#: ../../chapters/2-processing/3-thresholding/imagej.md:0
#: ../../chapters/2-processing/4-filters/filters.md:0
#: ../../chapters/2-processing/4-filters/imagej.md:0
#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:0
#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:0
msgid "Solution"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:268
msgid "The origin of the image is at the top left, i.e. the top left pixel is identified with the coordinate x=0, y=0."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:275
msgid "Changing appearance"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:279
msgid "Adjusting Brightness & Contrast"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:286
msgid "*Brightness/Contrast* dialog"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:289
msgid "The main command to change the brightness of an image is {menuselection}`Image --> Adjust --> Brightness/Contrast...`. Since you're likely to use it a lot, it is worth learning the shortcut: {kbd}`Shift+C`."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:292
msgid "The Brightness/Contrast dialog has four sliders: {guilabel}`Minimum`, {guilabel}`Maximum`, {guilabel}`Brightness` & {guilabel}`Contrast`. They are linked together: changing either of the first two also results in a change to the last two, and vice versa."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:295
msgid "Supposing you have a grayscale LUT, with colors ranging from black to white, you should see that"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:296
msgid "All pixels with a value less than or equal to the {guilabel}`Minimum` will be shown as black"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:297
msgid "All pixels with a value greater than or equal to the {guilabel}`Maximum` will be shown as white"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:298
msgid "All other pixels with a value in between will be shown using a shade of gray"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:300
msgid "Use the minimum & maximum sliders"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:303
msgid "Despite the name of the command implying {guilabel}`Brightness` and {guilabel}`Contrast` are the star perfomers, I would argue that the {guilabel}`Minimum` and {guilabel}`Maximum` sliders are far more intuitive."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:305
msgid "I use {guilabel}`Minimum` and {guilabel}`Maximum` almost exclusively."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:312
msgid "Does adjusting any of the sliders in the brightness & contrast dialog change the pixel values or only the LUT?"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:314
msgid "What happens if you press {guilabel}`Apply`?"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:316
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/bioimagebook.github.io/blob/main/chapters/1-concepts/1-images_and_pixels/images/couple.png)"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:320
msgid "Adjusting the sliders changes the LUT -- and *not* the pixel values."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:322
msgid "That is, unless you press {guilabel}`Apply`. If you do press {guilabel}`Apply` then the pixel values are changed."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:325
msgid "Recent versions of ImageJ give a warning when pressing {guilabel}`Apply`, but previous versions did not... which made it an extremely dangerous button for new users of the software. In most cases, the rule is:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:328
msgid "**When adjusting the brightness & contrast in ImageJ, don't press {guilabel}`Apply`!**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:331
msgid "You shouldn't break this rule without a good reason!"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:338
msgid "Switching LUTs"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:340
msgid "You can change the colors of the LUT by selecting an alternative option from the {menuselection}`Image --> Lookup tables -->` submenu."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:342
msgid "Use the Control Panel to frequently access the same menu"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:345
msgid "If you want to explore LUTs quickly, use {menuselection}`Plugins --> Utilities --> Control Panel`. This opens a window that allows you to double-click on commands from any menu or submenu to apply that command quickly."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/imagej.md:128
msgid "Sometimes they also need a kind word or a compliment, because they are human. Supporting software can be time-consuming, hard and stressful -- and is usually something they do for free, in their limited spare time."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:16
msgid "Images & pixels"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:18
#: ../../chapters/1-concepts/2-measurements/measurements.md:19
#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:18
#: ../../chapters/1-concepts/4-colors/colors.md:18
#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:19
#: ../../chapters/1-concepts/6-files/files.md:19
#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:17
#: ../../chapters/2-processing/2-point_operations/point_operations.md:18
#: ../../chapters/2-processing/3-thresholding/thresholding.md:18
#: ../../chapters/2-processing/4-filters/filters.md:18
#: ../../chapters/2-processing/5-morph/morph.md:19
#: ../../chapters/2-processing/6-transforms/transforms.md:18
#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:18
#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:18
#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:18
#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:18
#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:18
#: ../../chapters/appendices/macros/macro_intro.md:18
msgid "Chapter outline"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:21
msgid "Digital images are composed of **pixels**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:22
msgid "Each pixel has a **numeric value** (often related to detected light)"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:23
msgid "The same pixel values can be displayed differently using **lookup tables (LUTs)**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:24
msgid "We can modify image appearance in two main ways:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:25
msgid "**Change the pixel values**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:26
msgid "**Change the LUT**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:27
msgid "**Preserving pixel values is crucial** for most analysis -- so it's essential to know what your software is doing"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:53
msgid "Image are composed of **pixels**."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:55
msgid "The word 'pixel' is derived from **pic**ture **el**ement and, as far as the computer is concerned, each pixel is just a number."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:57
msgid "When the image data is displayed, the values of pixels are usually converted into squares of particular colors – but *this is only for our benefit*. The colored squares are nothing more than a helpful visualization that enable us to gain a fast impression of the image contents, i.e. the approximate values of pixels and where they are in relation to one another."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:60
msgid "When it comes to processing and analysis, we need to get past the display and delve into the real data: the numbers ({numref}`fig-image_array`)."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:121
msgid "An image depicting an interestingly-matched couple I saw when walking home from work. (A) & (B) The image is shown using small squares of different shades of gray, where each square corresponds to a single pixel. This is only a convention used for display; the pixels themselves are stored as arrays of numbers \\(C) -- but looking at the numbers directly it's pretty hard for us to visualize what the image contains."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:126
msgid "Image data & its display"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:128
msgid "The distinction between a pixel's numeric value and the color used to display it might seem like a minor detail, but it definitely isn't: failing to recognise this difference underlies a *lot* of errors."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:130
msgid "If we aren't careful, two related facts can cause us an enormous amount of trouble:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:133
msgid "Images that **look the same** can contain **different** pixel values"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:134
msgid "Images that **look different** can still contain **the same** pixel values"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:176
msgid "Images that *look* the same, but contain *different* pixel values.\\ Measuring each of these images would give different results, for reasons we shall see in later chapters."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:213
msgid "Images that *look* different, but contain *the same* pixel values.\\ Measuring each of these images would give the same results."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:217
msgid "This is crucial because it's entirely possible to analyze two different images that *appear* identical, but to get very different (and very wrong) results."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:219
msgid "This is far from a theoretical problem. It happens a lot in practice whenever someone innocently makes an adjustment to an image (e.g. to make it look brighter, or change the colors for display) without realising that the adjustment has actually changed the pixel values -- and thereby compromised the underlying data. This can fatally undermine the integrity of any later analysis."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:223
msgid "What's worse, these errors can go completely unnoticed, surreptitiously compounding the problem of replicability in science."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:225
msgid "Which brings us to the key message of this chapter:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:227
msgid "Don't (just) trust your eyes!"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:230
msgid "In science, we need to know what is happening whenever we open, adjust and save our images. If we don't, we risk misinterpreting our data."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:234
msgid "Fortunately, knowing just a little bit about imaging and image analysis is enough to avoid making these mistakes. Knowing more than a little bit can open up new worlds of possibility to extract useful information from scientific images."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:237
msgid "The goal of this handbook is to explain these ideas. We'll start by considering two questions:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:240
msgid "**Where do the pixel values come from?**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:241
msgid "**How are pixel values converted into colors for display?**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:243
msgid "It's hard to give a detailed-but-general answer to the first question, because the origin and interpretation of the pixel values depends upon how the image was created, and there are many different ways to generate an image."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:245
msgid "Nevertheless, the key ideas are similar everywhere. By way of illustration, we'll consider a very common case in bioimaging where the pixel values relate to detected light -- specifically, using the example of a fluorescence microscope -- before moving how to see how these values are displayed."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:250
msgid "A simple microscope"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:252
msgid "When I work with fluorescence images, I have a very simple picture in my head of how the image is formed. It may not be very exact, but I find it extremely useful as a basis to which we can add detail whenever we need it. We will revisit this picture later in the book to help organize the interrelating imaging considerations relevant to analysis."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:256
msgid "In my simplified model, there are only three components that we need to worry about:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:258
msgid "**Sample** -- the thing we want to look at"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:259
msgid "**Objective lens** -- the thing that gathers the light and focusses it for detection"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:260
msgid "**Detector** -- the thing that detects the light to form the digital image (here, a CCD camera)"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:262
msgid "The process is illustrated below:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:272
msgid "There are a couple of things to note at this point:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:274
msgid "Not *all* the light emitted from the sample is detected. A lot of it never enters the objective lens."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:275
msgid "Our images aren't perfect. We will explore problems of blur, noise and pixel size later."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:277
msgid "For now, we are mostly interested in the detection step and how it generates a digital image. Zooming in to look at this in more detail, we can imagine what happens as light hits the camera. The sensor of the camera itself is divided into **physical pixels**, which will correspond to the pixels in the final image. When a photon strikes the detector, an electron may be released at one of the physical pixels. During the acquisition of an image, many photons strike the detector, which can cause many electrons to be released at different physical pixels. These electrons contribute to the value of a pixel in the final image: more electrons &rarr; higher pixel values."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:292
msgid "The important point is that **pixel values are only *indirectly* related to whatever it is in our sample that we want to measure**."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:294
msgid "In this example, they have been derived by quantifying the charge of electron clouds gathered at each physical pixel. This should be proportional to the amount of detected light that originated from a particular volume of the sample. This, in turn, depends upon what is actually present in the sample -- but there are *a lot* of things that can influence the final values in connection with acquisition parameters, conversion factors, and physics. These are not usually related directly to the thing you might want to quantify."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:299
msgid "Some of the factors influencing pixel values"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:301
msgid "**Amount of time spent detecting photons**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:302
msgid "*More time → More photons → More electrons → Higher pixel values*"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:303
msgid "**Numerical aperture of the objective lens**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:304
msgid "This relates to the **angle** of light accepted by the objective"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:305
msgid "*Higher NA → Larger angle → More photons → More electrons → Higher pixel values*"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:306
msgid "**Sensitivity of the detector (Quantum Efficiency)**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:307
msgid "Not all photons necessarily produce an electron; I think of this as the photon hitting the detector, but not hard enough to dislodge an electron. A detector with low sensitivity is likely to 'miss' more photons, so that they never contribute to the pixel value."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:308
msgid "*Higher sensitivity → More electrons → Higher pixel values*"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:311
msgid "Ultimately, this leads to the warning:"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:313
msgid "Don't over-interpret pixel values!"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:316
msgid "Individual pixel values are rarely very meaningful in isolation: we're usually interested in *relative* differences between groups of pixels."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:319
msgid "As we shall see, this means that we often need to average values and normalize to something whenever we want to make measurements in an image. We can't usually untangle the influences well enough to infer anything with confidence from a single pixel value."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:322
msgid "But the limitations in what pixel values can tell us don't diminish their importance: on the contrary, pixel values remain our raw data and it's essential that we preserve them as faithfully as possible. That's a lot harder than you might expect. It requires knowing when and how pixel values might become changed whenever we are working with our images. This is so crucial that it will be the focus throughout the entire first part of this book."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:330
msgid "Lookup tables"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:332
msgid "LUTs vs. Colormaps"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:333
msgid "**Lookup tables** are sometimes referred to as **colormaps**."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:335
msgid "For our purposes, the terms are interchangeable -- you may see either depending upon which software you are using."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:338
msgid "So images are really comprised of a lot of numbers -- the pixel values -- even though we normally visualize them as shapes and colors."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:340
msgid "It's time then to consider our second question: **How are pixel values converted for display?**"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:342
msgid "The basic idea is simple: the software displaying the image uses a **lookup table (LUT)** that maps each pixel value to a color. When it comes to showing the image, each pixel is replaced by a little dot or square on screen that has the corresponding color."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:353
msgid "LUTs therefore provide a way to **change the appearance of an image without changing its pixel values**."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:355
msgid "This is extremely useful in practice. Since images in biology often have rather low pixel values (formed from a small amount of detected light), we very often want to change their brightness for display."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:358
msgid "One way we *could* make an image brighter is to change the pixel values themselves -- multiply them by 2, for example. That would indeed usually make the image look brighter, but we risk making a terrible mess of our data if we permit ourselves to make such changes. As described above, we really don't want to modify our raw data unnecessarily."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:362
msgid "A **much** better way to change the brightness of an image is to change the LUT only."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:372
msgid "The danger is that **not all software cares so much about preserving pixel values**. Someone wanting to enhance their holiday photos isn't likely to care about retaining the original pixel values for quantification later; rather, they just want the images to look as nice as possible."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:375
msgid "For this reason, a lot of software designed for working with images really *will* rescale the pixel values when you do something as simple as adjusting the brightness. And so it is entirely possible to open an image, adjust the display slightly to see things more clearly, and in doing so irreparably damage the image -- losing the raw data required for later analysis."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:378
msgid "This is why you should **use scientific software for scientific image analysis** -- and not just any general imaging editing software you might find."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/images_and_pixels.md:380
msgid "But even when using scientific software, it's often possible to change pixel values whenever you'd really rather only be changing lookup tables. The next chapter will show how to check when this is happening."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:15
msgid "Python: Images & pixels"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:19
msgid "The goal of these sections is to provide an interactive illustration of image analysis concepts through the popular [Python](https://www.python.org) programming language."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:21
msgid "Feel free to skip this!"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:24
msgid "If you're more interested in concepts and/or ImageJ, I would recommend skipping the Python chapters at the beginning - you don't need them to follow the rest of the book."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:29
msgid "However, if you *are* interested, I hope these sections can help provide an alternative view of image analysis."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:31
msgid "Even if you've never coded before, working through the examples will hopefully give you both a deeper understanding of image processing and some useful programming skills."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:33
msgid "This page will introduce reading and displaying images. Later Python chapters in the handbook will build on these foundations."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:36
msgid "Make it interactive!"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:40
msgid "Before continuing, you should [make the notebook interactive](sec-live-notebooks) so that you can run the code yourself - and explore what happens if you make changes."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:43
msgid "Python overview"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:44
msgid "If you want a quick introduction to Python, check out the [Python Primer](../../appendices/python/python.md) section."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:46
msgid "For lots more, see Robert Haase's [Bio-image Analysis Notebooks](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/)."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:52
msgid "Read & show an image using Python <a name=\"show-image-in-python\" />"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:54
msgid "Let's begin by loading an image in Python, and then showing it using [matplotlib](https://matplotlib.org)."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:77
msgid "Changing lookup tables"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:79
msgid "The key method here is `plt.imshow`. We can pass additional parameters to customize the display in many ways."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:82
msgid "To see what is possible, I usually start to type the name and then press {kbd}`Shift+Tab` to prompt some documentation to appear."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:86
msgid "Alternatively, you can run either of the following lines"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:91
msgid "to display some help text."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:97
msgid "This can sometimes reveal an overwhelming amount of information, and it can take a bit of time to figure out how to identify the key bits."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:99
msgid "The important plotting options for our purposes are"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:100
msgid "`cmap` to change the colormap (LUT)"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:101
msgid "`vmin` to change the pixel value corresponding to the first color in the colormap"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:102
msgid "`vmax` to change the pixel value corresponding to the last color in the colormap"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:104
msgid "The last two options control the brightness/contrast."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:106
msgid "Try running the following code cells to see the effect, and try out other changes."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:137
msgid "There are many more colormaps available in matplotlib -- for details, see https://matplotlib.org/stable/tutorials/colors/colormaps.html"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:151
msgid "As you can see, the image may look *very* different depending upon the colormap and min/max values used."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:153
msgid "However, it's crucial that *we haven't modified the original image data itself*."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:155
msgid "To check this, try showing the image as we did initially - to make sure it looks the same."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:163
msgid "Further customizing image display"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:165
msgid "Lots more can be done to customize appearance."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:167
msgid "In order to standardize things throughout this book, I normally turn off the outer axis (numbers around the boundary), set an image title, and use a grayscale lookup table."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:169
msgid "The code to do this is shown below."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:181
msgid "Writing functions"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:183
msgid "If you use the same customizations frequently, it helps to **define a function** that applies them. Then you don't need to copy and paste the same lines of code frequently; rather, you just call the function instead."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:186
msgid "The function definition starts with `def`. It is followed by"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:187
msgid "The function name"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:188
msgid "Parameters (within parentheses), sometimes with default values"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:189
msgid "A colon"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:190
msgid "The main code that implements the function - this needs to be indented (something Python is *very* fussy about)"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:214
msgid "Helper functions in this book"
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:216
msgid "I've written several helper functions to standardize image display throughout this handbook. They aren't part of any wider Python library, but we can use them here to make our scripts shorter and focus on the more important concepts."
msgstr ""

#: ../../chapters/1-concepts/1-images_and_pixels/python.md:219
msgid "To use these helper functions, we need to import them once per Jupyter notebook. Then we can use the methods such as `load_image` and `show_image` (along with companions like `show_histogram`) to display images."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:16
msgid "ImageJ: Measurements & histograms"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:36
msgid "ImageJ makes generating basic measurements and histograms *extremely* easy:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:38
msgid "Press {kbd}`M` to make **M**easurements"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:39
msgid "This is the shortcut to run {menuselection}`Analyze --> Measure`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:40
msgid "Press {kbd}`H` to create a **H**istogram"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:41
msgid "This is the shortcut to run {menuselection}`Analyze --> Histogram`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:43
msgid "Assuming your image is 2D and there is no ROI active (we will explore [dimensions](chap_dimensions) and [ROIs](sec_imagej_rois) later), both of these commands will use all the pixels in the image."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:45
msgid "We'll explore how to customize the regions being measured and exactly what measurements are made later in this section, but already it should be possible to answer the following questions."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:54
msgid "*similar_1.tif*, *similar_2.tif*, *similar_3.tif* and *similar_4.tif* are all, well, similar. However only two contain *identical* pixel values."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:57
msgid "Which two images contain the same values?"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:59
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/similar_1.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/similar_2.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/similar_3.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/similar_4.tif)"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:64
msgid "Only *similar_1.tif* and *similar_3.tif* can contain the same values. An easy way to determine this is to compute the mean (average) of all pixels in each of the images. Only those two images share the same mean value."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:82
msgid "*disguise_matching.tif* has lost its match."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:84
msgid "Which of the following three images have the same pixel values as *disguise_matching.tif*?"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:85
msgid "*disguised_1.tif*"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:86
msgid "*disguised_2.tif*"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:87
msgid "*disguised_3.tif*"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:89
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/disguise_matching.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/disguised_1.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/disguised_2.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/disguised_3.tif)"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:94
msgid "*disguised_3.tif* is the matching image."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:102
msgid "Measuring images"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:104
msgid "When using {menuselection}`Analyze --> Measure`, the measurements are added to a *Results table*."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:106
msgid "By default, the mean, minimum and maximum pixel values are provided, along with the area of the image... and that's all. It's not a lot."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:109
msgid "Furthermore, if you make multiple measurements then they are added to the *same* results table, without any identifiers. This is especially confusing if you have several images open at the same time, and have no clue which row of the results table corresponds to measurements from which image."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:112
msgid "{menuselection}`Analyze --> Set Measurements...` makes it possible to address both of these limitations. It not only provides many more measurements that can be selected, it includes a crucial {guilabel}`Display label` option that will cause the title of the image to be included in the results table ({numref}`fig-measure`)."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:117
msgid "Measurement units matter -- but aren't displayed!"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:120
msgid "The results table does not include units for measurements, even though these are essential. Seeing an area of 10 *might* mean 10 pixels<sup>2</sup>, or 10 µm<sup>2</sup>... or something else entirely."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:123
msgid "See {ref}`chap_pixel_size` for more information about why that matters for any measurements of size (area, length etc.), and how to check the units."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:146
msgid "Measurements made on an image are added to a results table. The choice of measurements to make can be changed using the {menuselection}`Analyze --> Set Measurements...` command."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:158
msgid "The 'One True Results Table' & its imposters"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:160
msgid "A small idiosyncrasy to be aware of is that, as far as ImageJ is concerned, there is only ever one 'official' results table -- the one with the title {guilabel}`Results`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:162
msgid "Different, similar-looking tables can be created by different commands, or by duplicating an existing results table with {menuselection}`File --> Duplicate...`. Nevertheless, any new measurements you make with the {menuselection}`Measure` command will *only* be added to the original, official table. This also has an extra {guilabel}`Results` entry in its menu bar that other tables lack."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:171
msgid "Choosing which measurements to select"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:173
msgid "Some options within {menuselection}`Analyze --> Set Measurements...` are so universally useful that they should pretty much always be set. Conversely, some options are manifestly confusing and dangerous and should be used rarely -- or not at all."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:176
msgid "Options to **always** select:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:177
msgid "{guilabel}`Area`, {guilabel}`Mean gray value`, {guilabel}`Standard deviation`, {guilabel}`Min & max gray value` -- basic summary values"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:178
msgid "{guilabel}`Display label` -- includes the image title"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:179
msgid "{guilabel}`Stack Position` -- includes the 2D plane that has been measured in an image with {ref}`more dimensions <chap_dimensions>`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:181
msgid "Options to **avoid**:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:182
msgid "{guilabel}`Limit to threshold` -- restricts the region being measured according to any {ref}`threshold <chap_thresholding>` that has been set; don't do this routinely, instead convert your threshold to a ROI and use that instead."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:183
msgid "{guilabel}`Redirect to` -- measures a different image from the one that's selected. It sounds weird, but it's intended for cases where you have two corresponding images; one in which you can identify a region to measure, and one that contains the pixel values you should measure."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:185
msgid "The two options that I think you should avoid can both result in something unexpected being measured if you don't know (or have forgotten) that either was selected under {menuselection}`Analyze --> Set Measurements...`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:187
msgid "Fortunately, they are not really needed if you master the art of generating, managing and transferring regions of interest between images."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:191
msgid "Regions Of Interest"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:193
msgid "**Regions Of Interest (ROIs)** can be used to define specific parts of an image that should be processed independently or measured. Only pixels within any ROI we draw will be included in the calculations when we run {menuselection}`Analyze --> Measure`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:212
msgid "ROI drawing tools are found on the left side of the ImageJ tool bar (A). The ROI in (B) was created by drawing one rectangular and two circular ROIs, holding down the {kbd}`Shift` key between each so that the regions were combined."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:215
msgid "ROIs of different types (e.g. rectangles, circles, lines, points, polygons, freehand shapes) can be drawn using the commands in the tool bar ({numref}`fig-roi_drawing`), and are invariably 2D. Right-clicking the tools often provides access to related tools, while double-clicking may give additional options. When drawing a ROI, pressing {kbd}`Shift` or {kbd}`Control` before releasing the mouse button adds the ROI being drawn to any existing ROI already present."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:220
msgid "**ROIs** in ImageJ are sometimes called **selections** -- meaning the same thing"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:223
msgid "Somewhat confusingly, ROIs are sometimes referred to as **selections** in ImageJ. This is why some extra commands to create or adjust ROIs appear under the {menuselection}`Edit --> Selection` submenu."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:226
msgid "One such command is {menuselection}`Edit --> Selection --> Create Mask`. This creates a new [binary](chap_binary) (black and white) image that differentiates between the pixels that are inside and outside the ROI."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:245
msgid "A ROI representing an area is usually depicted using yellow lines drawn on an image, but sometimes it isn't clear which pixels are inside or outside the ROI. {menuselection}`Edit --> Selection --> Create Mask` can help clarify this."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:255
msgid "{menuselection}`Process --> Binary --> Options...`"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:258
msgid "Interpreting 'Create Mask'"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:261
msgid "Unfortunately, when using {menuselection}`Edit --> Selection --> Create Mask` it is not *entirely certain* whether black means 'inside' or 'outside'. This depends upon whether {guilabel}`Black background` is selected within {menuselection}`Process --> Binary --> Options...`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:264
msgid "This doesn't usually matter in practice, because it tends to be clear from the context; ROIs usually cover a small region of the image, so the background color is the one seen in the majority of pixels."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:266
msgid "An exception to this is if {menuselection}`Edit --> Selection --> Make Inverse` has been used to flip a ROI to represent all the background pixels of the original, with the foreground removed."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:271
msgid "Don't overestimate the accuracy of measurements"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:274
msgid "Although ImageJ can measure very exactly whatever regions it is told to measure _within an image_, keep in mind that in light microscopy images any size measurements will not exactly correspond to sizes of structures _in real life_. This is especially true at very small scales (hundreds of nanometers or smaller), for resolution-related reasons that will be described in {ref}`chap_formation_spatial`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:280
msgid "Working with multiple ROIs"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:282
msgid "Normally, only a single ROI can be 'active' in ImageJ (i.e. affecting measurements) at any one time. If you need control over multiple ROIs, there are two places in which you can store them. These differ according to purpose:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:286
msgid "**The ROI Manager:** for most ROIs that you want to be able to edit and use for measurements"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:287
msgid "**The image overlay:** for ROIs that you only want to display"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:291
msgid "The ROI Manager"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:294
msgid "{kbd}`T` for _**T**roy manager_: shortcut to add ROI to the ROI Manager"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:297
msgid "ImageJ's *ROI Manager* provides a convenient way to store multiple ROIs in a list, allowing you to easily access, edit and measure them."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:299
msgid "The slow way to open the ROI Manager is to choose {menuselection}`Analyze --> Tools --> ROI Manager...`. The fast way is just to draw a ROI and press {kbd}`T`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:302
msgid "The additional {guilabel}`Measure` command within the manager is then like applying {menuselection}`Analyze --> Measure` to each ROI in turn. If you happen to want to show all the ROIs simultaneously, you can select the {guilabel}`Show All` option [^fn_1]."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:307
msgid "Because ROIs in the ROI Manager are represented independently of the image on which they were defined, you can create a ROI on one image, add it to the ROI manager, select a different image and then click on the ROI in the ROI Manager to place it on the second image. This provides one way to transfer a ROI from one image to another."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:310
msgid "Measurements made from the ROI Manager always use the most recently-selected image, so be careful if you have several images open at the same time. This is another reason why choosing {guilabel}`Display label` under {menuselection}`Analyze --> Set Measurements...` is so important."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:315
msgid "Transferring individual ROIs"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:318
msgid "A faster way to transfer a single ROI between images without using the ROI Manager is to click on the second image and press {kbd}`Shift+E` (the shortcut for {menuselection}`Edit --> Selection --> Restore Selection`)"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:323
msgid "Expert ROI manipulation with the ROI Manager"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:326
msgid "Using the ROI Manager, you can craft your ROIs into more complex shapes: adding or removing other ROIs."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:328
msgid "To do this, first add the main ROIs you want to work with to the manager. Then select them, and choose from among the options:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:330
msgid "{guilabel}`AND` – create a ROI containing only the regions where the selected ROIs overlap"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:331
msgid "{guilabel}`OR` – create a single ROI composed by combining all the selected ROIs"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:332
msgid "{guilabel}`XOR` – create a single ROI containing all the selected ROIs, _except_ the places where they overlap ('eXclusive OR')"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:342
msgid "The *ROI Manager* with two ROIs"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:350
msgid "For {numref}`fig-rois_mask`, I used the ROI Manager to create a ROI with a hole in it."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:352
msgid "To do this in *happy_cell.tif*, you can"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:354
msgid "Draw one ROI around the full cell, and add it to the ROI Manager"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:355
msgid "Draw a second ROI around the nucleus, and add it to the ROI Manager"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:357
msgid "Then you can select both ROIs and use *one* of the combine operations -- {guilabel}`AND`, {guilabel}`OR`, {guilabel}`XOR` -- to subtract the nucleus ROI from the cell ROI. The end result is a ROI representing the cytoplasm, with the nucleus removed."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:360
msgid "Which combine operation do you need to achieve this?"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:362
msgid "**Tip:** Remember {menuselection}`Edit --> Selection --> Create Mask` will let you see which pixels are inside and which pixels are outside the ROI."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:365
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/launch-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/happy_cell.tif)"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:370
msgid "{guilabel}`XOR` ('exclusive OR') provides a ROI that contains pixels that are inside the cell OR inside the nucleus, but NOT both."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:379
msgid "Overlays"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:382
msgid "{kbd}`B` for _**B**overlay_: shortcut to add a ROI to an overlay"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:385
msgid "Overlays also contain a list of ROIs that are shown simultaneously on the image. However, unlike with the ROI Manager, ROIs stored on an overlay do _not_ usually affect the {guilabel}`Measure` command."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:388
msgid "Overlays are therefore suitable for storing annotations for visualization purposes. You can think of them as existing on their own separate layer, so that adding and removing the overlay does not mess up the underlying pixel values ({numref}`fig-rois`)."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:391
msgid "The main commands for working with overlays are found in the {menuselection}`Image --> Overlay -->` submenu, where you can get started by drawing a ROI and choosing {guilabel}`Add Selection` (or simply press {kbd}`B`). The same submenu also provides commands to transfer ROIs between the overlay and the ROI Manager."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:395
msgid "You can 'reactivate' a ROI on an overlay by clicking it with the {kbd}`Alt` key pressed (provided a suitable ROI tool is selected), and then edit or reposition it."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:397
msgid "Note that if a ROI on an overlay has been 'reactivated' in this way, then it *does* influence measurements."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:402
msgid "Saving ROIs"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:404
msgid "Individual ROIs, currently active on an image, can be saved simply by choosing {menuselection}`File --> Save As --> Selection...`"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:406
msgid "The ROI Manager also has a {guilabel}`Save...` command (under {guilabel}`More`), which will save whichever ROIs are currently selected in the manager (or, if none are selected, all of them)."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:408
msgid "Overlays are fixed to specific images and do not have their own special save command, but will nonetheless be included if you save the image as a TIFF file (ImageJ's default format). Any currently-active ROI will also be saved in a TIFF."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:411
msgid "This is all fine if you work only in ImageJ or Fiji, but unfortunately if you try to view your ROIs in other software it is highly unlikely to work properly. The ROI format is specific to ImageJ."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:414
msgid "The way around this is to use the {menuselection}`Image --> Overlay --> Flatten` command. This creates an _RGB copy of the image in which the pixel values have been changed_ so that any ROIs or overlays will appear whenever you open the image elsewhere. Therefore you may well want to use this command when creating figures or presentations, but you do _not_ want to subsequently apply your analysis to the image you have flattened – always use the original instead."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:418
msgid "For more details on the impact of converting an image to RGB, see {ref}`chap_colors`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:434
msgid "ROIs and overlays are displayed on top of images, and so can be removed easily without having any effect upon the pixel values. Flattened images may appear the same on screen, but are invariably RGB (see {ref}`chap_colors`) and have had their pixel values permanently changed to show any annotations."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:448
msgid "Open the images *Annotated_Cyclists_1.tif* and *Annotated_Cyclists_2.tif*, which depict the 3 main cyclist characteristics I found most disconcerting as a pedestrian in Heidelberg."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:450
msgid "The images should initially look the same, but in one the text is an overlay, while in the other the image has been flattened. Which is which? Try to think of several ways to investigate this."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:453
msgid "**Tip:** Zooming in may help. So might searching the menus for overlay-related commands (aided by {kbd}`L`)."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:455
#: ../../chapters/1-concepts/2-measurements/imagej.md:487
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/Annotated_Cyclists_1.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/Annotated_Cyclists_2.tif)"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:459
msgid "*Annotated_Cyclists_1.tif* is the one with the overlay."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:461
msgid "Five ways to determine whether an annotation is an overlay or not:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:463
msgid "Zoom in very closely to the region containing the annotation. If it becomes 'blocky', i.e. made up of pixels, it is not an overlay. If it remains smooth, then it is an overlay."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:466
msgid "Move your cursor over the region where the annotation appears, and look at the pixel values. If the values are all the same where the annotation is present, but different elsewhere, then it is unlikely to be an overlay: the annotation is influencing the pixel values."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:468
msgid "Using the paintbrush <img src=\"../../../images/imagej/icons/brush.png\" /> tool from the toolbar, try putting some other color where the annotation appears. If the annotation remains visible on top of where you drew, it must be on an overlay."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:470
msgid "Choose {menuselection}`Image --> Overlay --> Hide Overlay` and see if the annotation disappears."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:471
msgid "Choose {menuselection}`Image --> Overlay --> To ROI Manager` and see if anything happens at all."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:483
msgid "Using the cyclist image containing the overlay from the previous practical, rearrange the annotations so that they are each positioned next to different cyclists."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:485
msgid "You could do this by deleting the overlay and starting again, but there are other, faster possibilities (using a technique mentioned before, or the {menuselection}`Image --> Overlay --> To ROI Manager` command)."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:493
msgid "Click the annotation while holding down the {kbd}`Alt` key, to bring it to life so it can be moved around again. This only works if certain tools are selected, e.g. {guilabel}`Rectangle` or {guilabel}`Text`, because some other tools have more overriding functions, such as zooming in or scrolling."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:501
#: ../../chapters/1-concepts/2-measurements/python.md:101
msgid "Generating histograms"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:503
msgid "Creating a histogram in ImageJ, via {menuselection}`Analyze --> Histogram` or simply pressing {kbd}`H`, results in a new histogram window being created. Like with {menuselection}`Analyze --> Measure`, this will use a ROI if it is available; otherwise it will use the full image."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:506
msgid "An ImageJ histogram is displayed above some basic summary statistics and four intriguing buttons:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:508
msgid "{guilabel}`List` -- to list the actual bins and counts associated with the histogram"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:509
msgid "{guilabel}`Copy` -- to copy the list above to the clipboard"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:510
msgid "{guilabel}`Log` -- to change the y axis to show the log of the counts for each bin; this is helpful to distinguish between counts that are very small"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:511
msgid "{guilabel}`Live` -- to make the histogram responsive to whatever you do with the image -- including changing the LUT, or any ROI"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:519
msgid "An image with its histogram in ImageJ."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:522
msgid "A histogram of an image... and an image of a histogram"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:524
msgid "A slightly odd feature of ImageJ histograms is that *the histogram is also an image*. That means you can draw ROIs and even make measurements on it. We will revisit this in {ref}`chap_pixel_size`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/imagej.md:305
msgid "If you have a stack, you also may need to explore {guilabel}`More >> Options...` to define whether all ROIs are shown on all slices, or only on the slices on which they were first created."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:17
msgid "Measurements & histograms"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:22
msgid "**Measurements** can be made in images by calculating statistics from the pixel values"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:23
msgid "**Histograms** show the distribution of pixel values in an image, and are extremely useful to compare images & diagnose problems"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:44
msgid "{ref}`chap_pixels` demonstrated how looks can be deceiving: the visual appearance of an image isn't enough to determine what data it contains."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:46
msgid "Because scientific image analysis depends upon having the right pixel values in the first place, this leads to the important admonition:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:48
msgid "Keep your original pixel values safe!"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:51
msgid "The pixel values in your original image are your raw data: it's essential to protect these from unwanted changes."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:54
msgid "This is really important because there are lots of ways to accidentally compromise the raw data of an image -- such as by using the wrong software to adjust the brightness and contrast, or saving the files [in the wrong format](chap_files). This can cause the results of analysis to be wrong."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:57
msgid "What makes this especially tricky is that trustworthy and untrustworthy images can *look* identical.  Therefore, we need a way to see beyond LUTs to compare the content of images easily and efficiently."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:62
msgid "Comparing histograms & statistics"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:64
msgid "In principle, if we want to compare two images we could check that every corresponding pixel value is identical in both images. We will use this approach later, but isn't always necessary."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:67
msgid "There are two other things we can do, which are often much faster and easier:"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:69
msgid "Calculate some **summary statistics** from the pixel values, such as the average (mean) pixel value, standard deviation, minimum and maximum values."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:70
msgid "Check out the image **histogram**. This graphically depicts the distribution of pixel values in the image."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:72
msgid "Putting these into action, we can recreate {numref}`fig-images_look_same` but this time add"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:73
msgid "the LUT (shown as a colored bar below the image)"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:74
msgid "a histogram"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:75
msgid "summary statistics"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:128
msgid "Recreation of {numref}`fig-images_look_same` showing images that *look* the same, but contain *different* pixels values -- this time with measurements and histograms included."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:131
msgid "With the additional information at our disposal, we can immediately see that the images really **do** contain different underlying values -- and therefore potentially quite different information -- despite their initial similar appearance. We can also see that the LUTs are different; they show the same colors (shades of gray), but in each case these map to different values."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:134
msgid "By contrast, when we apply the same steps to {numref}`fig-images_look_different` we see that the histograms and statistics are identical -- only the LUT has been changed in each case. This suggests that any analysis we perform on each of these images should give the same results, since the pixel values remain intact."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:183
msgid "Recreation of {numref}`fig-images_look_different` showing images that *look* different, but contain *the same* pixel values -- this time with measurements and histograms included."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:212
msgid "If two images have identical histograms and summary statistics (mean, min, max, standard deviation), does this **prove** that the images are identical?"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:216
msgid "No! For example, we might have the same pixel values in a different arrangement. If I randomly shuffle the pixels in the image then the basic statistics and histogram remain unchanged -- but the image itself is very different."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:223
msgid "This means that, technically, we can only really use histograms and summary measurements to prove that images are definitely *not* the same."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:225
msgid "However, in practice this is usually enough. If two images have identical histograms and summary statistics *and* look similar, it is *very likely* that they are the same."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:228
msgid "Conceivably, someone might try to deceive us by making some very subtle change to an image that preserves the statistics, such as as swapping two pixels amongst millions so that we don't notice the difference. Later, we'll see how to overcome even that by checking every single pixel -- but such elaborate trickery probably isn't a very real risk for most of us."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:231
msgid "Most of the time, when things go wrong with scientific images the histogram and statistics will be compromised in an obvious way -- we just need to remember to check for these changes."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:237
msgid "The ability to quickly generate and interpret histograms is an essential skill for any image analyst. We will use histograms a lot throughout this text, both to help diagnose problems with the data and to figure out which techniques we should use."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:240
msgid "Make histograms a habit!"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/measurements.md:243
msgid "When working with new images, it's a good habit to *always* check histograms. This can give a deeper understanding of the data, and help flag up potential problems."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:15
msgid "Python: Measurements & histograms"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:19
msgid "Here, we will explore how to make measurements and generate histograms with Python."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:37
msgid "Introduction to NumPy arrays"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:39
msgid "The images we are working with in Python are **NumPy arrays** - https://numpy.org"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:41
msgid "Rather than plotting the image with `plt.imshow`, we can also simply print its values. Since there can be a *lot* of values (i.e. millions of pixels per image), only a few are shown by default."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:48
msgid "If we want to know how many values are in an image, we can query its `shape`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:50
msgid "This returns the size in the order `(height, width)`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:56
msgid "Whenever we have a 2D NumPy array, we can easily transpose it - which will switch the width and height values."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:65
msgid "Calculating statistics"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:67
msgid "A more meaningful benefit of working with NumPy arrays, for our purposes at least, is that they enable us to calculate some summary statistics *extremely* easily."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:69
msgid "For example, to compute the average (mean) pixel value we can simply use `im.mean()`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:75
msgid "If that's the last thing we add to a code cell, then the result will be displayed in our notebook."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:77
msgid "However, if we want to print multiple values - and multiple statistics - in quick succession we should use the `print` function again."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:86
msgid "Formatting output"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:88
msgid "Things become more readable if we add some extra text, rather than just printing numbers."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:90
msgid "One of the easiest ways to do this is to use an 'f-string', which is in the form `f'Some text {some_variable}`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:92
msgid "The part between the braces `{}` can be a calculation, and if you add `:.2f` at the end this will optionally limit the number of decimal places (here, to two)."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:103
msgid "We can now try to generate image histograms, using `plt.hist`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:105
msgid "You might expect `plt.hist(im)` to work, just as `plt.imshow(im)` did previously. However, the result can be a bit surprising."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:113
msgid "The problem is that the image is 2D, and `plt.hist` is expecting just a single 1D list of values. We can generate that with a call to `.flatten()`, and use the flattened array to create the histogram."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:127
msgid "As with `plt.imshow`, we have lots of options to customize the histogram. This includes the ability to set the color or number of histogram bins."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:135
msgid "**Parentheses**"
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:137
msgid "It may initially be confusing why we sometimes need parentheses `()` and sometimes we don't, e.g. `im.flatten()` vs. `im.shape`."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:139
msgid "As a general rule, parentheses indicate that we're calling a method that *does* something (e.g. prints a value, calculates an average, flattens an array)."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:141
msgid "When we don't see parentheses, this indicates that we're accessing a field or property (e.g. the shape of an array)."
msgstr ""

#: ../../chapters/1-concepts/2-measurements/python.md:143
msgid "In practice, the distinction can sometimes be a bit murky as you get deeper into Python - but it helps as a general guide."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:16
msgid "Types & bit-depths"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:21
msgid "The **bit-depth** & **type** of an image determine what pixel values it can contain"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:22
msgid "An image with a **higher bit-depth** can (potentially) contain **more information**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:23
msgid "During acquisition, most images have the type **unsigned integer**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:24
msgid "During processing, it's often better to use **floating point** types"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:25
msgid "Attempting to store values outside the range permitted by the type & bit-depth leads to **clipping** -- which is usually **very bad indeed**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:48
msgid "As described in {ref}`chap_pixels`, each pixel has a numerical value – but a pixel cannot typically have just *any* numerical value it likes. Instead, it works under the constraints of the image **type** and **bit-depth**."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:51
msgid "Ultimately the pixels are stored in some binary format: a sequence of **bits** (**bi**nary digi**ts**), i.e. ones and zeros. The bit-depth determines how many of these ones and zeros are available to store each pixel. The type determines how these bits are interpreted."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:57
msgid "Representing numbers with bits"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:64
msgid "Bob devising his code."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:67
msgid "Suppose Bob is developing a secret code to store numbers, but in which he is only allowed to write ones and zeros. If he is only allowed a single one or zero (i.e. a single bit), he doesn't have many options."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:70
msgid "Assuming he wants his encoded numbers to be consecutive integers starting from zero, this means he can only represent two different numbers: one and zero."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:82
msgid "If he is allowed an extra bit, suddenly he can represent 4 numbers by combining the ones and zeros differently."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:94
msgid "Clearly, the more bits Bob is allowed, the more unique combinations he can have -- and therefore the more different numbers he can represent in his code."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:96
msgid "With 8 bits are his disposal, Bob can combine the bits in 256 different ways to represent 256 different numbers."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:108
msgid "The pixel values in an image are stored using a code just like this. Each possible value is represented in binary as a unique combination of bits."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:113
msgid "Image bit-depth"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:115
msgid "The **bit-depth** of an image is the number of bits used to represent each pixel. A bit-depth of 8 would indicate that 8 bits are used to represent a single pixel value."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:118
msgid "The bit-depth imposes a limit upon the pixel values that are possible. A lower bit-depth implies that fewer different pixel values are available, which can result in an image that contains less information."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:156
msgid "Representing an image using different bit-depths."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:161
msgid "As shown in {numref}`fig-bit_depths_demo`, a 1-bit image can contain only two values: here, shown as black or white pixels. Such **binary images** are extremely limited in the information that they can contain, although will turn out to be [very useful later](chap_thresholding) when processing images."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:164
msgid "A 2-bit image is not much better, containing at most only 4 different values. A 4-bit image can have 16 values. When visualized with a grayscale LUT, this is a substantial improvement. In fact, the eye is not particularly good at distinguishing different shades of gray -- making it difficult to see much difference between a 4-bit and 8-bit image. However, the histograms reveal that the 8-bit image contains more fine-grained information."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:172
msgid "In practice, computers tend to work with groups of 8 bits, with each group of 8 bits known as a **byte**. Microscopes that acquire 8-bit images are still reasonably common, and these permit 2<sup>8</sup> = 256 different pixel values, which fall in the range 0–255. The next step up is a 16-bit image, which can contain 2<sup>16</sup> = 65536 values: a dramatic improvement (0–65535)."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:180
msgid "What impact would you expect bit-depth to have on the file size of a saved image?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:182
msgid "For example, would you expect an 8-bit image to have a larger, smaller or (roughly) equivalent file size to a 16-bit image of the same scene? You can assume the two images have the same number of pixels."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:187
msgid "In general, the file size required to store an image is expected to be higher with a higher bit-depth."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:189
msgid "Assuming that the image isn't [compressed](sec_files_compression), a 16-bit image would require roughly twice as much storage space as a corresponding 8-bit image."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:191
msgid "If you have a 1024 x 1024 pixel image that is 8-bit, that should take roughly 1 MB to store. The corresponding 16-bit image would require approximately 2 MB."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:200
msgid "Image type"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:202
msgid "At this point, you  might be wondering: what about fractions? Or negative numbers?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:205
msgid "In reality, the bit-depth is only part of the story. The **type** of the image is what determines how the bits are interpreted."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:208
msgid "Until now, we have assumed that 8 bits would be used to represent whole numbers in the range 0 -- 255, because we have 2<sup>8</sup> = 256 different combinations of 8 bits. This is an **unsigned integer** representation."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:211
msgid "But suppose we dedicate one of our bits to represent whether the number should be interpreted as positive or negative, with the remaining seven bits providing the magnitude of the number. An image using this approach has the type **signed integer**. Typically, an 8-bit signed integer can be in the range -128 -- 127. Including 0, that still leaves 256 distinct possibilities."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:216
msgid "Although the images we acquire are normally composed of unsigned integers, we will later explore the immense benefits of processing operations such as averaging or subtracting pixel values, in which case the resulting pixels may be negative or contain fractional parts. **Floating point** type images make it possible to store these new, not-necessarily-integer values in an efficient way. That can be important, because we could lose a lot of information if we always had to round pixel values to integers."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:220
msgid "Floating point images also allow us to store three special values: $+\\infty$, $-\\infty$ and `NaN`. The last of these stands for *Not a Number*, and can represent a missing or impossible value, e.g. the result of 0/0."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:223
msgid "Key message"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:226
msgid "The bit-depth and type of an image determine what pixel values are possible."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:229
msgid "How & why points can float"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:231
msgid "Floating point pixel values have variable precision depending upon whether they are representing very small or very large numbers."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:233
msgid "Representing a number in binary using floating point is analogous to writing it out in standard form, i.e. something like 3.14×10<sup>8</sup>, which may be written as 3.14e8. In this case, we have managed to represent 314000000 using only 4 digits: 314 and 8 (the 10 is already baked in to the representation)."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:236
msgid "In the binary case, the form is more properly something like ± 2<sup>**M**</sup>×N: we have one bit devoted to the sign, a fixed number of additional bits for the exponent *M*, and the rest to the main number *N* (called the fraction)."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:238
msgid "A 32-bit floating point number typically uses 1 bit for the sign, 8 bits for the exponent and 23 bits for the fraction, allowing us to store a very wide range of positive and negative numbers. A 64-bit floating point number uses 1 bit for the sign, 11 bits for the exponent and 52 for the fraction, thereby allowing both an even wider range and greater precision. But again these require more storage space than 8- and 16-bit images."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:245
msgid "Common image types & bit-depths"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:246
msgid "Lots of permutations of bit-depth and type are possible, but in practice three are most common for images:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:247
msgid "8-bit unsigned integer"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:248
msgid "16-bit unsigned integer"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:249
msgid "32-bit floating point"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:251
msgid "The representations above are sufficiently ubiquitous that the type is often assumed. Unless otherwise specified, any 8-bit or 16-bit image is most likely to use unsigned integers, while a 32-bit image is probably using floating point pixels."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:254
msgid "Conceivably you *can* have a 32-bit signed/unsigned integer image, or even a 16-bit floating point image, but these are less common in the wild."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:269
msgid "The pixels shown on the right all belong to different images."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:271
msgid "In each case, identify what *possible* type an image could have in order to represent the value of the pixel. There can be more than one possible type for each pixel."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:274
msgid "Your type options are:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:276
#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "Signed integer"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:277
#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "Unsigned integer"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:278
#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:286
#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "Floating point"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:282
msgid "The possible image types, from left to right:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:284
msgid "Signed integer or floating point"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:285
msgid "Unsigned integer, signed integer or floating point"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:288
msgid "Note that 'floating point' is an option in all cases: it's the most flexible representation."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:299
msgid "What is the maximum pixel value that can be stored in a *16-bit, unsigned integer* image?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:303
msgid "The maximum value that can be stored in a 16-bit, unsigned integer image is 2<sup>16</sup>-1 = 65535."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:314
msgid "What would be the maximum pixel value that can be stored in a *16-bit, signed integer* image?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:318
msgid "The maximum value that can be stored in a 16-bit, signed integer image is 2<sup>15</sup>-1 = 32767 (since one of the bits is used for the sign, we have 15 remaining)."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:342
msgid "An image as a matrix of numbers, or just ones and zeros?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:344
msgid "You may recall how {numref}`fig-image_array` showed an image as being a matrix of numbers. That is already a slightly high level abstraction of how the image is actually represented. It's more accurate to see the image (or, indeed, any digital data) as simply being a long stream of ones and zeros, such as"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:348
msgid "{glue:}`binary_string`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:350
msgid "More information is needed about how the pixel values of the image are encoded to interpret these ones and zeros. This includes how should the ones and zeros be split up to represent different values (e.g. in chunks of 8, 16, or some other number?)."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:353
msgid "The bit-depth is what tells us how big the chunks are, and the type tells us how to convert each chunk into a decimal number."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:358
msgid "When bits go bad"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:360
msgid "We're now ready to discuss why you absolutely do need to know the basics of bit-depths and image types when working with scientific images."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:362
msgid "The main point of {ref}`chap_pixels` is that we need to keep control of our pixel values so that our final analysis is justifiable. There are two main bit-related things that can go wrong when trying to store a pixel value in an image:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:366
msgid "**Clipping:** We try to store a number outside the range supported, so that the closest valid value is stored instead. For example, if we try to store -10 in an 8-bit unsigned integer image then the closest value we can actually store is 0. Similarly, if we try to store 500 then the closest valid value is 255."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:367
msgid "**Rounding:** We try to store a number that cannot be represented exactly, and so it must be rounded to the closest possible value. For example, if we want to store 6.4 in an 8-bit unsigned integer image then this is not possible; rather, we would need to store 6 instead."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:371
msgid "Data clipping"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:373
msgid "Of the two problems, clipping is usually the more serious, as shown in {numref}`fig-bits_clipping`. A clipped image contains pixels with values equal to the maximum or minimum supported by that bit-depth, and it's no longer possible to tell what values those pixels *should* have. **The information is irretrievably lost.**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:377
msgid "Clipping often occurs whenever an image is converted to have a lower bit-depth. During this conversion, not all the original pixel values may be preserved -- in which case they must be somehow transformed into the range permitted by the output bit-depth."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:380
msgid "This transformation could simply involve clipping the unsupported values (usually very bad), or it could involve rescaling the pixel values first (usually less bad)."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:463
msgid "Storing an image using a lower bit-depth, either by clipping or by scaling the values. The top row shows all images with the same minimum and maximum values to determine the contrast, while the second row shows shows the same images with the maximum set to the highest pixel value actually present (the images are the same, only the LUTs are different). The bottom rows show both a plot of the pixel values through the center of each image and histograms of all the image pixel values. One may infer that information has been lost in both of the 8-bit images, but more much horrifically when clipping was applied. Scaling squeezes the data into a narrow range, which might result in some rounding errors -- but most of the information remains intact, with the shapes of the profile plot and histogram remaining similar."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:473
msgid "Clipping of high pixel values during acquisition is also called **saturation**."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:476
msgid "However, it's important to know that **clipping can already occur during image acquisition**. In fluorescence microscopy, this depends upon three main factors:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:479
msgid "**The amount of light being emitted.** Because pixel values depend upon how much light is detected, a sample emitting very little light is less likely to require the ability to store very large values. Although it still *might* because of..."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:480
msgid "**The gain of the microscope.** Quantifying very tiny amounts of light accurately has practical difficulties. A microscope’s gain effectively amplifies the amount of detected light to help overcome this before turning it into a pixel value (see {ref}`chap_microscope_types`). However, if the gain is too high, even a small number of detected photons could end up being over-amplified until clipping occurs."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:481
msgid "**The offset of the microscope.** This effectively acts as a constant being added to every pixel. If this is too high, or even negative, it can also push the pixels outside the permissible range."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:483
msgid "Avoid clipping your data!"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:486
msgid "If clipping occurs, we no longer know what is happening in the brightest or darkest parts of the image -- which can thwart any later analysis. Therefore **during image acquisition, any available controls should be adjusted to make sure clipping is avoided.**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:501
msgid "When acquiring an 8-bit unsigned integer image, is it fair to say your data is fine so long as your minimum pixel value is 0 and your maximum value is 255?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:505
msgid "No! At least, not really."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:507
msgid "You *cannot* store pixels outside the range 0–255. If your image contains pixels with either of those extreme values, *you cannot be certain whether or not clipping has occurred*. Therefore, you should ensure images you acquire do not contain any pixels with the most extreme values permitted by the image bit-depth. To be confident your 8-bit data is not clipped, the maximum range would be 1–254."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:521
msgid "The bit-depth of an image is probably some multiple of 8, but the bit-depth that a [detector (e.g. CCD)](chap_microscope_types) can support might not be."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:523
msgid "For example, what is the maximum value in a 16-bit image that was acquired using a camera with a 12-bit output?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:525
msgid "And what is the maximum value in a 8-bit image acquired using a camera with a 14-bit output?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:527
msgid "Assume unsigned integers are used in both cases."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:531
msgid "The maximum value of a 16-bit image obtained using a 12-bit camera is 4095 (i.e. 2<sup>12</sup>-1)."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:533
msgid "The maximum value of an 8-bit image obtained using a 14-bit camera is 255 – the extra bits of the camera do not change this. But if the image was saved in 16-bit instead, the maximum value would be 16383."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:536
msgid "So be aware that the actual range of possible values depends upon the acquisition equipment as well as the bit-depth of the image itself. The lower bit-depth will dominate."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:542
msgid "Rounding errors"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:544
msgid "Rounding is a more subtle problem than clipping. Again it is relevant as early as acquisition."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:547
msgid "For example, suppose you are acquiring an image in which there really are 1000 distinct and quantifiable levels of light being emitted from different parts of a sample. These could not possibly be given different pixel values within an 8-bit image, but could normally be fit into a 16-bit or 32-bit image with lots of room to spare. If our image is 8-bit, and we want to avoid clipping, then we would need to scale the original photon counts down first – resulting in pixels with different photon counts being rounded to have the same values, and their original differences being lost."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:551
msgid "Nevertheless, rounding errors during acquisition are usually small: it may not *really* matter if we can't tell the difference between detecting 1,000 photons and 1,003 photons."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:553
msgid "Rounding can be a bigger problem when it comes to processing operations like filtering, which often involve computing averages over many pixels (see {ref}`chap_filters`). The good news is that at this post-acquisition stage we can convert our data to floating point and then get fractions if we need them."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:556
msgid "Floating point rounding errors"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:559
msgid "As a full disclosure, I should admit that using floating point types is only a partial solution to rounding issues. Even a 64-bit floating point image cannot store all useful pixel values with perfect precision, and seemingly straightforward numbers like 0.1 are only imprecisely represented."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:562
msgid "But this is not really unexpected: this binary limitation is similar to how we cannot write 1/3 in decimal exactly. We can write 0.3333333 but our level of precision will depend upon our willingness to continue adding 3’s after the decimal point."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:565
msgid "In any case, rounding 0.1 to 0.100000001490116119384765625 (a possible floating point representation) is not so bad as rounding it to 0 (an integer representation), and the imprecisions of floating point numbers in image analysis are *usually* small enough to be disregarded."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:567
msgid "See <https://xkcd.com/217/> for more information."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:571
msgid "More bits are better (usually)"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:575
msgid "From considering both clipping and rounding, the simple rule of bit-depths emerges: if you want the maximum information and precision in your images, more bits are better. This is depicted in {numref}`fig-blocks_and_bits`."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:578
msgid "When given the option of acquiring a 16-bit or 8-bit image, most of the time you should opt for the former."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:586
msgid "**Illustration of the comparative accuracy of *(left to right)* 8-bit, 16-bit and 32-bit images.** If an 8-bit image is like creating a sculpture out of large building blocks, a 16-bit image is more like using Lego and a 32-bit floating point image resembles using clay. Anything that can be created with the blocks can also be made from the Lego; anything made from the Lego can also be made from the clay. This does not work in reverse: some complex creations can only be represented properly by clay, and building blocks permit only a crude approximation at best. On the other hand, if you only need something blocky, it’s not really worth the extra effort of Lego or clay. And, from a very great distance, it might be hard to tell the difference."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:598
msgid "Although *more bits are better* is a simple rule of thumb we can share with those who do not know the subtleties of bit-depths, it should not be held completely rigorously."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:600
msgid "Can you think of any circumstances when more bits might *not* be better?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:604
msgid "Reasons why a lower bit depth is *sometimes* preferable to a higher one include:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:606
msgid "A higher bit-depth leads to larger file sizes, and potentially slower processing. For very large datasets, this might be a bigger issue that any loss of precision found in using fewer bits."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:607
msgid "The amount of light detected per pixel might be so low that thousands of possible values are not required for its accurate storage, and 8-bits (or even fewer) would be enough. For the light-levels in biological fluorescence microscopy, going beyond 16-bits would seldom bring any benefit."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/bit_depths.md:609
msgid "But with smallish datasets for which processing and storage costs are not a problem, it is safest to err on the side of more bits than we strictly need."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:16
msgid "ImageJ: Types & bit-depths"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:38
msgid "The bit-depth and type of an image is determined before it is opened in ImageJ. If the data is clipped, it's already wrong before we begin -- and no amount of ImageJ wizardry will get the information back."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:42
msgid "Here, we will explore how to:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:44
msgid "Check the bit-depth and type"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:45
msgid "Diagnose when clipping may have occurred"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:46
msgid "Convert the bit-depth and height -- carefully -- if needed"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:49
msgid "Checking the bit-depth & type"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:51
msgid "Bit-depth and type are related to one another: both are needed to convert binary data into pixel values. ImageJ does not always make a careful distinction between the two."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:54
msgid "The full list of image types supported by ImageJ is found in the {menuselection}`Image --> Type --> ` submenu. The top three entries are the most important; they are"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:56
msgid "**8-bit** -- unsigned integer"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:57
msgid "**16-bit** -- unsigned integer"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:58
msgid "**32-bit** -- floating point"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:60
msgid "Although these look like bit-depths, they are listed as 'types'. But since an 8-bit and 16-bit images in ImageJ are *always* unsigned integer, and 32-bit images are *always* floating point, there is no ambiguity."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:63
msgid "You can see the type of the current image by checking which item under {menuselection}`Image --> Type` has a tick next to it. But you don't usually have to; you can also see the information at the top of the image window."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:80
msgid "The text at the top of each image window provides useful information. Here, the image on the left is 8-bit and the image on the right is 16-bit."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:84
msgid "There are various other types listed under {menuselection}`Image --> Type`, which all have an association with color. These are less different than they first appear: an RGB image is really an 8-bit image with three channels (corresponding to red, green and blue). We will explore this in {ref}`chap_colors`."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:89
msgid "Diagnosing problems"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:91
msgid "The biggest problem associated with an image's bit-depth and type is clipping. {menuselection}`Analyze --> Histogram` is the essential command needed to diagnose if something is wrong -- just press {kbd}`H` to run it."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:108
msgid "Two similar-looking images and their histograms: one clipped, one not."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:111
msgid "The main sign that an image was clipped is a big peak at either end of the histogram. This can take some careful inspection to distinguish from the black border that surrounds the histogram in ImageJ."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:114
msgid "If you know the bit-depth and type of the image, you can figure out the range (e.g. 0-255 for an 8-bit unsigned integer image, 0-65,535 for 16-bit) and usually that gives a good indication to where the peaks would be -- but it isn't a perfect guide. Conceivably, we could have an image that was clipped at some other value because it has been rescaled *after* clipping."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:121
msgid "Does the image below show signs of having been clipped?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:130
msgid "Yes! There is a small peak at the high end of the histogram, corresponding to pixel values of 4095. This is itself a suspicious number because it would be the maximum possible value in a 12-bit unsigned integer image (i.e. 2<sup>12</sup> - 1) -- so my guess is that was the bit-depth of the acquisition device."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:134
msgid "Admittedly, the image is not *very badly* clipped. We could check the proportion of pixels with that value, and use this to estimate whether it is likely that the clipping will have a significant impact upon later analysis. But it's better to avoid clipping altogether when possible."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:142
msgid "Converting images"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:144
msgid "There are three main scenarios when you might need to convert the type or bit-depth of an image:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:146
msgid "**Reducing the file size**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:147
msgid "**Converting to 8-bit to display the image in other software**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:148
msgid "Because 8-bit images are more common outside of science"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:149
msgid "**Converting to floating-point before doing image processing operations**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:150
msgid "Because (as we will see later in the book) these often require fractions and negative numbers"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:152
msgid "Note that *reversing* the effects of clipping isn't in the list: if an image is clipped during acquisition, any later conversion won't help. The clipped data is gone for good."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:155
msgid "However, you can still introduce clipping after acquisition by making ill-advised conversions -- with all the unfortunate consequences of that. Therefore it's important to know how ImageJ's type conversion works."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:159
msgid "Increasing the bit-depth"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:161
msgid "Let's start with the easy case: *increasing* the bit-depth of an image."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:163
msgid "In principle, we can convert an image just by choosing the type we want from the {menuselection}`Image --> Type -->` submenu."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:165
msgid "In ImageJ, there are only really three bit-depths and associated types. This means that the only conversions that can increase the bit-depth are:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:167
msgid "8-bit (unsigned integer) &rarr; 16-bit (unsigned integer)"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:168
msgid "8-bit (unsigned integer) &rarr; 32-bit (floating point)"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:169
msgid "16-bit (unsigned integer) &rarr; 32-bit (floating point)"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:171
msgid "Fortunately,"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:172
msgid "any 8-bit unsigned integer value can be represented in a 16-bit unsigned integer image"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:173
msgid "any 16-bit unsigned integer value can be represented in a 32-bit unsigned floating point image"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:175
msgid "Consequently, increasing the bit-depth *should* always be safe. That being said..."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:178
msgid "Always prepare for software to surprise us!"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:181
msgid "We shouldn't be complacent about image conversions, even if we think they *should* be ok. It's so easy to measure images (press {kbd}`M`), we should always check before and after conversion to make sure the summary measurements are unchanged."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:186
msgid "Reducing the bit-depth"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:188
msgid "Reducing the bit-depth is where the biggest dangers lurk. Then not all values from a higher bit-depth image fit into an image with a lower bit-depth."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:191
msgid "The process is the same: choose the type you want from the {menuselection}`Image --> Type -->` submenu."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:193
msgid "But what happens next depends upon whether the option {guilabel}`Scale When Converting` under {menuselection}`Edit --> Options --> Conversions...` is checked or not."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:195
msgid "{guilabel}`Scale When Converting` **is _not_ checked:** pixels are simply given the closest valid value within the new bit depth, i.e. there is clipping and rounding as needed."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:196
msgid "Example: If you convert an image to 8-bit, then no data will be lost *only* if every pixel value before conversion is an integer in the range 0--255. Every other value will be rounded or clipped."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:197
msgid "{guilabel}`Scale When Converting`**_is_ checked:** a constant is added or subtracted, then pixels are further divided by another constant before being assigned to the nearest valid value within the new bit depth. Only *then* is clipping or rounding applied if it is still needed."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:199
msgid "{guilabel}`Scale When Converting` is on by default and, as suggested by {numref}`fig-bits_clipping`, is usually the best option. The question then is where the constants come from to perform the rescaling."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:202
msgid "Perhaps surprisingly, they are determined from the {guilabel}`Minimum` and {guilabel}`Maximum` in the current *Brightness/Contrast...* settings: the *Minimum* is subtracted, and the result is divided by *Maximum* - *Minimum*. Any pixel value that was lower than *Minimum* or higher than *Maximum* ends up being clipped. Consequently, **converting to a lower bit-depth with scaling can lead to different results depending upon what the brightness and contrast settings were**."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:206
msgid "This means that, ideally, we would use a minimum value that is equal to the minimum pixel value in the image, and a maximum value equal to the maximum pixel value. Fortunately, there is an easy way to achieve this:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:209
msgid "Reset the Brightness/Contrast range before reducing the bit-depth"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:212
msgid "If you **really** need to reduce the bit-depth of an image in ImageJ, you should usually open {menuselection}`Image --> Adjust --> Brightness/Contrast...` ({kbd}`Shift+C`) and press the {guilabel}`Reset` button first, to minimize the data lost to clipping or rounding."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:219
msgid "Why is scaling usually a good thing when reducing the bit-depth, and why is a constant usually subtracted before applying this scaling?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:221
msgid "**Hint:** As an example, consider how a 16-bit image containing values in the range 4000–5000 might be converted to 8-bit first without scaling, and then alternatively by scaling with or without the initial constant subtraction. What constants for subtraction and division would usually minimize the amount of information lost when converting to 8-bit image, limiting the errors to rounding only and not clipping?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:226
msgid "In the example given, converting to 8-bit without any scaling would result in all pixels simply becoming 255: all useful information in the image would be lost."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:228
msgid "With scaling but without subtraction, it would make sense to divide all pixel values by the maximum in the image divided by the maximum in the new bit depth, i.e. by 5000/255. This would then lead to an image in which pixels fall into the range 204–255. Much information has clearly been lost: 1000 potentially different values have now been squeezed into 52."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:231
msgid "However, if we first subtract the smallest of our 16-bit values (i.e. 4000), our initial range becomes 0–1000. Divide then by 1000/255 and the new values become scaled across the full range of an 8-bit image, i.e. 0–255. We have still lost information – but considerably less than if we had not subtracted the constant first."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:242
msgid "Make sure that the {guilabel}`Scale When Converting` option is turned on (it should be by default). Then using a suitable 8-bit sample image, e.g. {menuselection}`File --> Open Samples --> Boats`, explore the effects of brightness/contrast settings when increasing or decreasing bit-depths."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:245
msgid "Can you destroy the image by simply 1) increasing the bit-depth, and the then 2) decreasing the bit-depth to its original value?"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:247
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?run=https://gist.github.com/petebankhead/6f9f451fdc0116197501ae504a57d5e7)"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:251
msgid "It's generally a good idea to choose {guilabel}`Reset` in the {menuselection}`Brightness/Contrast...` window before reducing any bit-depths for 2D images (see {ref}`chap_multidimensional_processing` to read about special considerations related to *z*-stacks or time series)."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/imagej.md:253
msgid "You can destroy an image by increasing its bit-depth, adjusting the brightness/contrast and then decreasing the bit-depth to the original one again. This may seem weird, because clearly the final bit-depth is *capable* of storing all the original pixel values. But ImageJ does not know this and does not check, so it will simply do its normal bit-depth-reducing conversion based on contrast settings."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:15
msgid "Python: Types & bit-depths"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:17
msgid "In this section, we will explore how bit-depths and image types are represented in Python. We'll look in particular at where things can go wrong when converting between bit-depths, and how to apply the tricks from previous chapters to identify problems."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:30
msgid "Bit-depths and dtype"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:32
msgid "The bit-depth of a **NumPy array** is encoded in its **data type** - or **dtype** for short."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:34
msgid "ImageJ is focussed on on 8-bit and 16-bit unsigned integer images, as well as 32-bit floating point images."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:36
msgid "NumPy, on the other hand, offers a much wider range of data types. The code for a Numpy dtype isn't hard to crack, with a `uint` standing for 'unsigned integer' and `float` for floating-point."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "Type"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "Bit-depth"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "dtype"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "8"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "`uint8`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "`int8`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "16"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "`uint16`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "`int16`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "32"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "`uint32`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "`int32`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "`float32`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "64"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:0
msgid "`float64`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:50
msgid "The `dtype` for any array is easy to check:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:58
msgid "We can print some basic statistics, as before. In particular, we can check that the minimum and maximum values fall inside the expected range."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:73
msgid "Fun with float32"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:75
msgid "If we want to change the type, that is easy to do as well."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:77
msgid "This makes use of the line `import numpy as np` to give us access to more NumPy properties & functions."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:83
msgid "This should convert our image into 32-bit floating point."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:85
msgid "However, when trying out a new command it is always a good idea to check it does what was expected. We can do that by showing the image and printing statistics again."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:97
msgid "That looks fine to me, but let's be extra careful and have NumPy check if the values are really identical."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:99
msgid "One way we might do that is with `==`."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:105
msgid "Hmmm, that looks quite convincing - it gives us an image that has either `True` or `False` for every single pixel. But because of the limits of what is printing, it really only shows that the pixels at the corners of our image match."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:108
msgid "If we want to ensure that *all* pixels are the same, we can use `np.all`"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:114
msgid "**Success!**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:116
msgid "But... skepticism belongs in science - particularly in image analysis - and it's always worth testing things from multiple angles, just in case. So let's check the statistics as well:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:136
msgid "Uh-oh... that was unexpected."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:138
msgid "**Somehow, we have two images with exactly the same pixel values - and yet they have a different mean value??!**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:140
msgid "It doesn't seem to make sense. We need to investigate by printing the actual values:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:147
msgid "Ok, so the means are actually very very close - and we need to go a long way after the decimal point before there is a difference."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:149
msgid "This is an example of a **precision error**."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:151
msgid "Precisions errors are common when coding, and we need to always be on our guard against them. They can occur in the midst of calculations because intermediate results aren't stored with perfect precision, but rather rounded to a value that is close."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:154
msgid "This happens both with integer and floating-point types - but of course it is more severe when working with integers. As an illustration using decimal values (since it's harder for most of us to think in binary), let's consider dividing a number by 3 and then multiplying the result by 3. Mathematically, we *should* get the same result."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:158
msgid "However, if we do our calculations using only with integers we instead see"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:160
msgid "\n"
"\\begin{align}\n"
"\\frac{10}{3}  & \\approx 3 \\\\\n"
"\\\\\n"
"3 \\times 3  & = 9\n"
"\\end{align}\n"
""
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:168
msgid "On the other hand, if we use floating point (to three decimal places for illustration) we would get"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:170
msgid "\n"
"\\begin{align}\n"
"\\frac{10}{3} & \\approx 3.333 \\\\\n"
"\\\\\n"
"3.333 \\times 3 & = 9.999\n"
"\\end{align}\n"
""
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:178
msgid "*Neither* gives the mathematically 'correct' final result of 10, because of the precision errors."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:180
msgid "Consequently, rather than checking whether non-integer values are identical with one another by using `==`, we often need to check if they are very close to one another. We can use `np.allclose` for that."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:187
msgid "Towards 8-bit"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:189
msgid "Previously, we had an image with a low bit depth and we increased the bit-depth. This was fine."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:192
msgid "Time now to go the opposite direction, and again check that it works."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:205
msgid "Oh dear. This is categorically **not** all right."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:208
msgid "Our minimum and maximum values are in the range 0-255 - which is all that's permitted in an unsigned integer, 8-bit image, so that makes sense. But the appearance doesn't make much sense at first look."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:211
msgid "Whenever we reduce the bit-depth of an image, we know that the pixel values will need to fit into the new range. In the main text, we considered two ways that could happen: by clipping or by rescaling."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:214
msgid "Here, we are meeting a slight idiosyncracy of NumPy that we really need to be careful about: *by default, it will neither clip nor rescale!*"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:216
msgid "But what *does* it do? Rather than googling or crawling around the NumPy docs, we can experiment."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:247
msgid "So it seems that NumPy *wraps around*: when converting 256 to `uint8` it becomes 0, 257 becomes 1 and so on."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:249
msgid "This means that, to convert an image to `uint8`, we need to take matters into our own hands to reduce data loss. To begin, let's clip."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:254
msgid "Converting with clipping"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:256
msgid "The trick is to clip the image this *before* converting it with `astype`:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:270
msgid "This has worked in a sense, but not a very good one. Our pixels are in the range 0-255, but recall from the histogram above that almost all the pixels were originally above 255 in value. When we clipped, these pixels all simply became 255 - and all further distinction was lost."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:276
msgid "Converting with rescaling"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:278
msgid "We can calculate the maximum possible value of an unsigned integer for a specific bit depth $N$ as $2^{N}-1$."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:280
msgid "With Numpy, we can use the `**` operator for this."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:290
msgid "Therefore, to convert our 16-bit image to 8-bit by rescaling, we could multiply the pixel values by the ratio of these maximum values, i.e. by $\\frac{255}{65535}$"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:305
msgid "This has *kind of* worked, but note that the maximum pixel value is very low. We have lost a *lot* of information: squeezing our values into a very small range of integers, much less than the full 256 available to us."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:308
msgid "Ideally, we would usually like to rescale our image while preserving as much of the information as possible. We would like the values in our output image to fill the full range of 0-255."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:311
msgid "We can do this in five steps:"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:312
msgid "Convert the image to floating point (so that we don't lose info to rounding)"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:313
msgid "Subtract the minimum value, so that the minimum becomes zero"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:314
msgid "Divide by the new maximum value, so that the maximum becomes one"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:315
msgid "Multiply by 255"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:316
msgid "Convert to 8-bit"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:334
msgid "As conversions to 8-bit go, rescaling certainly looks like it was more successful than simply clipping, and the output fills the full range available."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:336
msgid "Nevertheless, **don't forget that the statistics are different, and we have changed the pixel values!**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:338
msgid "Therefore this isn't something we should do without a very good reason."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:342
msgid "Summary"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:344
msgid "**The key message here is that it is very easy to change the bit-depth and type of an image - but also very easy for things to go wrong.**"
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:346
msgid "Sometimes these are small precision errors. Sometimes they are big, data, destroying errors."
msgstr ""

#: ../../chapters/1-concepts/3-bit_depths/python.md:349
msgid "But if you know how to show images, make measurements and generate histograms, you can always check what is happening to the data at each step. This can help you make sure nothing is being lost along the way."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:16
msgid "Channels & colors"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:21
msgid "Images with multiple **color channels** may display differently in different software"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:22
msgid "**RGB images** are a special case, and generally look consistent across different software"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:23
msgid "In ImageJ, multichannel images that are not RGB may be referred to as **composite images**"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:24
msgid "**Converting images to RGB often loses information!**"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:45
msgid "One way to introduce color into images is to use a suitable LUT, as described in {ref}`chap_pixels`. Then the fact that different colors could be involved in the display of such images was really only incidental: at each location in the image there was still only one channel, one pixel and one value."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:48
msgid "There are images for which color plays a more important role. We will consider two types:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:50
msgid "**RGB images** -- which are widely used for display, but are *usually* not very good for quantitative analysis"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:51
msgid "**Multichannel / composite images** -- which are often better for analysis, but need to be converted to RGB for display"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:53
msgid "Since they often *look* the same, but behave very differently, knowing which kind of color image you have is important for any scientific work."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:57
msgid "Mixing red, green & blue"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:59
msgid "We previously discussed how image LUTs provide a way to map pixel values to colors that can be displayed on screen. Now that we've looked at image types and bit-depths, we can expand a bit more on how that works in practice."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:62
msgid "In general, each color is represented using three 8-bit unsigned integers: one for **r**ed, one for **g**reen, one for **b**lue. Each integer value defines how much of each primary color should be mixed together to create the final color used to display the pixel."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:65
msgid "In the case of a grayscale LUT, the red, green and blue values are all the same:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:129
msgid "Other LUTs may include only one color, with the others set to zero:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:137
msgid "However for most LUTs the red, green and blue values differ:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:147
msgid "Because each of the red, green and blue values can be in the range 0-255, mixing them together can generate (theoretically at least) up to 256 x 256 x 256 = 16,777,216 different colors, i.e. a *lot*."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:149
msgid "When it comes to display, this method of representing color using 8-bit RGB values should easily give us many more colors than we could ever hope to distinguish by eye. We don't need a higher bit-depth for display."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:154
#: ../../chapters/1-concepts/4-colors/python.md:31
msgid "RGB images"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:156
msgid "Until now we have considered images where each pixel has a single value, and there is an LUT associated with the image to map these values to colors."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:158
msgid "Now that we know how colors are represented, we can consider another option."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:160
msgid "Instead of storing a single value per pixel, we can store the RGB values that represent the color used to display the pixel instead. Each pixel then has three values (for red, green and blue), not just a single value."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:163
msgid "When an image is stored in this way it's called an **RGB image**."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:165
msgid "We can easily create an RGB image from any combination of image + LUT: just replace each pixel value in the original image with the associated RGB values that we find in the LUT. Now each pixel has three values instead of one, but the end result *looks* exactly the same."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:170
msgid "The risk of RGB"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:172
msgid "The problem with converting an image to RGB is that, in general, *we can't go back!* In fact, the unwitting *overuse* of RGB images is one of the most common sources of data-destroying errors in some branches of scientific imaging."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:176
msgid "Beware converting to RGB!"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:179
msgid "Converting an image to RGB is another way lose our raw data."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:182
msgid "{numref}`fig-colors_im_grays_rgb` shows this in action. In the 'least destructive' case, the image has a grayscale LUT. This means that the red, green and blue values are identical to one another -- but *not* necessarily identical to the pixel values of the original image. We have converted the data to 8-bit and used the LUT to determine how much to scale during the conversion."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:187
msgid "In general, it's not possible to recover the original pixel values from the RGB image: we probably don't know exactly what rescaling was applied, and we have lost information to clipping and rounding."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:248
msgid "Converting a grayscale image to RGB can lose information. We can separate out the red, green and blue values from the RGB image and visualize each as separate images to explore the information they contain. Even though the RGB image looks unchanged from the original, and all three color channels have similar histograms to the original, the bit-depth has been reduced and image statistics modified. There is also a big histogram peak that indicates substantial clipping."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:254
msgid "The impact of converting an image with any other LUT to RGB is even more dramatic, as shown in {numref}`fig-colors_im_rgb`. Here, the red, green and blue values are different and the histograms for each color are very different. Again, it would not be possible to recover the original pixel values from the RGB image."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:319
msgid "Converting an to RGB can lose information in a particularly dramatic way if the LUT is not grayscale. The histograms for each channel may now look completely different."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:324
msgid "The role of RGB"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:326
msgid "Using RGB images for display"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:328
msgid "So what's the point of having RGB images, if they are so risky?"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:330
msgid "One of the biggest reasons to use RGB images in science is for presentation. While specialist image analysis software applications, such as ImageJ, are typically designed to handle a range of exotic image types and bit-depths, the same is not true for non-scientific software."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:333
msgid "If want want an image to dispay exactly the same in ImageJ as in a PowerPoint&reg; presentation or a figure in a publication, for example, we'll probably want to convert it to RGB. If we don't, the image might display very strangely on other software -- or even not open at all."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:336
msgid "'Why is my image just black?'"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:340
msgid "Over the years, I have encountered a remarkable number of cases where a researcher has saved their fluorescence microscopy images *only* in an RGB format."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:342
msgid "Their justification was that they tried saving the images in different way at the microscope, but *'it didn't work -- the images were all black'*."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:344
msgid "The explanation is almost invariably that their images were really 16-bit or 32-bit, but they tried to open them in software that doesn't handle 16-bit images very well (e.g. they just double-clicked the file to open it in the default image viewer). All they saw as a black, seemingly-empty image."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:347
msgid "Whenever they tried exporting from the microscope's acquisition software in different ways, they found an option that gave a viewable image -- and stuck with that."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:349
msgid "The problem with this is that it usually meant that *they didn't save their raw data at all!* They *only* saved an RGB copy, with all the rescaling and LUT magic applied, which is wholly unsuitable for analysis."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:352
msgid "The solution is to view images in ImageJ, or similar scientific software. This usually reveals that the image is not 'all black' after all. Rather, one only needs to adjust the brightness and contrast (using the LUT) to see the raw data in all its glory."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:359
msgid "When RGB is all you've got"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:361
msgid "All the previous comments about *'don't convert to RGB before analysis'* as based on the assumption that your raw data isn't already RGB. This is usually the case with microscopy and medical imaging whenever accurate quantification is important."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:364
msgid "Nevertheless, it's not *always* the case."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:366
msgid "A common example is brightfield imaging for histology or pathology. Here, the camera is often RGB and an RGB image is really as close to the raw data as we are likely to get."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:374
msgid "Example RGB histology image, from https://openslide.org"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:377
msgid "Crucially, the analysis of brightfield images in histology usually aims to replicate (and sometimes improve upon) the visual assessment that a pathologist might make looking down a microscope. It's often based on detecting, classifying and counting cells, measuring stained areas, or recognizing the presence of particular patterns -- but *not* accurately quantifying staining intensity."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:382
#: ../../chapters/1-concepts/4-colors/python.md:147
msgid "Multichannel images"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:384
msgid "So far, we have focussed on 2D images with a **single channel** -- that is, a single value for every pixel at every *x,y* coordinate in the image."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:386
msgid "Such images can be converted to 8-bit RGB using a LUT. If we do this, then we get an image with **three channels**, where each channel is displayed using red, green and blue LUTs -- with the colors blended together for display. But we shouldn't do that conversion prior to analysis in case we lose our raw data."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:390
msgid "Now, we turn to consider **multichannel images** that aren't RGB images. Rather, the raw data itself has multiple channels."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:393
msgid "In fluorescence microscopy, it's common to acquire multichannel images in which pixel values for each channel are determined from light that has been filtered according to its wavelength. We *might* choose to visualize these channels as red, green and blue, but we don't have to."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:396
msgid "In principle, any LUT might be applied to each channel, but it makes sense to choose LUTs that somehow relate to the wavelength (i.e. color) of light detected for the corresponding channels. Channels can then be overlaid on top of one another, and their colors further merged for display (e.g. high values in both green and red channels are shown as yellow)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:399
msgid "The important feature of these images is that the actual channel information is always retained, and so the original pixel values remain available. This means we can still extract channels or adjust their LUTs as needed."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:440
msgid "Multichannel image using red, green and blue LUTs. Although this looks a lot like an RGB image, each channel still contains the raw data (which might be 16-bit or 32-bit). The original pixel values can be extracted if needed, and different LUTs used."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:449
msgid "Multichannel image from {numref}`fig-colors_composite_rgb` using different LUTs. Again, no information is lost: we can access the original pixel values, and update the LUTs if needed."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:453
msgid "Just like with a single channel image, we can create an RGB image that allows us to visualize our multichannel image -- using the LUTs to figure out which RGB values are needed to represent the color of each pixel."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:455
msgid "Then, again just like with the single channel image, this is problematic if we don't keep the raw data -- because we can never recover the original values from the RGB representation."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:462
msgid "We can create an RGB image from {numref}`fig-colors_composite_non_rgb`, but then we have three channels locked to red, green and blue -- which have converted the original channels to 8-bit, and mixed up information due to the LUT colors used. We can no longer recover the original pixel values after converting to RGB."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:467
msgid "Summary of color images"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:469
msgid "The main message here can be distilled into two rules:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:472
msgid "**Always use the original image for analysis**"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:473
msgid "If the raw data isn't RGB, then don't convert it before analysis!"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:474
msgid "**Create an RGB copy of your image for display**"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:475
msgid "Keep the RGB copy separate, so you always retain it *and* the raw image"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:478
msgid "RGB images aren't *bad* -- we almost always need them for display, and for *some* imaging applications (e.g. brightfield histology) they are the best raw data we can get. But we need to be cautious if our raw data isn't RGB, and avoid converting to RGB too early."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:481
msgid "In the end, it's normal to keep at least two versions of each dataset: one in the original (possibly multichannel) format, and one as RGB for display. This RGB image is normally created as the _final_ step, after applying any processing or LUT adjustments to the original data."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:486
msgid "Other color spaces"
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:488
msgid "Color is a big topic, and there is a lot more that could be said about different color spaces and transformations. However, these are mostly relevant when working with data that is originally RGB."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:491
msgid "For example, we could convert an RGB image to an *HSB* representation, where HSB stands for *Hue*, *Saturation* and *Brightness*. This is useful to separate hue from brightness, e.g. to help identify all red pixels regardless of whether they are bright or dark."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:494
msgid "Alternatively, we could convert an RGB image to *CMYK*, which stands for *Cyan*, *Magenta*, *Yellow* and *blacK* -- which may be a better fit for printers than monitors."
msgstr ""

#: ../../chapters/1-concepts/4-colors/colors.md:496
msgid "But I personally haven't found such transforms very relevant to the areas of bioimage analysis in which I have worked. I have tried to focus here on the main need-to-know topics that impact analyzing scientific images. With this in mind, I think that understanding RGB (and its limitations) is crucial -- while other transforms can be picked up later if they are needed."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:16
msgid "ImageJ: Channels & colors"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:36
msgid "ImageJ has good support for both RGB and multichannel images, but the behavior is not always obvious. This section explains the ideas, including common areas of confusion."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:40
msgid "RGB vs. Multichannel"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:42
msgid "ImageJ treats RGB as a special image type, even though it is still [8-bit unsigned integer](chap_bit_depths_imagej). There are several ways to recognize that an image has the type 'RGB':"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:44
msgid "The text *RGB* appears at the top of the image window"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:45
msgid "{menuselection}`Image --> Type --> RGB Color` is selected"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:46
msgid "When moving the cursor over the image, there are *three* values shown in the status bar (e.g. *value=127,127,127*) instead of one"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:48
msgid "Multichannel images that *aren't* RGB are recognizable because they have an extra slider at the bottom, with a small {guilabel}`C` label, which is used to switch the 'active' channel. The {menuselection}`Image --> Type --> ` will be {menuselection}`8-bit`, {menuselection}`16-bit` or {menuselection}`32-bit`."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:65
msgid "A multichannel image (left) and RGB image (right). The colors used to display the image are identical, but other aspects of the image window indicate that the images themselves are quite different."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:69
msgid "The distinction is really important when it comes to measurements and histograms, because the behavior between RGB and multichannel images is subtly different:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:71
msgid "**Multichannel images:**"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:72
msgid "{menuselection}`Analyze --> Measure` uses the active channel only, based on the {guilabel}`C` slider"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:73
msgid "{menuselection}`Analyze --> Histogram` uses either uses the active channel only or all channels, after prompting the user to choose"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:74
msgid "{menuselection}`Image --> Adjust --> Brightness/Contrast...` can be used to adjust the brightness & contrast for the active channel"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:75
msgid "It is possible to change LUTs independently for each channel"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:76
msgid "**RGB images:**"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:77
msgid "{menuselection}`Analyze --> Measure` converts the image to have a single 8-bit channel before making measurements"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:78
msgid "{menuselection}`Analyze --> Histogram` creates a histogram after converting the image as above, but also provides an {guilabel}`RGB` button to also view separate histograms for the red, green and blue channels"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:79
msgid "{menuselection}`Image --> Adjust --> Brightness/Contrast...` can only be used to adjust the brightness & contrast for all channels simultaneously"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:80
msgid "It is *not* possible to change LUTs per channel"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:82
msgid "When it comes to measuring an RGB image, the enigmatic statement above that ImageJ 'converts the image' is explained (in more detail than you might want) [at the end](sec_colors_converts)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:89
msgid "Explore several of the images under {menuselection}`File --> Open Samples -->` and identify which are treated by ImageJ as RGB, which as multichannel, and which have just a single channel. There is only one correct answer per image."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:92
msgid "**Note 1:** Here, 'RGB' means that ImageJ treats the image has having the special 'RGB' image type. It's possible for a multichannel image to have three channels with red, green and blue LUTs, but Imagej doesn't consider it to be RGB. You should therefore use the rules given above to distinguish images RGB from multichannel."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:96
msgid "**Note 2:** At the time I write this, the sample images don't work for me properly in Fiji -- but they do work in ImageJ. Hopefully the Fiji bug will be fixed before you read this."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:108
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/launch-imagej-js-badge.svg)](https://ij.imjoy.io)"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:125
msgid "There are several awkward images:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:127
msgid "{menuselection}`HeLa Cells (48-bit RGB)` is *not* treated as having the RGB type... and ImageJ doesn't have a '48-bit' type either! Here, 48-bit RGB means that we actually have three 16-bit channels with red, green and blue LUTs. For ImageJ, that's not really an RGB image, it's a multichannel image. Don't expect too much consistency in naming: always check the types!"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:128
msgid "{menuselection}`Fly Brain` has a slider, but it doesn't have a {guilabel}`C` label. This is because the slider isn't for channels, but rather for *z*-slices. We will meet *z*-slices in the [next chapter](chap_dimensions)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:129
msgid "{menuselection}`Image with Overlay` looks colorful, but the colors all come from the [overlay](sec_imagej_overlay) -- not from the image being RGB. Admittedly, the name helps here."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:136
msgid "Working with channels"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:138
msgid "There are several useful commands for working with color channels under {menuselection}`Image --> Color --> `. Some of these, such as {menuselection}`Image --> Color --> Split channels` and {menuselection}`Image --> Color --> Merge channels` are quite intuitive, and work for both RGB and multichannel images."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:141
msgid "One of the most useful commands that requires some explanation is {menuselection}`Image --> Color --> Channels Tool...` {kbd}`Shift+Z`. If you run the {menuselection}`Channels Tool...` command for an RGB image and try to do anything, ImageJ will ask"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:146
msgid "Agreeing to the prompt will convert the RGB image to a multichannel image."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:148
msgid "The question might be a little bit confusing because 'composite' and 'multichannel' do not quite mean the same thing, although they are sometimes used interchangeably with ImageJ. To be more precise, a 'composite image' in this context is a multichannel image that is displayed using a particular **display mode**."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:151
msgid "ImageJ has three main modes for displaying multichannel images, accessible from the drop-down menu of the *Channels Tool* dialog:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:152
msgid "{guilabel}`Composite` -- Merge some or all the channels together for display. Currently, this works with up to 7 or 8 channels (depending on software version; an extra one was added recently). Individual channels can be turned on and off."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:153
msgid "{guilabel}`Color` -- View the 'active' channel only, using its original color LUT. You can switch the channel with the slider below the image."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:154
msgid "{guilabel}`Grayscale` -- Similar to {guilabel}`Color`, except always using a grayscale LUT."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:156
msgid "Whenever a channel is active, the LUT can be changed using options in the *Channels Tool* dialog -- or the {menuselection}`Image --> Lookup Tables --> ` submenu as usual. Similarly, {menuselection}`Image --> Adjust --> Brightness/Contrast...` works on the active channel to update the LUT."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:176
msgid "ImageJ multichannel image sample *Fluorescent Cells*. Using the {menuselection}`Image --> Color --> Channels Tool...` and the slider at the bottom of the window, you can view the channels individually or simultaneously."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:181
msgid "The way in which {guilabel}`Composite` mode works is that an RGB image is effectively created for each channel based on its LUT, and the red, green and blue values are *added* together to get the final output color (clipping at 255 if needed)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:183
msgid "This isn't the only way to generate a composite image, and it doesn't work well for all LUTs -- particular LUTs that map low pixel values to bright colors or white."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:185
msgid "Therefore, since ImageJ 1.53o some additional composite modes were added to the {menuselection}`Channels Tool...`, and refined over the next few releases after a long (and occasionally testy) discussion on image.sc. At the time of writing, the available modes are:"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:187
msgid "{guilabel}`Composite Max` -- Similar to {guilabel}`Composite`, except use the *maximum* of the red, green and blue values across all channels (not the sum)"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:188
msgid "{guilabel}`Composite Min` -- Similar to {guilabel}`Composite Max`, except use the *minimum* of the red, green and blue values across all channels (not the maximum)"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:189
msgid "{guilabel}`Composite Invert` -- Similar to {guilabel}`Composite`, except *subtract* the red, green and blue LUT values instead of adding them"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:191
msgid "Both {guilabel}`Composite Min` and {guilabel}`Composite Invert` are useful for LUTs with light backgrounds, therefore if you select one of these options ImageJ may flip a LUT to have a light background if needed."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:210
msgid "Visualizing the new composite modes."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:213
msgid "Be careful with composites!"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:216
msgid "Any new visualization modes have the potential to cause confusion or to be abused. Although the new composite modes can be useful, I advise caution."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:219
msgid "The original {guilabel}`Composite` mode is really well established, and is the default. If you use any of the 'new' composite modes in a figure for publication, you should clearly specify which."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:232
msgid "Choosing channel colors"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:235
msgid "By changing the LUTs, channels can be assigned any color you like. Although red/green images are widespread, especially for colocalization, they are particularly unhelpful for colorblindness. More accessible images can be created by switching the LUTs of at least one channel to something more suitable (e.g. Red &rarr; Magenta) – although displaying both channels separately is better still."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:239
msgid "You can also test the effects of different colors using the Fiji command {menuselection}`Image --> Color --> Simulate Color Blindness` (note that this may require converting the image to RGB first)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:241
msgid "More information about generating figures with suitable colors is available at <https://www.nature.com/articles/nmeth.1618>."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:247
msgid "Converting to RGB"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:249
msgid "As described in {ref}`chap_colors`, one of the most important uses of RGB images is to create a compatible image for display in different software. We will see more about how to save such images in {ref}`chap_files`."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:252
msgid "It should be possible to convert any image to RGB using {menuselection}`Image --> Type --> RGB Color`. However, my preferred way to create an RGB image for display is usually {menuselection}`Image --> Overlay --> Flatten` {kbd}`Shift+F`. This not only converts the image, but also incorporates any ROIs or overlays into the RGB version. Flattening is similar to taking a screenshot of the image as it currently appears, except unaffected by the current zoom level or field of view."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:264
msgid "ImageJ has two different copying commands, {menuselection}`Edit --> Copy` and {menuselection}`Edit --> Copy to System`. Why?"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:267
msgid "**Note:** When investigating this, you should explore {menuselection}`Edit --> Paste`, alongside two commands in the {menuselection}`File --> New -->` submenu. Be on the lookout for any conversions."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:274
msgid "{menuselection}`Edit --> Copy` allows you to copy part of an individual image slice (i.e. a 2D part of a particular color channel) and paste it into another image while exactly preserving the original image type and pixel values. You can also use {menuselection}`File --> New --> Internal Clipboard` to get the copied region (but {menuselection}`Image --> Duplicate...` is usually a better option). However, this image type might well not be compatible with other software, therefore images copied in this way cannot be accessed outside ImageJ."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:278
msgid "{menuselection}`Edit --> Copy to System` is needed if you want to copy an image to the system clipboard so that it can be pasted into other software. However, be warned that this converts the image to RGB in the process. If therefore preserves the image appearance, but not necessarily the pixel values."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:293
msgid "You can test the compatibility of composite and RGB images by opening {menuselection}`File --> Open Samples --> HeLa Cells` image, and saving it using {menuselection}`File --> Save As --> Tiff...` both before and after running {menuselection}`Image --> Type --> RGB Color` to convert the original 16-bit composite data to RGB."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:295
msgid "Try then opening both saved images in other software (e.g. Microsoft PowerPoint&reg;) and compare their appearance."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:297
#: ../../chapters/1-concepts/5-pixel_size/imagej.md:304
#: ../../chapters/2-processing/3-thresholding/imagej.md:250
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?run=https://gist.github.com/petebankhead/a45e4eed3a90b6374ec7b272db090ec9)"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:309
msgid "Think of at least 2 ways in which converting a composite image to RGB can lose information."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:311
msgid "You can explore this by comparing the images *Neuron-composite.tif* and *Neuron-RGB.tif*. The {menuselection}`Image --> Color --> Split Channels` command should help."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:315
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/Neuron-composite.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/Neuron-RGB.tif)"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:323
msgid "One way that converting an image to RGB can lose information is if the original data is 16-bit before conversion and 8-bit afterwards, causing rounding and/or clipping to occur (see {ref}`chap_bit_depths`)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:325
msgid "Another is that during conversion the channels have been forced to be purely red, green and blue. But perhaps they were not originally so, and separate channels have been merged into the same ones. If you had started with more than three channels, this will definitely have occurred, but even if you had fewer channels you can have problems (like in the *Neuron_composite.tif* and *Neuron_RGB.tif* examples)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:329
msgid "The trouble with _only_ having an RGB image is that it is no longer possible to know for sure what the original data looked like, to be able to figure out whether anything has been lost. For example, perhaps you have managed to generate a magnificent image consisting of turquoise, yellow and dazzling pink channels. Each pixel is displayed on screen as a combination of those colors. However, precisely the same color for any pixel can also be represented -- rather more simply -- as a mixture of red, green and blue. So no matter what channels and colors you began with, the final result after merging can be replicated using red, green and blue channels. But if you _only_ have the RGB version, you might never be able to extract the original 3 channels again. Their colors could be so mixed together that the original pixel values would be irretrievably lost."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:337
msgid "And so the good things about RGB images are that they look identical to the original image you had before conversion, and other software (e.g. webbrowsers or PowerPoint&reg;) can understand them effortlessly. But the _potentially very bad_ thing about RGB images is that creating them requires conversion, and after this it might very well be _impossible_ to regain the original pixel values."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:346
msgid "How RGB images are converted / How I find out what I can't remember"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:348
msgid "When describing how {menuselection}`Analyze --> Measure` handles RGB image, I said that it converts the image first."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:350
msgid "'Converts the image' is a fairly vague statement for a very good reason: I only have a vague awareness of how it works, because I've never needed to know it. RGB images aren't good for quantification anyway, so I don't often have any reason to measure pixel values within them."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:353
msgid "I admit this to give reassurance that there's a good chance you don't need to know it either. So if you find the rest of this box confusing, don't worry."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:356
msgid "**However,** it also gives an opportunity to make a bigger point: there are too many intricacies within ImageJ to remember all of them. And that's fine. I believe that a far more important skill is knowing how to investigate what is happening."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:360
msgid "And so here is how I set about understanding what 'converts the image' means."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:362
msgid "Firstly, I created an RGB image with 50x50 pixels known values for red (0), green (100) and blue (200)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:366
msgid "**If** the conversion is simply averaging the red, green and blue values then I would expect the result of running {menuselection}`Analyze --> Measure` to be 100 (since that is the mean of 0, 100 and 200). When I tested it, I found that was the case. I tried some other values, and they all behaved the same way: it appears that conversion is simply averaging the channels."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:370
msgid "I then hypothesised that I should get the same thing if I use {menuselection}`Image --> Type --> 8-bit`. So I tried that out, and again it matched expectations."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:373
msgid "So I concluded that {menuselection}`Analyze --> Measure` was quietly calling {menuselection}`Image --> Type --> 8-bit` on a copy of the image, and then measuring *that*."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:375
msgid "Or maybe it's calling {menuselection}`Image --> Type --> 32-bit` instead?"
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:377
msgid "I needed a new image that would show the effects of rounding, so I added 1 to the blue channel, making its values 201."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:381
msgid "I then tried {menuselection}`Image --> Type --> 32-bit`, which gave the expected average of 100.33. But {menuselection}`Image --> Type --> 8-bit` still gave 100 per pixel -- because it is limited to integers. And {menuselection}`Analyze --> Measure` also gave me 100 -- which suggest that it converts the RGB images to 8-bit, not floating point, when making its measurements."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:385
msgid "Finally, I remembered that ImageJ sometimes sneaks in extra options. So I opened {menuselection}`Edit --> Options --> Conversions...` and found a checkbox for {menuselection}`Weighted RGB conversion`. If I selected it, and repeated the steps above I got quite different answers -- because it no longer converts using a straight 'average of the 3 channels'. Rather, each channel is weighted: 0.30 x Red + 0.59 x Green + 0.11 x Blue."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:390
msgid "Pondering the weights took me down a googling rabbit hole to see these are (somewhat) standard weight values for grayscale image conversion used across different software. But, more importantly, I saw that the {menuselection}`Weighted RGB conversion` option affected *both* measurement and conversion -- supporting my suspicion that they are connected."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:393
msgid "Confused? Me too."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:396
msgid "**But** my main point is that mortals like me can't predict what software is going to do. Even if we think we know, there's a chance some sneaky option somewhere is changing the behavior."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:399
msgid "What we *can* do is foster a critical mind. We can learn enough about the software to know how to test what it is doing."
msgstr ""

#: ../../chapters/1-concepts/4-colors/imagej.md:402
msgid "And that, at least, is how I learned to use ImageJ and came to write this book."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:15
msgid "Python: Channels & colors"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:17
msgid "This section gives a brief overview of some color-related considerations when using Python."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:19
msgid "See the [scikit-image color module](https://scikit-image.org/docs/dev/api/skimage.color.html) for a lot more useful info."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:33
msgid "Let's begin by reading the RGB image used on the title page of this book."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:43
msgid "If we check the shape of the image, we can see that the RGB information seems to be joined on at the end: the shape is in the form `[rows, columns, channels]`."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:49
msgid "RGB to single-channel"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:51
msgid "We can convert an RGB image to a single-channel image in lots of ways."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:53
msgid "A single-channel image is often referred to as **grayscale** - although whether it is actually displayed using shades of gray or not depends upon the colormap."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:55
msgid "Split channels"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:57
msgid "One option is to split the RGB channels to give three separate single-channel images."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:78
msgid "Averaging channels"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:80
msgid "A second easy option is to simply calculate the average (mean) of the RGB values."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:91
msgid "However, it is common to calculate a *weighted* mean of the RGB values. Commonly the weights are"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:94
msgid "0.2125 R + 0.7154 G + 0.0721 B"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:96
msgid "This is what scikit-image's [`rgb2gray`](https://scikit-image.org/docs/stable/api/skimage.color.html#skimage.color.rgb2gray) does, as described [here](https://scikit-image.org/docs/stable/auto_examples/color_exposure/plot_rgb_to_gray.html)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:108
msgid "To be fair, the simple mean and the weighted mean images don't look very different to me."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:110
msgid "To check if they really *are* different, we can show one subtracted from the other."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:118
msgid "Hmmmmm, this looks very suspicious. The fact the *difference* image looks the same suggests to me that some rescaling might have happened."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:121
msgid "So let's go back to checking the `dtype` comparing statistics."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:129
msgid "Right, that seems to suggest that `rgb2gray` has also rescaled our image during conversion."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:131
msgid "Indeed, it's reasonably common to work with 8-bit RGB images in Python (`uint8`) with values in the range 0-255, but it's perhaps even more common to work with floating point RGB images in the range 0-1 (either `float32` or `float64`). So we do need to be on the lookout for sneaky conversions."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:134
msgid "With that in mind, we can make our images comparable my dividing our `im_mean` by 255."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:143
msgid "This demonstrates that the pixel values are at least a bit different when converted using the weighted mean."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:149
msgid "Working with multichannel (non-RGB) images in Python is extremely easy in some ways, and very awkward in others."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:151
msgid "Although because most of the awkward stuff comes at the start, that will dominate the rest of this section."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:153
msgid "For example, even just opening the data properly can be a challenge."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:156
msgid "Reading multichannel images"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:158
msgid "I like using [imageio](https://imageio.readthedocs.io/en/v2.9.0/userapi.html) to read images for its simplicity. However, if we rely upon `imageio.imread` for a multichannel tiff, we tend to just get the first channel."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:161
msgid "Later chapters will show other ways to open images."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:172
msgid "We can do better if we switch to `imageio.volread` to treat the image as a volume instead."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:182
msgid "The trouble now is that the channels appear at the *start* of our shape, whereas for the RGB image the channels were at the end."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:184
msgid "That may or may not matter - *because Python doesn't have a completely fixed convention for where the channels should be*."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:186
msgid "Some libraries assume 'channels-first', and some assume 'channels-last'."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:188
msgid "The good news is that, if you know what's required, you can easily move the channels to the right place."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:198
msgid "Displaying multichannel images"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:200
msgid "Unfortunately, you can't easily show any arbitrary multichannel image using either channels-first or channels-last."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:214
msgid "Let's focus on channels-last, since it's more similar to how the RGB images behaved."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:216
msgid "We can show the channels one by one, as in the RGB case, or average the channels if we like - although the mean we get probably won't be a very meaningful mean."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:249
msgid "Adding color"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:251
msgid "Unfortunately, we don't currently have any of the color information that could be used to display each channel. We can just choose a colormap, like with any other single-channel image, but we can't easily visualize channels merged together (at least with matplotlib... as far as I know)."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:254
msgid "But one this we *can* do is convert each of our channels to RGB, using a fixed color. Here is a helper function to do that."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:293
msgid "Creating composites"
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:295
msgid "Having done that, we can simply add our RGB images together to create a composite image - remembering to clip the result, so that we keep inside the range 0-1."
msgstr ""

#: ../../chapters/1-concepts/4-colors/python.md:297
msgid "**Important!** We've moved away from colormaps here to change pixel values when creating RGB images. This gives us more control, but we need to remember that none of these modified images are suitable for quantitative analysis."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:15
msgid "ImageJ:  Pixel size & dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:34
msgid "This section will explore pixel sizes and dimensions in ImageJ. Along the way, we will see how to generate scale bars and fix images where the pixel size or dimensions are incorrect -- at least whenever we know what the correct values are."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:37
msgid "Pixel sizes & Properties"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:39
msgid "You can see the pixel size for an image in ImageJ under {menuselection}`Image --> Properties...`. These are provided separately as values for {guilabel}`Pixel width` and {guilabel}`Pixel height`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:43
msgid "A **voxel** is the 3D analogue of a pixel; a 'volume pixel'."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:46
msgid "There is also an additional value, {guilabel}`Voxel depth`, which is only relevant for *z*-stacks; this gives the spacing between *z*-slices."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:54
msgid "Image properties for the *Confocal Series* sample, which include the pixel size."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:57
msgid "If the pixel size information is unavailable, the pixel sizes are given as 1 pixel: not terribly informative. Otherwise, the pixel sizes are given in the units displayed nearby in the properties dialog."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:66
msgid "Image properties for the *Fluorescent Cells* sample, which do not include useful pixel size information."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:69
msgid "The pixel width and height are *usually* the same. The voxel depth (where relevant) is often different."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:77
msgid "One way to check if the pixel size information is set for an image is to use {menuselection}`Image --> Properties...`"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:79
msgid "How else can you check this, even more easily?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:81
msgid "**Tip:** The answer should already be visible in {numref}`fig-properties_confocal` and {numref}`fig-properties_fluorescent`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:85
msgid "The size of the image is given at the top of each image window. If the pixel size information is available, this is given in calibrated units. Otherwise, it is given only in pixels."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:92
msgid "Pixel sizes & measurements"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:94
msgid "As [described before](sec_imagej_measure_calibration), the pixel size influences measurements in ImageJ -- but the units don't appear anywhere in the *Results table*. Furthermore, once a measurement is added to the *Results table* it is fixed: it won't automatically update if the pixel sizes are changed later."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:97
msgid "For that reason, you need to be careful to check pixel sizes *before* making any measurements and make sure it's clear to you which units have been used."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:105
msgid "The same ROI (here, a 100 x 100 pixel square) can appear to have a different area if it is measured on images that have different pixel sizes. The measurement is converted before being added to the *Results table*, but the units are not included."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:110
msgid "Setting the pixel size"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:112
msgid "If the pixel size information is missing, but you know what it should be, you can simply enter the required width and height values in the *Properties...* dialog box."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:114
msgid "Typing µm"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:118
msgid "Depending upon your computer, typing µm for the units might be tricky. Fortunately, typing *um* works as well -- ImageJ automatically converts *um &rarr; µm*."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:122
msgid "If you don't know what the pixel size should be, but you *do* know the length of some structure in your image, then you can"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:123
msgid "Draw a line along the known structure with the line tool <img src=\"../../../images/imagej/icons/line.png\" />"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:124
msgid "Run {menuselection}`Analyze --> Set Scale...`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:126
msgid "This will automatically populate the {guilabel}`Distance in pixels` based upon the length of the line. You can then input the known physical length and units, then click {guilabel}`OK`. You should check {menuselection}`Image --> Properties...` to confirm that the values have been updated sensibly."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:136
msgid "Setting the pixel size in an image by inserting the length of a known structure."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:139
msgid "Using *Set Scale...*"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:142
msgid "Ideally, {menuselection}`Analyze --> Set Scale...` would be used with a calibration slide to establish the pixel sizes reliably. The values can then be transferred to other images acquired with the same settings using {menuselection}`Image --> Properties...` (or a [macro](chap_macro_intro))."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:145
msgid "Beware that, if you have drawn a line as described above, the {guilabel}`Distance in pixels` value is initialized from that line -- so *don't* change that. Rather, *do* change the {guilabel}`Known distance` and {guilabel}`Unit of length` values according to the physical length indicated by the line."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:148
msgid "If the {guilabel}`Unit of length` should be *µm* but your keyboard lacks a *µ*, you can type *um* instead."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:151
msgid "Showing a scale bar"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:153
msgid "It's generally good practice to include a scalebar in any figures. This is only really meaningful if the pixel sizes are set correctly within the image properties."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:156
msgid "You can create a scalebar using {menuselection}`Analyze --> Tools --> Scale Bar...`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:164
msgid "Setting a scale bar as an overlay."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:167
msgid "There are several options that can be used to adjust the appearance of the scalebar. One of the most important is the {guilabel}`Overlay` option, because this determines whether the scalebar is 'burned in' to the image (i.e. the pixel values are modified) or if it's instead added as a (text) ROI as part of the image overlay."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:170
msgid "My advice is to always add the scalebar as an overlay. That means you can remove it again, or adjust its appearance. The only disadvantage is that, if you save the image immediately, it might not appear in other software. The solution is to [generate an RGB image](sec_imagej_flatten) that includes the overlay as a final step before saving, by using {menuselection}`Image --> Overlay --> Flatten`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:176
msgid "Stacks & Hyperstacks"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:178
msgid "2D images have been around since the beginning. Then ImageJ supported **stacks**, which allowed an extra dimension that could either include different time points or *z*-slices -- but not both. Nowadays, **hyperstacks** are the more flexible derivative of stacks, and can (currently) store up to 5 dimensions without getting them confused."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:183
msgid "Hyperstack flexibility"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:186
msgid "A hyperstack can contain 0–5 dimensions, while a stack can only contain 0–3. So why worry about stacks at all?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:189
msgid "The main reason comes from ImageJ's evolution over time. Some commands -- perhaps originating in the pre-hyperstack era -– were written only for 2D or 3D data. Trying to apply them to 4D or 5D images may then cause an error, or it may simply produce strange results."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:193
msgid "In practice, this is unlikely to be an issue nowadays. Hyperstacks have been around for so long now that all major commands that work on stacks should also handle hyperstacks properly. Nevertheless, it helps to have a historical perspective to understand why both terms still exist in ImageJ's interface."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:197
msgid "It may also help if you encounter some very old plugin that was written for stacks but that doesn't handle hyperstacks properly."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:202
msgid "Navigating dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:204
msgid "With a stack or hyperstack, only a single 2D **slice** is 'active' at any one time. A (hyper)stack image window can have up to 3 sliders, used to navigate the **channels**, **z** and **time** dimensions and select the active slice. In the case of multichannel images (where there is a 'channel' dimension), any changes to lookup tables are made for all the slices on the currently-active channel."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:214
msgid "A 5D image viewed in ImageJ."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:218
msgid "Correcting dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:220
msgid "Like the pixel size, the dimensions of an image can found under {menuselection}`Image --> Properties...`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:222
msgid "Sometimes the dimensions can be incorrect. This might happen, for example, if different *z*-slices were wrongly interpreted as time points when a file was opened, or the presence of multiple channels was not spotted. Misinterpreting the dimensions can not only affect the display of the image, but also some processing and measurements."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:226
msgid "It's also possible to change the dimensions through {menuselection}`Image --> Properties...`, but I find that can sometimes be unreliable because of the old stack/hyperstack distinction (i.e. it doesn't convert a stack to a hyperstack, and therefore doesn't display all the sliders that are needed). A better option is to use {menuselection}`Image --> Hyperstack --> Stack to Hyperstack...` to fix dimensions."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:234
msgid "Something terrible has befallen the file *lost_dimensions.tif*, so that it's displayed as a 3D stack, when in reality it should have more dimensions."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:236
msgid "By inspecting the file, identify how many channels, *z*-slices and time points it originally contained, and set these using {menuselection}`Image --> Hyperstack --> Stack to Hyperstack...` so that it displays properly. What are the correct dimensions?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:239
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/lost_dimensions.tif)"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:244
msgid "*lost_dimensions.tif* should contain 2 channels, 3 *z*-slices and 16 time points."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:246
msgid "The dimensions are in the default order (*xyczt*)."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:251
msgid "Plots and profiles"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:253
msgid "More dimensions can make data harder to visualize and interpret. Reducing dimensions can help."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:256
msgid "{menuselection}`Analyze --> Plot Profile` can be used to generate a 1D plot of pixel values along a line within the image. To use it, you can first draw a line ROI <img src=\"../../../images/imagej/icons/line.png\" />. By default, pixel values occurring along the line will be displayed in the plot, however it's possible to average multiple pixels perpendicular to line if needed. To do this, double-click on the line tool and adjust the {guilabel}`Line width` value."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:261
msgid "It's also possible to apply {menuselection}`Analyze --> Plot Profile` {kbd}`K` to a rectangle <img src=\"../../../images/imagej/icons/rectangle.png\" />, in which case it will average pixels vertically (default) or horizontally (if the {kbd}`Alt` key is pressed)."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:275
msgid "Another option if you have a stack or hyperstack is to use {menuselection}`Image --> Stacks --> Plot Z-axis Profile` to generate a profile across the slices. This essentially plots the mean value within any ROI (or across the whole image) for every slice in the stack. Perhaps unexpectedly, the same command is able to generate a profile across time points as well; when necessary, a dialog is shown to choose the dimension."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:279
msgid "In all cases, profile plots contain a {guilabel}`Live` button. This means the plot data updates as any changes are made to the image, including ROIs being generated and moved around."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:287
msgid "Three different profile plots, based on a rectangle. *(Top)* A regular profile plot from the active 2D slice, using {menuselection}`Analyze --> Plot Profile`. *(Bottom)* Profiles generated by {menuselection}`Image --> Stacks --> Plot Z-axis Profile` along the z-axis *(left)* and across time points *(right)*."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:297
msgid "Create a profile plot from any image, by drawing a line ROI and pressing {kbd}`K`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:299
msgid "As far as ImageJ is concerned, the profile plot itself is an image -- albeit a strange one. This means you can use {menuselection}`Image --> Properties...` to check the pixel size *of the profile plot*."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:302
msgid "What do you notice about the pixel sizes?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:308
msgid "You will probably see that the pixel width and height are different. In fact, the pixel width depends upon the scaling of the x-axis and the pixel height depends upon the scaling of the y-axis."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:311
msgid "This can be quite useful, because it means you can make measurements within the profile plot itself."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:313
msgid "If you want to measure a distance along the x or y axis, you can use the line tool <img src=\"../../../images/imagej/icons/line.png\" /> while pressing {kbd}`Shift`. This forces the line to be perfectly horizontal or perfectly vertical; without {kbd}`Shift` it would be easy to draw a line at a slight diagonal that could give incorrect results."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:327
msgid "Displaying dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:329
msgid "Z-projections"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:331
msgid "The command to generate a [*z*-projection](sec_dims_z_project) in ImageJ is {menuselection}`Image --> Stacks --> Z Project...`. This supports several different projection types, as shown in {numref}`fig-visualize_fiji_projection`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:349
msgid "Three projections of a *z*-stack. Sum projections often look similar to maximum projections, but less sharp."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:357
msgid "Imagine computing a sum and a maximum projection of a 10-slice stack containing a large, in-focus nucleus. How might each of these projections be affected if your stack contained:"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:360
msgid "4 additional, out-of-focus slices (with non-zero pixel values)"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:361
msgid "several very bright, isolated, randomly distributed outlier pixels – with values twice what they should be (due to noise)"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:367
msgid "Additional, out-of-focus planes will have an effect upon sum projections: increasing all the resulting pixel values. However, the extra planes would have minimal effects upon maximum projections, since they are unlikely to contain higher values than the in-focus planes."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:370
msgid "Maximum projections will, however, be very affected by bright outliers: these will almost certainly appear in the result with their values unchanged. Such outliers would also influence a sum projection, but less drastically because each pixel would contain the sum of 9 reasonable values and only 1 large value (unless, by bad luck or a dubious detector, many outliers happen to overlap at the same _xy_ coordinate)."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:387
msgid "What happens if you calculate a maximum projection *twice* for the 5D image {menuselection}`File --> Open samples --> Mitosis`?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:389
msgid "By this I mean you run {menuselection}`Image --> Stacks --> Z Project...` on the original image, and then again on the output of the first projection."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:391
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?run=https://gist.github.com/petebankhead/9dbe7657bb476ea457f14229e93c5862)"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:397
msgid "You should end up with a maximum *z*-projecton followed by a time projection!"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:399
msgid "If there is a time dimension but no *z* dimension, {menuselection}`Image --> Stacks --> Z Project...` will use time instead."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:401
msgid "If there *is* a *z* dimension but you want a time projection anyway, you could try careful use of {menuselection}`Image --> Hyperstack --> Re-order Hyperstacks...` or {menuselection}`Image --> Hyperstack --> Stack to Hyperstack...` to temporarily switch the dimension names and trick ImageJ into doing what you want."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:407
msgid "Orthogonal views"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:409
msgid "The command {menuselection}`Image --> Stacks --> Orthogonal Views` makes it possible to generate interactive [orthogonal slices](sec_dims_orthogonal) from an image stack. This opens up 2 extra windows, so that when you click at any point on the original _xy_ view, you are shown cross-sections through that point from each direction."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:418
msgid "Orthogonal views in ImageJ."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:421
msgid "Note that when viewing the orthogonal slices, clicks on the image are intercepted. This makes it difficult to interact with the image normally or create new ROIs. If you close any of the additional views then the command is deactivated, and you can go back to working with the image as before."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:425
msgid "Reslicing"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:427
msgid "If you look closely at the orthogonal slices, you will see that they are RGB images -- even if the original stack is not RGB. They are also locked to using the LUT and brightness/contrast settings that were active when the command was first run."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:430
msgid "This makes them a useful visualization trick, but they do not provide a rotated version of the data for analysis."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:432
msgid "If you instead want to rotate the entire stack so that you can browse through what are effectively _xz_ or _yz_ slices and do whatever you want to them, the command you need is {menuselection}`Image --> Stacks --> Reslice...`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:440
msgid "Reslicing an image."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:443
msgid "After reslicing, you can then use {menuselection}`Image --> Stacks --> Z Project...` to effectively generate orthogonal *z*-projections."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:445
msgid "Reslicing and interpolation"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:449
msgid "Interpolation effectively means making up plausible new pixel values to fill in the gaps 'between' known pixels. In this case, interpolation handles the fact that the pixel width, pixel height and voxel depth (*z*-spacing) are seldom identical."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/imagej.md:452
msgid "With that in mind, if you need to reslice an image then I recommend trying it both with and without {guilabel}`Avoid pixel interpolation` selected, checking the pixel size under {menuselection}`Image --> Properties...` in both cases. Seeing what actually happens is likely to be more informative than trying to make sense of any explanation I could try to give."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:17
msgid "Pixel size & dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:22
msgid "The concept of **pixel size** relates measurements in pixels to physical units"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:23
msgid "It can be helpful to think of pixels as little squares -- but this is a simplification"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:24
msgid "The number of **dimensions** of an image is the number of pieces of information required to identify each pixel"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:44
msgid "Hopefully by now you're appropriately nervous about accidentally changing pixel values and therefore compromising your image's integrity. If in doubt, you'll always calculate histograms or other measurements before and after trying out something new, to check whether the pixels have been changed."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:47
msgid "This chapter explores pixels in more detail, including how they are arranged within an image and how they relate to things in the physical world."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:49
#: ../../chapters/1-concepts/5-pixel_size/python.md:29
msgid "Pixel size"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:51
msgid "**How big is a pixel?**"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:53
msgid "In one sense, a pixel is just a number: it doesn't really have a size at all. However, if we don't get too philosophical about it[^philosophy], we intuitively know that the things depicted in our images usually have a size in real life."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:58
msgid "The 'pixel size' is an idea that helps us translate measurements we make in images to the sizes and positions of things in real life. We often need to know the pixel size for our images if our analysis results are be meaningful."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:61
msgid "One way to think about this in microscopy is to consider the **field of view** of an image, i.e. the width and height of the area that has been imaged. We can divide the width and height in physical units (often µm) by the number of pixels along that dimension, as shown in {numref}`fig-px_sizes`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:64
msgid "The result is that we have two value in µm/px, corresponding to the **pixel width** and **pixel height**. *Usually* these are the same."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:143
msgid "Images with different pixel sizes. Whenever the field of view remains the same, the pixel size increases as the number of pixels in the image decreases."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:154
msgid "[A Pixel is *Not* a Little Square](http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf)"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:157
msgid "Pixel squareness"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:160
msgid "Talking of pixels as having (usually) equal widths and heights makes them sound very square-like, but previously I stated that pixels are not squares -- they are just displayed using squares."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:162
msgid "This slightly murky philosophical distinction is considered in Alvy Ray Smith's technical memo (_right_), the title of which gives a good impression of the central argument. In short, pushing the pixels-are-square model too far leads to confusion in the end (e.g. what would happen at their 'edges'?), and does not really match up to the realities of how images are recorded (i.e. pixel values are not determined by detecting light emitted from little square regions, see {ref}`chap_formation_spatial`). Alternative terms, such as _sampling distance_, are often used instead of pixel size -- and are potentially less misleading."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:166
msgid "But 'pixel size' is still used commonly in software (including ImageJ), and we will use the term as a useful shorthand."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:169
msgid "Pixel sizes and measurements"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:171
msgid "Knowing the pixel size makes it possible to calibrate size measurements. For example, if we measure some structure horizontally in the image and find that it is 10 pixels in length, with a pixel size of 0.5µm, we can deduce that its actual length in reality is (approximately!) 10 × 0.5µm = 5µm."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:173
msgid "This conversion is often done within the analysis software, but depends upon the pixel size information being present and correct. All being well, appropriate pixel sizes will have been written into an image file during acquisition and subsequently read by the software. Unfortunately, this does not always work out (see {ref}`chap_files`) and so we do always need to check our pixel sizes, and derived measurements of size, for reasonableness."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:180
msgid "Suppose we detect a structure and we count that it covers an area spanning 10 pixels. Suppose also that the pixel width = 2.0 µm and the pixel height is 2.0 µm."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:183
msgid "What is the **area** of the structure in µm<sup>2</sup>?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:187
msgid "40 µm<sup>2</sub>"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:189
msgid "At least that's the answer I was looking for: 10 x 2µm x 2µm = 40µm<sup>2</sup>."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:191
msgid "If you want to be pedantic about it, you might quibble about whether it makes sense to report 2D areas for 3D structures, or the possible impact of measurement error caused by the diffraction limit."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:193
msgid "But let's not be pedantic for now."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:197
msgid "Pixel sizes and detail"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:199
msgid "In general, if the pixel size in a microscopy image is large then we cannot see very fine detail (see {numref}`fig-px_sizes`). However, the subject becomes complicated by the diffraction of light whenever we are considering scales of hundreds of nanometers, so that acquiring images with smaller pixel sizes does not necessarily bring us extra information -- and might even become a hindrance."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:202
msgid "This will be explored in more detail in {ref}`chap_formation_spatial` and {ref}`chap_formation_noise`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:206
#: ../../chapters/1-concepts/5-pixel_size/python.md:138
msgid "Dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:208
msgid "Identifying dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:210
msgid "The concept of **image dimensions** is *mostly* straightforward, although I'm not aware of any universal definition that all people and all software stick to reliably."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:212
msgid "The approach we'll take here is to say: **the number of dimensions is the number of pieces of information you need to know to identify an individual pixel.**"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:214
msgid "For example, in the most familiar 2D images, we can uniquely identify a pixel if we know its _x_ and _y_ spatial coordinates."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:216
msgid "But if we needed to know _x_ and _y_ coordinates, a _z_-slice number, a color channel and a time point then we would be working with 5D data ({numref}`fig-dimensions`). We could throw away one of these dimensions -- any one at all -- and get a 4D image, and keep going until we have a single pixel remaining: a 0D image."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:219
msgid "Throw away that pixel, and we no longer have an image."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:263
msgid "Depictions of images with different numbers of dimensions. (A) A single value is considered to have 0 dimensions. (B--E) Additional dimensions are added, here in the following order: _x_ coordinate (1), _y_ coordinate (2), channel number (3), _z_ slice (4). The volume view in (E) was generated using the [ClearVolume plugin for Fiji](https://imagej.net/plugins/clearvolume)."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:267
msgid "Loic A. Royer et al. (2015). \"ClearVolume – Open-source live 3D visualization for light sheet microscopy\". *Nature Methods* 12, 480–481. https://doi.org/10.1038/nmeth.3372"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:275
msgid "Visualization of a 5D image (xyczt) using ClearVolume + Fiji."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:279
msgid "In principle, therefore, 2D images do not need to have *x* and *y* dimensions. The dimensions could be *x* and *z*, or *y* and time, for example. But while we may play around with the identity of dimensions, the important fact remains: an *nD* image requires *n* pieces of information to identify each pixel."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:283
msgid "Do channels really add a dimension?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:286
msgid "There can be some fuzziness in the idea of dimensions, particularly when channels are involved. If we rigorously follow the approach above, an image with *x*, *y* and *channels* would be 3D... but in practice such images are often (but not always!) called 2D anyway."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:289
msgid "'3D' is sometimes restricted to mean that there is a *z* dimension. If we have an image with *x*, *y* and *time* then we might technically be correct to call it 3D -- but that is likely to be confusing, so it's probably best to refer to a 'time series' instead."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:292
msgid "I still think that our explanation of the number of dimensions as being 'the number of things you need to know to identify a pixel' is a good baseline way to think about it, and corresponds well with the implementation in software and usage in Python/NumPy. But we need to be prepared to use context to identify when the word 'dimensions' is being used with images more casually."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:298
msgid "Z-Projections"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:300
msgid "The more dimensions we have, the trickier it can be to visualize the entire image effectively."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:302
msgid "**Z-stacks** are composed of different 2D images (called **slices**) acquired at different focal depths, optionally with an extra channel dimension added as well."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:304
msgid "One way to visualize a z-stack is to simply look at each slice individually."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:356
msgid "Visualizing the slices from a z-stack as separate images. Here, each slice has 2 channels."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:364
msgid "How many dimensions does the z-stack in {numref}`fig-dimensions_slices` have?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:366
msgid "*Remember: we count channels as a dimension here!*"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:370
msgid "The image is 4D: x, y, z, channels."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:376
msgid "Viewing many slices separately is cumbersome."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:378
msgid "An efficient way to summarize the information in a z-stack is to compute a **z-projection**."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:380
msgid "This generates a new image with the z-dimension essentially removed, i.e. a 3D image becomes 2D, or a 4D image becomes 3D."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:382
msgid "The pixel values in the output image depend upon which function was used to compute the projection. Perhaps the most common is to use a **maximum z-projection**. For each pixel location in the new image, the maximum value is taken across all the z-slices at the corresponding pixel location in the original image (i.e. the same _x_, _y_, _c_ and _t_ coordinate, as appropriate)."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:429
msgid "Visualizing a z-stack using z-projections."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:435
msgid "Orthogonal slices"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:437
msgid "Another useful way to visualize z-stack information is to use **orthogonal slices**."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:439
msgid "Conceptually, the z-stack is viewed as a 3D block of pixels (or perhaps, 4D if we count channels). We choose a single point in the image, and generate three orthogonal views on the image that pass through that point. We can think of it as looking at the block from three different angles: from above, and from two adjacent sides."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:443
msgid "This gives us 3 images, as shown in {numref}`fig-dimensions_orthogonal`. Each image depends upon the single point through which the orthogonal views pass."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:543
msgid "Visualizing a z-stack using orthogonal slices at different locations within a z-stack, indicated by dashed lines."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:548
msgid "The idea of orthogonal views and projections can be combined to give **orthogonal projections**, as shown in {numref}`fig-dimensions_orthogonal_projections`. In this case, we don't need to choose a point through which to pass, because the projections do not depend upon a specific slice location; rather, all pixels contribute to each projection."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:583
msgid "Visualizing a z-stack using orthogonal projections."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/pixel_size.md:56
msgid "If we *do* get too philosophical about it, I would expect there to be issues with 'know', 'size' and 'real life' -- and probably many other elements of that sentence."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:15
msgid "Python:  Pixel size & dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:17
msgid "This section gives a bit of background on working with pixel sizes and dimensions in Python... which is a bit more complicated than one might first expect."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:31
msgid "Checking the pixel size in Python has been, in my opinion, a bit of a pain - because the common libraries used to read images don't always make that information very easy to access."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:33
msgid "The situation is improving though."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:35
msgid "Here, we'll look at accessing pixel size information using two popular image-reading libraries:"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:36
msgid "[`imageio`](https://pypi.org/project/imageio/) - which very commonly used, and makes reading lots of common image types straightforward"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:37
msgid "[`AICSImageIO`](https://pypi.org/project/aicsimageio/3.2.1/) - which is a bit more complex, but has some *extremely* useful features for working with scientific images"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:41
#: ../../chapters/1-concepts/6-files/python.md:66
msgid "ImageIO"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:43
msgid "To explore pixel sizes with `imageio`, let's return to the neuron image used in the 'Channels & colors' chapter."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:45
msgid "The following code shows how we can read both the pixel values and the metadata."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:64
msgid "The metadata contains a lot of info, even including lookup tables."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:66
msgid "Printing it a little more nicely (and skipping the LUTs), we get:"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:74
msgid "This metadata is actually quite ImageJ-specific, and other TIFFs may give quite different metadata."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:76
msgid "We can see the version of ImageJ that wrote the file, but picking out the key thing we want here - the pixel size - is not so easy."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:78
msgid "Seeing `unit=um` is encouraging, but not enough."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:80
msgid "We can explore a bit more with 'properties', which imageio described as ['a curated set of standardized metadata'](https://imageio.readthedocs.io/en/v2.30.0/reference/userapi.html#metadata)."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:87
msgid "Here, the `spacing=(6.25, 6.25)` seems promising."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:89
msgid "It's tempting to suppose that means the pixel width and height are both 6.25 µm - *however* if I check the same image in ImageJ itself, I see the pixel width and height are actually 0.16 µm... which happens to equal 1.0/6.25 µm."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:95
msgid "Therefore the information **is** in the metadata, but it's very easy to misinterpret - and it isn't even guaranteed to be correct if the image was written by some other software."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:97
msgid "So while `imageio` is excellent for reading images easily - generally just a quick `im = imread(path)` - it's not necessarily the best thing to use when pixel sizes (or other metadata) matter."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:101
msgid "Using AICSImageIO"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:103
msgid "The best alternative I know for working with scientific (especially biomedical) images is [**AICSImageIO**](https://github.com/AllenCellModeling/aicsimageio). This is a really useful Python library that standardizes reading and writing multiple file formats - and, depending upon how it's installed, can even access lots more awkward proprietary file formats with the help of [Bio-Formats](http://www.openmicroscopy.org/bio-formats/)."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:106
msgid "Although it's possible to use a version of `imread` with AICSImageIO, it's worth learning the alternative way of doing things by creating an `AICSImage` object. This provides us with a way to access pixels and lots of other useful things whenever we need them."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:122
msgid "From this, we can immediately see the attribute that will provide us with pixel sizes directly."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:128
msgid "One perhaps non-obvious thing to know when using AICSImageIO is that the `AICSImage` isn't a regular NumPy array of the kind that `imageio.imread` would return. Rather, if you want that, you need to request the data."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:131
msgid "Using this knowledge, we can check that we have the same mean pixel value for both - as a quick way to ascertain that the actual pixel values are likely to match."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:140
msgid "Array shapes and dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:142
msgid "We've seen how two different libraries can enable us to read the same pixel values as NumPy arrays and extract pixel size information."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:144
msgid "We might well expect that the NumPy arrays representing the pixel values are the same, but in fact we can't count on that."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:146
msgid "NumPy is incredibly flexible when it comes to handling multidimensional arrays.  And while that flexibility can be really helpful, it can also complicate things."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:149
msgid "To see it in action, let's check the dimensions of the images we read using imageio and AICSImageIO."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:166
msgid "We can see the number of pixels are the same, but there are some extra 'singleton' dimensions stuck into the results from AICSImageIO (i.e. with length `1`)."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:168
msgid "Fortunately, we can easily remove them with an `np.squeeze` - and end up with the same arrays."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:177
msgid "So a natural question is: **why has AICSImageIO snuck in some extra dimensions?**"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:179
msgid "Before answering that, we should ask ourselves something else. **What exactly do we _have_ along the dimension of length `5`?**"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:182
msgid "And this is where things aren't terribly clear with imageio."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:184
msgid "`5` *could* be the width of the image, height of the image, number of channels, number of z-slices, or number of timepoints."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:186
msgid "Based upon our knowledge of images and the other dimensions, we'd be justified in expecting that the `5` doesn't correspond to the image width or height - `512` seems more likely for those - so it's probably one of the others."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:188
msgid "But the problem is that **we have no way of knowing** without further information. If we don't have some external source to tell us, we need to poke around the metadata or look at the contents to figure out the answer."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:201
msgid "To me, that looks very much like we have 5 different channels. I'm making some assumptions there... but they seem pretty safe assumptions."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:204
msgid "However AICSImageIO removes this ambiguity in a couple of ways."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:205
msgid "You can expect `AICSImage` to return a 5D array, with the dimensions in a consistent order: `TCZYX` (although there is at least one caveat in the next section!)"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:206
msgid "You can easily query the dimensions and order to be sure"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:215
msgid "Where are my channels?!?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:217
msgid "We've seen above that imageio can return a 5-channel image with the channels first. Our question here is: does it always do that?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:220
msgid "The answer, alas, is no. The location of the channels dimensions is painfully uncertain in Python, and often different tools expect it to be in different places."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:223
msgid "Or sometimes the *same* tool might put it in a different place."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:225
msgid "To see that in action, let's read a simple RGB image with imageio."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:233
msgid "An RGB image has 3 channels - red, green and blue - but it seems that suddenly we have the channels dimension last."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:235
msgid "Why?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:237
msgid "I don't have a very satisfying explanation, except to say that for RGB that's often what you want because matplotlib expects the channels to be last, and we often use matplotlib to show images."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:249
msgid "It's not *always* what you want though, and if you get enough deep learning then you'll find the 'channels-first' or 'channels-last' question coming up often."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:251
msgid "With that in mind, we can use NumPy to shift from so-called 'channels-last' to 'channels-first' - but matplotlib won't like that very much."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:266
msgid "So imageio might get channels at the start or the end. For RGB, it seems to prefer the end."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:269
msgid "What does AICSImageIO do?"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:271
msgid "Since I said AICSImageIO is consistent, I'd like to say it puts the channels in the same place for the RGB and 5-channel image... but no. It also treats RGB as a special case."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:281
msgid "It's a little hard to find, but the AICSImageIO documentation mentions that [you can expect 5 dimensions for non-RGB images, but RGB images have 6 dimensions](https://allencellmodeling.github.io/aicsimageio/aicsimageio.readers.html#aicsimageio.readers.bioformats_reader.BioFile.to_numpy) - where the sixth is called `S` for `Samples`."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:283
msgid "The good thing is that, assuming you don't have anything else going on with the first 3 dimensions - i.e. they are just `(1, 1, 1)` - a simple `np.squeeze` is enough to convert the pixel array into a matplotlib-friendly channels-last RGB format."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:287
msgid "More dimensions"
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:289
msgid "We'll end this section by looking at an image with 2 channels and 25 z-slices."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:291
msgid "Since you now know how to explore the dimensions in detail, I'll use my `load_image` helper function for convenience... which returns a NumPy array that's pre-squeezed to remove any singleton dimensions."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:298
msgid "Since we already considered how to view multichannel images in the last chapter, let's extract a single channel here."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:307
msgid "At this point, NumPy becomes quite fun - because it is *so easy* to do stuff along different dimensions."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:309
msgid "For example, we can rapidly generate different z-projections."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:337
msgid "But we're not limited to projecting along z - we can just switch the `axis` value and project along some other dimension."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:339
msgid "Note that this won't do any correction for differences in pixel size in xy vs. z. With only 25 z-slices, these projections look extremely squashed."
msgstr ""

#: ../../chapters/1-concepts/5-pixel_size/python.md:367
msgid "And we can also slice wherever we like as well, to obtain orthogonal views."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:16
msgid "Files & file formats"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:22
msgid "Image files consist of **pixel values** and **metadata**"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:23
msgid "Some file formats are suitable for **data to analyze**, others for **data only to display**"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:24
msgid "Metadata essential for analysis can be lost by saving in a **non-scientific file format**"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:25
msgid "**Compression** can be either **lossless** or **lossy** -- with different results"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:26
msgid "Original pixel values can be lost through **lossy compression**, **conversion to RGB**, or by **removing dimensions**"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:47
msgid "One of the surest ways to lose information when working with images is by making bad file format choices."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:49
msgid "There is a vast array of file formats used to store images -- but not all formats support all the bit-depths, types and dimensions needed for scientific imaging. Some formats tend to lose metadata, and some compromise pixel values through compression."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:52
msgid "To avoid getting bogged down in file format intricacies, I want to give you the main messages of this chapter up-front:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:54
msgid "Working with image formats"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:57
msgid "Always keep your original image files, in their original format"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:58
msgid "During analysis:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:59
msgid "Use software designed for scientific data (i.e. not a general photo editor)"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:60
msgid "If you need to save images, use the default file format for the software (e.g. TIFF for ImageJ)"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:61
msgid "**Check everything!** Make sure you can reopen the image after saving, and any pixel values, pixel size information and dimensions are retained exactly."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:62
msgid "Use general-purpose file formats (e.g. PNG, JPEG) for figures, presentations or websites -- but not later analysis"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:63
msgid "Use TIFF cautiously, because it can be used both as a scientific format suitable for analysis and a general-purpose format suitable only for display"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:64
msgid "OME-TIFF is often a better alternative to TIFF, since it standardizes how the metadata is stored"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:67
msgid "To help put this into practice, {numref}`table-file_formats` lists some of the most important image formats you need to know about when saving images yourself."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:69
msgid "Some of the most useful file formats for bioimage analysis & display"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:73
msgid "Format"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:74
msgid "Extensions"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:75
msgid "Main use"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:76
msgid "Compression"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:77
msgid "Comment"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:78
msgid "TIFF"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:79
msgid ".tif, .tiff"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:80
msgid "Analysis, display (print)"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:81
#: ../../chapters/1-concepts/6-files/files.md:86
#: ../../chapters/1-concepts/6-files/files.md:91
msgid "None, lossless, lossy"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:82
msgid "Very general image format"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:83
msgid "OME-TIFF"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:84
msgid ".ome.tif, .ome.tiff"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:85
msgid "Analysis, Display (print)"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:87
msgid "TIFF, with standardized metadata for microscopy"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:88
msgid "Zarr"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:89
msgid ".zarr"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:90
msgid "Analysis"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:92
msgid "Emerging format, great for big datasets -- but limited support currently"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:93
msgid "PNG"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:94
msgid ".png"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:95
msgid "Display (web, print)"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:96
msgid "Lossless"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:97
msgid "Small(ish) file sizes without compression artefacts"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:98
msgid "JPEG"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:99
msgid ".jpg, .jpeg"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:100
msgid "Display (web)"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:101
msgid "Lossy (usually)"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:102
msgid "Small file sizes, but visible artefacts"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:105
msgid "The rest of this chapter explains the key ideas. Despite already having the conclusions, I hope you might persist with reading the rest anyway. Understanding more about file formats can help enormously when it comes to choosing how to save images for different purposes, and diagnosing problems when the wrong formats have been used."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:111
msgid "Image file contents"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:113
msgid "An image file stored on computer contains two main things:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:115
msgid "**Pixel values** -- the 'raw numbers' of the image"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:116
msgid "**Metadata** -- additional information, such as dimensions, image type, bit-depth, pixel sizes and microscope settings ('data about data')"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:118
msgid "The pixel values are clearly important. But some pieces of the metadata are essential for the image data to be interpretable at all. And if metadata such as the pixel size is incorrect or missing, measurements can also be wrong. Therefore files must be saved in formats that preserve both the pixel values and metadata accurately if they are to be suitable for analysis later."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:126
msgid "Pixel values & compression"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:128
msgid "Pixel values are represented using bytes. As described in {ref}`chap_bit_depths`, an 8-bit image uses 1 byte per pixel, a 16-bit image uses 2 bytes per pixel and a 32-bit image uses 4 bytes per pixel."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:131
msgid "However, the way these bytes are stored in the image file can depending upon whether compression is used. There are three main options:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:134
msgid "**No compression**. The bytes representing the pixels are stored directly in the file. This means that the pixel values are preserved exactly, but the file can be quite large."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:137
msgid "*Examples: TIFF (Uncompressed), ICS/IDS*"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:138
msgid "**Lossless compression**. The bytes representing the pixels are stored using a compression algorithm that (usually) results in less storage space being required, while making it possible to reconstruct the original values exactly by decompression. Compared to uncompressed data, the file size using lossless compression is generally smaller but reading or writing the file takes longer."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:141
msgid "*Examples: TIFF (LZW compressed), PNG, BMP, JPEG2000 (lossless)*"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:142
msgid "**Lossy compression**. The bytes representing the pixels are stored using a compression algorithm that does *not* have to be able to reconstruct the original values exactly. This can result in dramatically smaller file sizes, but at a loss of information in the image -- and often visual artefacts."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:145
msgid "*Examples: TIFF (JPEG compressed), JPEG, GIF, JPEG2000 (lossy)*"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:147
msgid "Probably the most famous file format that uses lossy compression is JPEG."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:149
msgid "The basic idea of JPEG compression is that an image is split into 8x8 pixel blocks, and an approximation of the original values is stored rather than the exact values themselves. Technically, this approximation involves the 'discrete cosine transform'; for our purposes, it's enough to know that JPEG artefacts tend to look 8x8 pixel squares, each containing wavy patterns, which are most evident when zooming in and/or cranking up the brightness and contrast to an extreme level ({numref}`fig-files_lossy`)."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:209
msgid "Examples of images saved with (A) no compression, (B) lossless compression, and (C) lossy JPEG compression. The pixel values of (A) and (B) are identical. Image (C) looks similar, but zooming in on a detailed region reveals characteristic JPEG artefacts."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:212
msgid "Compression quality"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:215
msgid "Lossy compression can often be varied with a 'compression quality' setting. For a JPEG with a high quality setting, the 8x8 artefacts are likely to be much less obvious than they appear in {numref}`fig-files_lossy` -- although the pixel values are still modified. Therefore it's a good idea to also use {ref}`statistics & histograms <chap_histograms>` to check for pixel changes."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:221
msgid "Based upon the importance of preserving pixel values, the easy rule is that:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:223
msgid "**Lossy compression is bad for analysis!**"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:226
msgid "If in doubt, don't use lossy compression when working with scientific images."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:228
msgid "The choice between 'no compression' and 'lossless compression' is a matter of preference, depending upon whether it's more important to you to save disk space or to open images quickly. Compatibility is also a consideration if you want to open the images in different software: not all compression types are supported by all software. So best check this before saving a lot of images in a format you might not be able to read elsewhere."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:233
msgid "How do I know if a file has been compressed?"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:234
msgid "An easy way to identify if an image has been lossily compressed is to look at the file extension, and check if it matches a format that uses lossy compression (e.g. *.jpeg*). Easy, but not *always* successful."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:237
msgid "One reason is that some file formats support both lossless and lossy compression. For example, both JPEG and JPEG2000 (*not* the same thing!) are generally used with lossy compression but they both *could* be used for lossless compression as well. Unless you've proof to the contrary, if you see a file with extension *.jpg*, *.jpeg*, *.jp2* then it's best to assume lossy compression has been used."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:241
msgid "TIFF images are particularly tricky. A TIFF image could contain uncompressed data, or data compressed using a variety of different methods -- both lossless and lossy, including JPEG. To determine if a TIFF image has used lossy compression, more detective work may be needed (e.g. zooming in and hunting for artefacts, comparing pixel statistics with the original data file, or using software to check for metadata)."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:253
msgid "It takes approximately 1 MB to store (1,000,000 bytes) an 8-bit uncompressed image with 1,000,000 pixels."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:255
msgid "How much memory does it take to store a 16-bit image with the same number of pixels?"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:257
msgid "*You can ignore the tiny bit of extra space needed to store any associated metadata.*"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:262
msgid "2 MB."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:264
msgid "8 bits corresponds to 1 byte, so 16 bits correspond to 2 bytes. We multiply the number of bytes per pixel by the number of pixels to get the minimum size required to store the uncompressed image."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:277
msgid "Suppose you have an original image in TIFF format (no compression). First, you save it as JPEG (lossy compression) to reduce the file size, then close it and throw away the TIFF."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:280
msgid "Upon hearing JPEG is bad, you reopen the image and save it as TIFF  once more (no compression), throwing away the JPEG. How does your final TIFF image look, and what is its file size?"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:287
msgid "The final image will look exactly like the JPEG version, *but with the same file size as the original TIFF!* As such, it has 'the worst of both worlds'."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:295
msgid "Core metadata"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:297
msgid "Pixel values are represented as a [stream of bits: ones and zeros](chap_bit_depths). A few core pieces of metadata *must* be stored alongside these bits to interpret them as an image, such as the dimensions, bit-depth and type. If this information is missing -- or wrong -- then the image usually either cannot be read, or looks strange in some way ({numref}`fig-files_core_metadata`)."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:333
msgid "Some examples of core metadata being read correctly or incorrectly."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:336
msgid "*Most* of the time, we don't need to care about this because all image file formats store this core information, and software used to open the image *usually* interprets this correctly."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:338
msgid "But it isn't unheard of for some fancy new format to store the core metadata in a way that cannot be properly read and interpreted by other software. If you try to open your images and find they look very odd, you should be aware that there might be a metadata problem -- and you might need to contact the developer of the software to figure out what has gone wrong."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:341
msgid "More commonly, the choice of file format impacts what type of image can be stored. For example, PNG or JPEG images are limited to 2D integer data, optionally with 1, 3 or 4 channels; they do not support (for example) 32-bit floating point images, z-stacks or time series. Saving a 5D floating point image as a JPEG or PNG therefore inherently involves converting the image type and discarding information."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:347
msgid "Additional metadata"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:349
msgid "The most important piece of 'non-core' metadata is the {ref}`pixel size <chap_pixel_size>`. Unlike core metadata, it is *not* necessary for a file format to preserve the pixel size for an image to be opened and appear 'correct'."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:352
msgid "This is a problem because if the pixel size is incorrect or missing, it remains possible to make length, area or volume measurements within an image -- but these measurements are likely to be wrong."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:354
msgid "In microscopy, the pixel size is typically represented as a value in µm/pixel. Saving in some file formats (e.g. JPEG and PNG) tends to lose pixel size information. Others (e.g. TIFF) *might* preserve the pixel size, *might* lose it, or *might* convert it to something else entirely."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:358
msgid "This should sound odd, scary and outrageous. Losing pixel size information is one thing, but why would any sneaky software just change the value to something else??!?"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:361
msgid "To explain this, we need to remember that most images aren't intended for analysis. Most are intended only for display. And, for display, size can have a different meaning."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:365
msgid "Many researchers already encounter this when it comes to publishing papers. Journals often require that figures are submitted at a sufficiently high resolution for printing, with the resolution defined in terms of **dots per inch (*dpi*)**. For example, an image might be requested that is at least 300 dpi; if it should be printed at a size of 2 x 2 inches, then it should be at least 600 x 600 pixels."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:369
msgid "For an image with a dpi of 300, one *could* argue that a single pixel has a size of 1/300 inches. In this case, size is related to display. It doesn't matter what the image depicts -- it could be a cell, a person, a building, a galaxy -- or tell us anything about its scale. In this case, the pixel size is only telling us how the image ought to be displayed."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:374
msgid "When it comes to TIFF images, the pixel size for science or the pixel size for display (i.e. dpi) might be stored *in exactly the same part of the file*. Therefore what this value actually means depends entirely upon which software wrote the image, and whether it was more concerned with analysis or display."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:377
msgid "For that reason:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:380
msgid "**Always sanity-check pixel size values!**"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:383
msgid "How to do that will depend upon which software you are using: each may display pixel size information in a different place. But one universal rule is to use whatever knowledge you have about whatever is in your images."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:386
msgid "For example, suppose you have an image of cells. A quick internet search can reveal a typical diameter of a nucleus (perhaps 5-20&nbsp;µm). Therefore you could spend a few minutes measuring some nucleus diameters to see if they are close to this value. If so, it does not prove the pixel size is correct but it does give some added confidence; if the value is far from what is expected, then it is a warning that the pixel size is wrong."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:394
msgid "Choosing file formats"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:396
msgid "The right choice of file format depends upon when you are saving the image, and what you will want to do with it. Three main scenarios are described below."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:399
msgid "During acquisition"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:402
msgid "Examples formats for specific microscopes include *.lif* (Leica), *.czi* (Zeiss), *.nd2* (Nikon), *.vsi* (Olympus)... with many more."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:405
msgid "The general rule is to"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:406
msgid "Saving images during acquisition"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:408
msgid "Use the default file format for your microscope and acquisition software"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:411
msgid "The rationale is that the manufacturer's format ought to preserve all the information and metadata. Often, the acquisition software supports saving the data in some other way -- but that can be risky. There's a strong chance that at least some metadata could be lost. Sometimes, the alternative export might do even worse things -- such as convert the data to RGB."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:416
msgid "The disadvantage of this is that microscopy formats are usually uncommon in the rest of the world, which means your images might be hard to open in other software."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:418
msgid "**Fortunately, there is a magnificent open-source project to help with this: [**Bio-Formats**](https://www.openmicroscopy.org/bio-formats/).**"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:420
msgid "Bio-Formats enables a [wide range of different formats](https://docs.openmicroscopy.org/bio-formats/latest/supported-formats.html) to be read by many different software applications. It's already available within Fiji and QuPath by default, or can be installed as a plugin for ImageJ. Although it's written in Java, Bio-Formats can also be used within some Python applications."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:424
msgid "*If* you are unlucky enough that the native format for your microscope isn't supported by Bio-Formats, you might need to export it in a different format for use elsewhere. But if you do this, it's best to retain a copy of the original data anyway -- so you can always refer to it using the original acquisition software to check what (if anything) might have been lost in the export."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:428
msgid "During analysis"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:430
msgid "If you want to save an image during analysis, the rule is"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:431
msgid "Saving images during analysis"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:433
msgid "Use the default file format for the analysis software you're using -- or OME-TIFF"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:435
msgid "Like the rule for acquisition, the idea is that this will generally preserve as much metadata as possible."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:437
msgid "For ImageJ, the default format is an uncompressed TIFF image. This supports 8-bit, 16-bit and 32-bit images with up to 5 dimensions, squeezing the key metadata required by ImageJ (e.g. pixel size) into one of the TIFF fields. All of this information should then be available if you open the image again in ImageJ or Fiji -- although it is not *necessarily* preserved if you open the TIFF in other software, which may not know how to interpret ImageJ's metadata. So if this is important to you, you'll need to check."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:442
msgid "*However*, this might not be the best choice if you want to continue working with your image in different software. In that case, it might take some exploration to see which formats enable metadata to be saved in a way that your preferred software applications recognize."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:445
msgid "If you're using software that incorporates Bio-Formats, the best option is likely to be OME-TIFF. Bio-Formats can read and write OME-TIFF images, which has a very well-defined standard for storing metadata (developed by the group behind Bio-Formats itself). This opens up more possibilities, such as writing TIFFs that include either lossless or lossy compression. OME-TIFF can also contain a lot more metadata than an ImageJ TIFF can, including things like stage position, laser power etc."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:451
msgid "For display"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:453
msgid "When it comes to displaying images, we usually only need a format that can support RGB images. Since we won't use the image for further analysis, we don't need to preserve the pixel size and don't *necessarily* have to avoid compression artefacts. My personal preferred formats for different scenarios are:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:457
msgid "**Journal figure: TIFF.** <br /> Often the journal requests this anyway. Even if I'm not convinced it always makes sense."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:458
msgid "**Presentation: PNG.** <br /> File size is not usually a problem, and PNG provides some compression without introducing artefacts."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:459
msgid "**Website: JPEG or PNG**, <br />JPEG (usually) because smaller file sizes mean the website can load quicker (and eat less data). But PNG for images that contain few colors, including most 'artificial' images such as drawings, dialog boxes or logos. JPEG artifacts can look especially ugly in such cases, while PNG can compress them very well."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:473
msgid "Creating figures for publication"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:475
msgid "Preparing figures for publication can be a bewildering process. To begin with, it's necessary to make another distinction between image types, one of which has not been discussed here so far:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:478
msgid "**Bitmaps**. These are composed of individual pixels: e.g. photographs, or all the microscopy images we are concerned with here."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:479
msgid "**Vector images**. These are composed of lines, curves, shapes or text.  The instructions needed to draw the image (i.e. coordinates, equations, fonts) are stored rather than pixels, and then the image is recreated from these instructions when necessary."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:481
msgid "Every other part of this handbook concentrates on bitmap images. Vector images are quite different."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:484
msgid "If you scale a 2D bitmap image by doubling its width and height, then it will contain four times as many pixels. Guesses need to be made about how to fill in the extra information properly (which is the problem of **interpolation**), and the result generally looks less sharp than the original. But if you double the size of a vector image, it's just a matter of updating the maths needed to draw the image accordingly, and the result looks just as sharp as the original."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:488
msgid "Vector images are therefore best for things like diagrams, histograms, plots and charts, because they can be resized freely and still look good. Also, they often have tiny file sizes because only a few instructions to redraw the image need to be kept, whereas a huge number of pixels might be required to store sufficiently nice, sharp text in a bitmap. But bitmaps are needed for images formed from detecting light, which cannot be reduced to a few simple equations and instructions."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:492
msgid "Finally, some versatile file formats, such as PDF or EPS, can store both kinds of image: perhaps a bitmap with some text annotations on top. If you are including text or diagrams, these formats are generally best. But if you only have bitmaps without annotations of any kind, then TIFF is probably the most common file format for creating figures."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:502
msgid "When viewed from afar, it may be difficult to know whether an image is a vector or a bitmap (A) because they can sometimes look identical (although a photograph or micrograph will always be a bitmap). However, when enlarged a vector image will remain sharp (B), whereas a bitmap will not (C)."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:510
msgid "Pyramidal images"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:512
msgid "Finally, we end with a few words on **pyramidal images**: a type of image that is becoming increasingly common."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:514
msgid "Modern bioimages can be *huge*. It's not uncommon for a single image to contain many gigabytes of pixel data, making it infeasible to open the full image in one go."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:517
msgid "However, for visualization or analysis we often don't *need* all the pixels at once. For example, when viewing an image we only really need to access the pixels that are visible on screen at any moment -- at the magnification at which they are being viewed."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:520
msgid "Pyramidal image files help overcome this by using two tricks:"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:521
msgid "They store the image as separate chunks (often called 'tiles', if they are 2D)"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:522
msgid "They store the same image at different resolutions in the same file"
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:529
msgid "Schematic diagram of a pyramidal image. The image itself (left) is broken into chunks and stored at multiple resolutions. The chunks needed to display the current field of view (top right) are highlighted in yellow. The original whole slide image here is from the [CAMELYON](https://camelyon16.grand-challenge.org) grand challenge."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:533
msgid "Software designed to handle pyramidal images can then dip into the image file and read **only the part of the image that is needed at the time**. This is often only a tiny proportion of the entire dataset."
msgstr ""

#: ../../chapters/1-concepts/6-files/files.md:536
msgid "Pyramidal images are especially common for pathology, although they are starting to be used more for other applications. [QuPath](https://qupath.github.io) is open source software that is designed specifically to handle pyramidal images efficiently (and happens to also be the software that I wrote and maintain, because I wasn't able to do the analysis with other open source tools at the time). Although QuPath can do a lot of things on its own, it can also be used [with ImageJ](https://qupath.readthedocs.io/en/stable/docs/advanced/imagej.html)."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:15
msgid "ImageJ: Files & file formats"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:21
msgid "On its own, ImageJ can read and write a range of common -- and a few not-so-common -- file formats. With Bio-Formats, it can handle a lot more."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:24
msgid "This section describes some of the most useful file formats for bioimage analysis and how to work with them effectively in ImageJ, along with a few tricks that may help if files are causing you trouble."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:26
msgid "File formats in ImageJ (only)"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:28
#: ../../chapters/1-concepts/6-files/imagej.md:117
msgid "Opening images"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:30
msgid "As described in {ref}`chap_imagej_pixels`, the general approach to open an image is to drag the file on top of the ImageJ toolbar and hope for the best. Assuming ImageJ supports the file format, then it will usually just work."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:33
msgid "One occasion when that might *seem* insufficient is whenever you have a large number of image files in the same folder, which really are different slices or time points of the same image. It's possible to drag all these onto ImageJ's toolbar at once, but they are likely to open as separate images. The trick is to drag the folder containing all the images onto the toolbar instead: you should then be invited to open the images together in a single image stack."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:42
msgid "This assumes that *all* the images in the folder should be opened. If you need more control, then {menuselection}`File --> Import --> Image Sequence...` can help. This gives a more extensive dialog, where (among other things) you can specify a filter, i.e. some text that should be present within the filenames of images to include."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:51
msgid "Virtual stacks for large images"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:55
msgid "Both the dialogs shown above to import multiple images give an intriguing {guilabel}`Use Virtual Stack` option. This causes ImageJ to *only* open the slice of the image stack that is currently being viewed. This can dramatically cut down memory requirements for large stacks, and make opening much faster."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:59
msgid "The disadvantage of using a virtual stack is that it can make processing behave a bit oddly: seemingly 'forgetting' when a slice has been processed, or requesting that the full image is read into memory with prompts like the one below."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:66
msgid "Still, virtual stacks are very handy if you want to peak into a large image without opening it all. If you don't mind its limitations, you can also open an ImageJ TIFF as a virtual stack using {menuselection}`File --> Import --> TIFF Virtual Stack...`."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:70
msgid "Saving images for analysis"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:72
msgid "To save an image, {menuselection}`File --> Save As --> Tiff...` *might* be all you ever need. This is ImageJ's default format, and so preserves all the important information that it requires -- including the pixel size. It even includes any [active ROIs and overlays](chap_rois)."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:76
msgid "The main disadvantage with saving an ImageJ TIFF is that it's uncompressed, and so the file size can quickly become quite large. One way to mitigate this is to choose {menuselection}`File --> Save As --> ZIP...`."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:79
msgid "Rather than being an entirely different format, a ZIP file saved by ImageJ is really just a TIFF that has been zipped up into a smaller file using lossless compression. You can probably unzip the file using the tools of your operating system to reveal the TIFF inside -- but you don't have to, because ImageJ can open the zip file directly."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:82
msgid "ImageJ's zip files are therefore good for archiving: they preserve all the same information as an ImageJ TIFF, but in a smaller file size. The cost is that reading and writing zip files can take quite a lot more time."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:85
msgid "Apart from TIFF and ZIP, none of ImageJ's other supported file formats are really to be recommended for analysis. Depending upon the original image, most will result in some kind of loss: for example through converting to RGB, discarding ROIs or dimensions, or applying some pixel-changing lossy compression."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:89
msgid "Saving images for display"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:91
msgid "When it comes to saving an image to display, data loss may be tolerable -- or even necessary. We care about appearance and compatibility, not exact pixel values."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:94
msgid "ImageJ TIFF can also be used to save an image for display, but the large file sizes can be a problem. If you want to do it anyway, then it is often best to [convert the image to RGB first](sec_imagej_flatten)."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:97
msgid "Alternatively, I regularly use {menuselection}`File --> Save As... --> PNG...` as my preferred option to save RGB images for display using lossless compression."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:99
msgid "If file size is still an issue, and artefacts are acceptable, then {menuselection}`File --> Save As... --> Jpeg...` can be used instead. The quality of the JPEG can be adjusted via {menuselection}`Edit --> Options --> Input/Output...`: increasing the JPEG quality will give (slightly) larger files, but less obvious artefacts."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:108
msgid "Using Bio-Formats"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:110
msgid "Bio-Formats is extremely useful when working with scientific images generally -- and pretty much indispensable when it comes to microscopy. It provides support for reading a wide range of formats, and writing a somewhat smaller (but still important) range."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:113
msgid "If you're using the Fiji distribution of ImageJ, then you should have Bio-Formats installed by default. Otherwise, you'll likely need to install *bioformats_package.jar* yourself. You can find it along with installation instructions at https://www.openmicroscopy.org/bio-formats/downloads/"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:119
msgid "Once it's installed, Bio-Formats can do much of its work without you needing to think about it: if ImageJ cannot open a file by drag & drop, then it will usually let Bio-Formats have a go. You can tell when that has happened because the familiar *Bio-Formats Import Options* dialog will pop up:"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:127
msgid "Sometimes -- but not always -- this is then followed by the *Bio-Formats Series Options* dialog. If the file contains multiple images, this gives an opportunity to select which images should be opened."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:135
msgid "Check out the import options"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:138
msgid "If you're anything like me, and have been using ImageJ for a while, there's a strong chance that the Bio-Formats import dialog has faded into the background noise of your life: something to be clicked away without another thought."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:140
msgid "But it's worth occasionally checking out the options in detail, and hovering your mouse on top to see the useful explanations about what each option actually means. Lurking within the checkboxes and drop-down menus are options to do things like automatically setting the brightness and contrast or display modes. If you find yourself doing these tasks each time you open an image anyway, changing the import defaults could make life a little easier."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:147
msgid "Saving images"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:149
msgid "To save a file, you can use {menuselection}`Plugins --> Bio-Formats --> Bio-Formats Exporter`."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:151
msgid "This is perhaps most useful if you want to save an OME-TIFF image. An OME-TIFF differs from a regular ImageJ TIFF in two main ways:"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:153
msgid "It stores a much more extensive collection of standardized metadata, as [OME-XML](https://docs.openmicroscopy.org/ome-model/latest/ome-xml/)"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:154
msgid "It provides options to compress the data inside the TIFF, using either lossless (e.g. LZW) or lossy (e.g. JPEG) compression"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:156
msgid "You may also find that it works better at preserving key metadata when you want to move an image to another software application."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:159
msgid "Troubleshooting files"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:161
msgid "Sometimes you might get slightly unlucky: an image fails to open, even though it *could* be opened."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:163
msgid "This can happen whenever ImageJ optimistically *thinks* it can open a file, gives it a shot, but fails with a error-emitting whimper. Pride presumably wounded, ImageJ never passes the file to Bio-Formats to try. If this happens, then you can call on {menuselection}`Plugins --> Bio-Formats --> Bio-Formats Importer`  to force the import to use Bio-Formats, in the hope it will have more success. I've had to do this on rare occasions with troublesome TIFFs."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:168
msgid "At other times, you might be more unlucky: an image fails to open, and no amount of effort will get ImageJ to open it."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:170
msgid "This could be because the file format itself is unsupported, or the image is corrupt. Assuming you have Bio-Formats installed, checking the [list of supported formats](https://docs.openmicroscopy.org/bio-formats/latest/supported-formats.html) is a good start for finding out if it even *should* work. If so, you could ask about it on the [Scientific Community Forum](https://forum.image.sc) -- you'll probably need to share the image though for anyone else to be able to investigate the problem."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:174
msgid "However, before doing that you should consider whether you have a whole slide image -- or other large pyramidal image -- that just has too many pixels for ImageJ to open. In that case, you might see a rather cryptic error like the one below:"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:182
msgid "Although by no means obvious, this indicates that the image is too large. If this happens, you might want to try [QuPath](sec_files_pyramidal) instead."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:191
msgid "To get a feel for the importance of metadata, you can try opening an image in which it is completely absent. This is quite tricky, and requires some detective work (or some luck)."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:194
msgid "Try to open the file *Besenfreunde.ids* using Fiji -- it depicts an odd, and as yet unexplained, scene that I passed on my way to work soon after arriving in Heidelberg. This file __only__ contains pixel values, and no metadata. It can still be read using the {menuselection}`File --> Import --> Raw...` command, but to do so you will need to figure out the necessary metadata and input the appropriate values."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:198
msgid "The following points may help:"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:201
msgid "The file contains only a single image, and a single channel."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:202
msgid "The dimensions (width and height) of the image are each a multiple of 100 pixels."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:203
msgid "The data is in 8, 16 or 32-bit format (signed or unsigned)."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:204
msgid "There are no offsets or gaps included."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:205
msgid "The total size of the file is 400 000 bytes."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:207
msgid "__Note:__ The option {guilabel}`Little-endian byte order` relates to whether the bytes of 16 or 32-bit images are arranged from the least-to-most significant, or most-to-least significant. Some types of computer prefer one order, some prefer another, so this is something else the metadata should contain. The difference is similar to how a perfectly respectable number like __twenty-three__ is (quite ludicrously, in my view) spoken as __three-and-twenty__ in German."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:215
msgid "The file size gives you the $$ \\textrm{File size (in bytes)} = \\frac{\\textrm{width} \\times \\textrm{height} \\times \\textrm{bit-depth}}{8} $$ where the division by 8 converts the total number of bits to bytes (since 8 bits make 1 byte). This can be used to make reasonable starting estimates for the width, height and bit-depth, but figuring out which are correct likely still requires some trial-and-error. In the end, the settings you need are:"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:220
msgid "Image type: 16-bit unsigned"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:221
msgid "Width: 500 pixels"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:222
msgid "Height: 400 pixels"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:223
msgid "Little-endian byte order: False"
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:225
msgid "Using these values in the import should result in a reasonable image."
msgstr ""

#: ../../chapters/1-concepts/6-files/imagej.md:227
msgid "Now make sure never to lose your metadata, and you do not need to solve such puzzles often in real life. (Also, any explanations for what exactly was going on in that scene would be welcome.)"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:15
msgid "Python: Files & file formats"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:17
msgid "When it comes to working with images in Python, there are various important packages. You might only need to use one - but it helps to know about the existence of the others."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:20
msgid "To avoid adding lots of extra dependencies to this book, not all the packages are installed here."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:32
msgid "Useful Python packages"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:36
msgid "Pillow"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:38
msgid "[Pillow's authors describe it as 'the friendly PIL fork'](https://pillow.readthedocs.io/en/stable/), where **PIL** is the *Python Imaging Library*."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:40
msgid "It is indeed *quite* friendly, and it does much more than just reading and writing images - even supporting features to draw onto images."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:42
msgid "The main disadvantage of Pillow is that it doesn't work directly with NumPy arrays. Therefore, if it's a NumPy array that you want then you'll need to add in a few extra lines of code to convert the images."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:68
msgid "[imageio](https://imageio.readthedocs.io/en/stable/) is my preferred Python package for most straightforward image reading - and the main one I've used in this book."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:70
msgid "It's also the [recommended alternative to *SciPy*'s deprecated `imread` function](https://docs.scipy.org/doc/scipy-1.1.0/reference/generated/scipy.misc.imread.html#scipy.misc.imread)."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:72
msgid "`imageio.imread(path)` returns a NumPy array automatically. This makes it easy to use for straightforward things, especially when working with 2D images (single-channel or RGB)."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:75
msgid "imageio can use different backends, which includes [Pillow](https://imageio.readthedocs.io/en/stable/_autosummary/imageio.plugins.pillow.html) and [tifffile](https://imageio.readthedocs.io/en/stable/_autosummary/imageio.plugins.tifffile.html) - so you can potentially get the advantages of both through using imageio, while writing less code yourself."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:86
msgid "tifffile"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:88
msgid "[tifffile](https://pypi.org/project/tifffile/) is a small package[^fn_tf] that is very handy if you need to get into the details of reading and writing TIFF images."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:100
msgid "AICSImageIO"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:102
msgid "[AICSImageIO](https://github.com/AllenCellModeling/aicsimageio) is an excellent package for reading lots of image formats in Python - and is particularly strong when it comes to reading multidimensional images and metadata."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:104
msgid "It can even handle a variety of microscopy formats, and optionally use [Bio-Formats](https://www.openmicroscopy.org/bio-formats/)."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:106
msgid "These features, alongside its consistent way of handling pixel sizes and dimensions, make it my main choice for scientific images."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:110
msgid "OpenSlide"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:112
msgid "[OpenSlide](https://openslide.org) is widely used in the world of digital pathology. It's limited to 2D RGB data, but its big benefit is that it supports a range of pyramidal whole slide images."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:117
msgid "Dask"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:119
msgid "[Dask](https://dask.org) is a project you should know about if you're working with big datasets in Python."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:121
msgid "Dask isn't an image reading package, but [dask-image](https://image.dask.org/) includes an `imread` function that can be used if you know you want your image to be in a dask array in the end."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:125
msgid "Napari"
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:127
msgid "Finally, [Napari](https://napari.org) isn't an image reading library either; rather, it's a fantastic open-source, extensible, multidimensional image viewer for Python."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:129
msgid "Napari can bring everything together - working with dask arrays and reading images with plugins, such as [napari-aicsimageio](https://github.com/AllenCellModeling/napari-aicsimageio) and [napari-lazy-openslide](https://github.com/manzt/napari-lazy-openslide)."
msgstr ""

#: ../../chapters/1-concepts/6-files/python.md:90
msgid "Small in that its code is mostly just one file. But it's [a pretty epic file](https://github.com/cgohlke/tifffile/blob/master/tifffile/tifffile.py)."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:15
msgid "Image processing & analysis"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:20
msgid "**Image processing** involves changing images, usually in ways that will help interpretation later"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:21
msgid "**Image analysis** involves converting images into measurements"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:22
msgid "When image analysis is our goal, we almost always need image processing to get there"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:43
msgid "Successfully extracting useful information from microscopy images usually requires triumphing in two main battles."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:45
msgid "The first is to overcome limitations in image quality and make the really interesting image content more clearly visible. This involves **image processing**, the output of which is another image. The second is to compute meaningful measurements, which could be presented in tables and summary plots. This is **image analysis**."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:50
msgid "Our main goal here is analysis -- but processing is almost always indispensable to get us there."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:53
msgid "An image analysis workflow"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:55
msgid "So how do we figure out how to analyze our images?"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:57
msgid "Ultimately, we need some kind of workflow comprising multiple steps that eventually take us from image to results. Each individual step might be small and straightforward, but the combination is powerful."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:60
msgid "I tend to view the challenge of constructing any scientific image analysis workflow as akin to solving a puzzle. In the end, we hope to extract some kind of quantitative measurements that are justified by the nature of the experiment and the facts of image formation. One of the interesting features of the puzzle is that there is no single, fixed solution."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:64
msgid "Although this might initially seem inconvenient, it can be liberating: it suggests there is room for lateral thinking and sparks of creativity. The same images could be analyzed in quite different ways. Sometimes giving quite different results, or answering quite different scientific questions."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:68
msgid "Admittedly, if no solution comes to mind after pondering for a while then such an optimistic outlook quickly subsides, and the 'puzzle' may very well turn into an unbearably infuriating 'problem' -- but the point here is that _in principle_ image analysis _can_ be enjoyable. What it takes is:"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:70
msgid "a modicum of enthusiasm (please bring your own)"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:71
msgid "properly-acquired data, including all the necessary metadata (the subject of Part I)"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:72
msgid "actually *having the tools at your disposal* to solve the puzzle (the subject Part II)"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:74
msgid "If you're a reluctant puzzler then it also helps to have the good luck not to be working on something horrendously difficult, but that is difficult to control."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:76
msgid "Combining processing tools"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:78
msgid "Image processing provides a whole host of tools that can be applied to puzzle-solving. When piecing together processing steps to form a workflow, we usually have two main stages:"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:81
msgid "**Preprocessing**: the stuff you do to clean up the image, e.g. subtract the background, use a filter to reduce noise"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:82
msgid "**Segmentation** the stuff you do to identify the things in the image you care about, e.g. apply a threshold to locate interesting features"
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:84
msgid "Having successfully navigated these stages, there are usually some additional tasks remaining (e.g. making measurements of shape, intensity or dynamics). However, these depend upon the specifics of the application and are *usually* not the hard part. If you can identify what you want to quantify, you're a long way towards solving the puzzle."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:88
msgid "{numref}`fig-workflow` shows an example of how these ideas can fit together."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:159
msgid "A simple image analysis workflow for detecting and measuring spots in an image."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:162
msgid "It won't be possible to cover *all* image processing tools in a book like this. Rather, we will focus on the essential ones needed to get started: thresholds, filters, morphological operations and transforms."
msgstr ""

#: ../../chapters/2-processing/1-processing_and_analysis/processing_and_analysis.md:165
msgid "These are already enough to solve many image analysis puzzles, and provide the framework to which more can be added later."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:15
msgid "ImageJ: Point operations"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:21
msgid "This section introduces image processing with ImageJ. It shows where to find the main point operations, including some tips (and warnings) about their use, along with a few exercises to try them out."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:26
msgid "Before we begin"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:28
msgid "Before we embark on processing pixels, there are a couple of things we need to know how to do in preparation."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:30
msgid "Duplicating images"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:32
msgid "One of the most important ImageJ shortcuts to learn is {kbd}`Shift+D` to **duplicate the image**. This applies the command {menuselection}`Image --> Duplicate...`."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:35
msgid "Being able to quickly duplicate an image matters for two main reasons:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:36
msgid "We often want to process duplicates of an image in different ways, and then combine or compare the results."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:37
msgid "Mistakes happen, and {menuselection}`Edit --> Undo` is rather limited; it can undo *some* processing steps applied to a single image slice, but not always... and it can't undo operations applied to image stacks"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:39
msgid "When working with an image in ImageJ, I almost always have at least one duplicate lingering around for when when things inevitably go wrong."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:41
msgid "But {menuselection}`Image --> Duplicate...` has an extra, hidden bonus: it's supports extracting just a part of the image. This is controlled both by any ROI and by selecting subsets of channels, z-slices or time points where relevant. I frequently use duplication as a way to extract the channel from an image, as a more convenient alternative to {menuselection}`Image --> Color --> Split Channels`."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:50
msgid "Why can't ImageJ's 'Undo' undo much?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:51
msgid "Implementing 'undo' in software is quite tricky. Especially in flexible software that enables the user to do a lot of different things."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:54
msgid "When it comes to image processing, undo effectively requires the software to quietly duplicate the pixel values of an image before any processing step, so that they can be recovered later if needed. For a small image, that can work fine. But for big images (say, 1 GB or more), duplicating that much data could *significantly* slow down the software and potentially result in lots of out-of-memory errors."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:58
msgid "ImageJ provides some very limited undo support for 2D slices, but it's best not to rely on it. In general, it's left up to the user to decide when duplicating is necessary. If you suspect you might regret a processing step, then it's best to always duplicate the image beforehand with {kbd}`Shift+D`."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:65
msgid "Converting to 32-bit"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:67
msgid "The second thing I often do when processing an image in ImageJ is to [convert it to 32-bit floating point](sec_bits_type), using {menuselection}`Image --> Type --> 32-bit`."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:69
msgid "This isn't *always* essential, but we will soon see examples where the type of the image makes a difference to the result. So you should always at least consider converting."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:75
#: ../../chapters/2-processing/2-point_operations/point_operations.md:69
msgid "Point operations for single images"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:77
msgid "Many point operations for single images are found in the {menuselection}`Process --> Math -->` submenu. At the top of the list come the arithmetic operations: {menuselection}`Add...`, {menuselection}`Subtract...`, {menuselection}`Multiply...` and {menuselection}`Divide...`."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:88
msgid "Open the image *Spooked_16-bit.tif*, and apply *only* the following steps:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:90
#: ../../chapters/2-processing/2-point_operations/imagej.md:93
msgid "Measure the mean pixel value of the image"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:91
msgid "Subtract 600 from all pixel values"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:92
msgid "Add 600 to all pixel values"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:95
msgid "*Mathematically*, you should get the same mean measurements. Can you explain the result?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:98
#: ../../chapters/2-processing/2-point_operations/imagej.md:155
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/launch-imagej-js-badge.svg)](https://ij.imjoy.io?open=https://github.com/bioimagebook/practical-data/blob/main/images/Spooked_16-bit.tif)"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:103
msgid "Firstly, the commands you need to run are:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:104
#: ../../chapters/2-processing/2-point_operations/imagej.md:107
msgid "{menuselection}`Analyze --> Measure`, or press {kbd}`M`"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:105
msgid "{menuselection}`Process --> Math --> Subtract...` with the value 600"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:106
msgid "{menuselection}`Process --> Math --> Add...` with the value 600"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:109
msgid "When I do this, I get the following results table:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:113
msgid "The reason the mean values differ is because we have a 16-bit image. After subtraction, any values that were less than 600 become clipped to zero. All these become 600 after the addition, pushing up the overall mean."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:117
msgid "If you didn't see this effect, then I would guess you had the foresight to run {menuselection}`Image --> Type --> 32-bit`. If you do this, the mean values match after all."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:126
msgid "The {menuselection}`Process --> Math --> Log...` and {menuselection}`Process --> Math --> Gamma...` commands implement the log and gamma transforms respectively. The gamma transform is more common, since it contains an adjustable gamma parameter that can be used to tune the effect."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:129
msgid "Beware of the bit-depth with nonlinear transforms!"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:132
msgid "When applying gamma or log transforms to 8-bit or 16-bit images, ImageJ applies some additional (linear) rescaling to the result so that the output falls within the range supported by the image."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:134
msgid "This rescaling isn't needed for 32-bit images. This means that if you apply either command to a 32-bit image then it can seem that the image disappears. You'll need to follow up by using {menuselection}`Image --> Adjust --> Brightness/Contrast...` to reset the LUT display range to see the output properly."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:147
msgid "Explore the use of {menuselection}`Process --> Math --> Gamma...` for enhancing the contrast of *Spooked_16-bit.tif*."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:149
msgid "If you want to see both the human and the ghost, should the gamma value be less than 1, equal to 1, or greater than 1?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:151
msgid "**Tip:** To get a feeling for how the values are changing, create a histogram of the image first and press the {guilabel}`Live` button on the histogram. Then run the gamma command, turn on the {guilabel}`Preview` option and adjust the slider. You should now see a live update of how changing the gamma affects the pixel values."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:160
msgid "The gamma needs to be less than 1."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:162
msgid "When the gamma is equal to 1, it isn't doing anything at all. When it is greater than 1, it's applying a non-linear adjustment -- but not one that really helps in this case."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:170
#: ../../chapters/2-processing/2-point_operations/point_operations.md:127
msgid "Image inversion"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:172
msgid "The {menuselection}`Edit --> Invert` command implements image inversion."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:175
msgid "Inverting images or inverting LUTs?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:178
msgid "{menuselection}`Edit --> Invert` should not be confused with the {menuselection}`Image --> Lookup Tables --> Invert LUT` command, which inverts the LUT but *does nothing to the pixel values!*"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:180
msgid "Moreover, whether the LUT is inverted can be saved inside the file -- and so you could potentially open an image and find its LUT was inverted before you even started to do anything, and thereby misjudge whether structures are really brighter or darker than everything else."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:182
msgid "{menuselection}`File --> Open samples --> Blobs` is an example of this. It took a long time before I realized that the pixel values inside the blobs are higher than the background, because of the sneaky inverted LUT. As is often the case, the signs of an inverted LUT are evident in the text at the top of an image window."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:193
msgid "{menuselection}`Edit --> Invert` works differently when applied to different image types. Like in the 8-bit case, pixel values are always subtracted from some 'maximum'."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:196
msgid "How this maximum is determined for 16 and 32-bit images in ImageJ?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:198
msgid "**Note:** the methods used for 16 and 32-bit images are different from one another!"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:200
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/Spooked_16-bit.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/happy_cell.tif)"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:204
msgid "When I first wrote this question, to invert a 16-bit image pixel were subtracted from *the maximum value within the original image*. This is also true for stacks: the maximum value in the entire stack is found."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:207
msgid "Since ImageJ v1.53k, the maximum value of 65535 is used... unless you happen to have a different {guilabel}`Unsigned 6-bit range` value specified via the {guilabel}`Set` button via the *Brightness & Contrast* dialog. I only know about this sneaky alternative option through the [ImageJ release notes](https://imagej.nih.gov/ij/notes.html)."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:210
msgid "For 32-bit image inversion, the pixels are subtracted from the *display maximum*, i.e. whatever maximum is set in the {menuselection}`Image --> Adjust --> Brightness/Contrast...` dialog box. Consequently, *inverting a 32-bit image can give different results each time it is applied if the contrast settings are not kept the same!*"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:213
msgid "I personally dislike this unpredictable weirdness. I would happily apply {menuselection}`Edit --> Invert` to an 8-bit image. For anything else, I'd generally rather convert to 32-bit and multiply by -1 -- so that I know the results should be repeatable, regardless of brightess & contrast settings."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:223
msgid "The Image Calculator"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:225
msgid "{menuselection}`Process --> Math --> Image Calculator...` is used to combine two images in various ways. It is one of ImageJ's most indispensable commands."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:231
msgid "The *Image Calculator...* dialog"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:235
msgid "But beware of the bit-depth and type! If any of the original images are 8 or 16-bit, then the result might require clipping or rounding, in which case selecting the option to create a {guilabel}`32-bit (float) result` may be necessary to get the expected output."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:243
msgid "{menuselection}`Process --> Math --> Image Calculator...` finally makes it possible for us to check whether the pixel values of two images are all identical -- without relying on summary measurements or histograms."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:245
msgid "Use it to determine which two of the images *Same_1.tif*, *Same_2.tif* and *Same_3.tif* are identical in terms of pixel values."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:247
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?open=https://github.com/bioimagebook/practical-data/blob/main/images/Same_1.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/Same_2.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/Same_3.tif)"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:251
msgid "My preferred way to check this is to subtract the images from one another, making sure that the result is 32-bit (in case there are negative values). Doing this should reveal something hidden in the image *Same_2.tif*. Note that the contrast settings differ between *Same_1.tif* and *Same_3.tif*, so they may _look_ different."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/imagej.md:254
msgid "(Note that the calculator's {guilabel}`Difference` or {guilabel}`Divide` commands could also be used. {guilabel}`XOR` would work as well, but its output is harder to interpret since it involves comparing individual bits used to store each pixel value and gives an output where all matching bits are 0 and all non-matching bits are 1. When converted back into actual decimal values and then to colors for us to look at, this can appear strange. But at least if the resulting image is not completely black then we know that the original input images were not identical.)"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:16
msgid "Point operations"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:21
msgid "**Point operations** are mathematical operations applied to individual pixel values"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:22
msgid "Point operations can be performed using a **single image**, an **image and a constant**, or **two images of the same size**"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:23
msgid "Some **nonlinear** point operations change the relationships between pixels in a way that can be useful to enhance contrast -- but should be used with caution"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:44
msgid "A step used to process an image in some way can be called an **operation**."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:46
msgid "The simplest operations are **point operations**, which act on individual pixels. Point operations change each pixel in a way that depends upon its own value, but not upon where it is in the image nor upon the values of other pixels. This is in contrast to **neighborhood operations**, which calculate new pixel values based upon the values of pixels nearby."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:50
msgid "While not immediately very glamorous, point operations often have indispensable roles in more interesting contexts -- and so it's essential to know how they are used, and what complications to look out for."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:53
msgid "Isn't modifying pixels bad?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:56
msgid "Part I stressed repeatedly that modifying pixels is a bad thing. Since image processing is all about changing pixel values, it's time to add a bit more nuance:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:59
msgid "**Modifying pixel values is bad -- unless you have a good reason**."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:61
msgid "A 'good reason' is something you can justify based upon the image data. Something you could confidently include in a journal article describing how you analyzed your image, and convince a reviewer was sensible."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:64
msgid "You should also make sure to apply the processing to a **duplicate** of the image, and keep the original file. That way you can always return to the original data if you need to."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:71
msgid "Arithmetic"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:73
msgid "Pixel values are just numbers. When we have numbers, we can do arithmetic."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:76
msgid "It should therefore come as no surprise that we can take our pixel values and change them by adding, subtracting, multiplying or dividing by some other value. These are the simplest point operations."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:79
msgid "We encountered this idea earlier when we saw that multiplying our pixel values could [increase the brightness](sec_images_luts). I argued that this was a *very bad thing* because it changes our data. Our better alternative was to change the LUT instead."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:83
msgid "Nevertheless, there are sometimes 'good reasons' to apply arithmetic to pixel values -- better than simply brightening the appearance. Examples include:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:85
msgid "Subtracting a constant offset added by a microscope before quantifying intensities"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:86
msgid "See {ref}`chap_macro_simulating`"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:87
msgid "Dividing by a constant so that you can convert bit-depth without clipping"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:88
msgid "See {ref}`chap_bit_depths`"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:90
msgid "**However**, we need to keep in mind that we're not dealing with abtract maths but rather bits and bytes. Which makes the next question particularly important."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:98
msgid "Suppose you add a constant to every pixel in the image. Why might subtracting the same constant from the result not give you back the image you started with?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:103
msgid "If you add a constant that pushes pixel values outside the range supported by the bit-depth (e.g. 0–255 for 8-bit), then the result cannot fit in the image. It's likely to be clipped to the closest possible value instead. Subtracting the constant again does not restore the original value."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:107
msgid "For example: 200 *(original value)* + 100 *(constant)* &rarr; 255 *(closest valid value)*. <br/> But then 255 - 100 &rarr; 155."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:115
msgid "Based upon this, an important tip for image processing is:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:117
msgid "Convert integer images to floating point before manipulating pixels"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:120
msgid "A 32-bit (or even 64-bit) floating point image is much less likely to suffer errors due to clipping and rounding. Therefore the first step of any image processing is often to convert the image to a floating point format."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:123
msgid "See {ref}`chap_bit_depths` for details."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:129
msgid "Inverting an image effectively involves 'flipping' the intensities: making the higher values lower, and the lower values higher."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:131
msgid "In the case of 8-bit images, inverted pixel values can be easily computed simply by subtracting the original values from the maximum possible -- i.e. from 255."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:133
msgid "Why is inversion useful?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:135
msgid "Suppose you have a good strategy designed to detect bright structures, but it doesn't work for you because your images contain dark structures. If you invert your images first, then the structures become bright -- and your detection strategy might now succeed."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:182
msgid "The effect of image and LUT inversion. Note that each histogram appears to be a mirror image of the other. Also, the image is clipped (sorry)."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:186
msgid "Defining the 'maximum' when inverting an image"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:188
msgid "Inverting an 8-bit (unsigned integer) image generally means subtracting all pixel values from 255, because 255 is the maximum supported by the image type and bit-depth."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:190
msgid "The 'maximum' is not always defined in this way. For a 32-bit or 64-bit image (either integer or floating point), the maximum possible value is *huge*, and using that would result in exceedingly large pixel values. Therefore the 'maximum' is usually defined in some other way rather than based on the image type, such as by taking the maximum pixel value found within the image."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:194
msgid "Because I don't like letting the software decide what maximum to use, I often cheat: I multiply the pixels by -1 (ensuring the image is floating point). This retains the key properties of image inversion: it flips the high and low values, while retaining all the relative diffences between values."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:200
msgid "Nonlinear contrast enhancement"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:202
msgid "With arithmetic operations we change the pixel values, usefully or otherwise, but (assuming we have not clipped our image in the process) we have done so in a **linear** way. At most it would take another multiplication and/or addition to get us back to where we were. Because a similar relationship between pixel values exists, we could also adjust the brightness and contrast LUT so that it does not *look* like we have done anything at all."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:206
msgid "**Nonlinear** point operations differ in that they affect relative values differently depending upon what they were in the first place. These are particularly useful for contrast enhancement."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:209
msgid "When we changed the brightness and contrast in {ref}`sec_images_luts`, we were making linear adjustments. For a grayscale LUT, this meant we chose the pixel value to display as black and the pixel value to display as white, with each value in between mapped to a shade of gray along a straight line ({numref}`fig-nonlinear_contrast`A)."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:212
msgid "We could optionally use a nonlinear mapping values between values and shades of gray, but most software doesn't make it straightforward to change LUTs in sufficiently complicated ways. An easier approach is to duplicate the image and apply any non-linear adjustments to the pixel values themselves, and then map them to shades of gray in the usual (linear) way."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:215
msgid "Common nonlinear transforms are to take the logarithm of the pixel value ({numref}`fig-nonlinear_contrast`B), or replace each value $p$ with $p^\\gamma$ where $\\gamma$ is the *gamma* parameter that can be adjusted depending upon the desired outcome ({numref}`fig-nonlinear_contrast`B-D)."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:270
msgid "Nonlinear transforms applied to a simple 'ramp' image, consisting of linearly increasing pixel values. Replacing each pixel with its log or gamma-adjusted value has the effect of compressing either the lower or higher intensities closer together to free up more gray levels for the others. Note that, here we assume an 8-bit input image and have incorporated some necessary rescaling for an 8-bit output (based on the approach used by ImageJ)."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:274
msgid "If all this sounds a dubious and awkward, be assured that it is: nonlinear transforms are best avoided whenever possible."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:276
msgid "However, there is once scenario when they can really help: displaying an image with a **high dynamic range**, i.e. a big difference between the largest and smallest pixel values."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:278
msgid "{numref}`fig-point_gamma_spooked` shows this in action. Here, the pixel values associated with the main character are all quite high. However, the values associated with the ghostly figure are all very low. There are no linear contrast settings with a standard grayscale LUT that make it possible to see both figures with any detail simultaneously. However, log or gamma transforms make this possible."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:321
msgid "The application of nonlinear contrast enhancement to an image with a wide range of values. *(Top row)* In the original image, it's not possible to see details in both the foreground and background simultaneously. *(Bottom row)* Two examples of nonlinear techniques that make details visible throughout the image."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:326
msgid "Avoid image manipulation!"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:329
msgid "When creating figures for publication, changing the contrast in some linear manner is normally considered fine (assuming that it has not been done mischievously to make some inconvenient, research-undermining details impossible to discern)."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:331
msgid "**But if any nonlinear operations are used, these should always be noted in the figure legend!**"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:333
msgid "This is because, although nonlinear operations can be very helpful when used with care, they can also easily mislead -- exaggerating or underplaying differences in brightness."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:337
msgid "Point operations & multiple images"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:339
msgid "Instead of applying arithmetic using an image and a constant, we could also use two images of the same size. These can readily be added, subtracted, multiplied or divided by applying the operations to the corresponding pixels."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:342
msgid "This is a technique that is used *all the time* in image processing. Applications include:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:345
msgid "subtracting varying backgrounds"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:346
msgid "computing intensity ratios"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:347
msgid "masking out regions"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:348
msgid "**and much more...**"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:350
msgid "We will combine images in this way throughout the rest of the handbook."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:397
msgid "In the two 32-bit images shown here, white pixels have values of one and black pixels have values of zero (gray pixels have values somewhere in between)."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:405
msgid "What would be the result of multiplying the images together? And what would be the result of dividing the left image by the right image?"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:410
msgid "Multiplying the images effectively results in everything outside the white region in the right image being removed from the left image (i.e. set to zero)."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:418
msgid "Dividing has a similar effect, except that instead of becoming zero the masked-out pixels will take one of three results, depending upon the original pixel's value in the left image:"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:420
msgid "if it was _positive_, the result is $+\\infty$ (shown here as yellow)"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:421
msgid "if it was _negative_, the result is $-\\infty$"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:422
msgid "if it was zero, the result is `NaN` ('not a number' -– indicating 0/0 is undefined; shown here as red)"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:424
msgid "These are special values that can be contained in floating point images, but not images with integer types."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:462
msgid "Adding noise"
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:465
msgid "Fluorescence images are invariably noisy. The noise appears as a graininess throughout the image, which can be seen as arising from a random noise value (positive or negative) being added to every pixel."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:468
msgid "This is equivalent to adding a separate 'noise image' to the non-existent cleaner image that we would prefer to have recorded. If we knew the pixels in the noise image then we could simply subtract it to get the clean result -- but, in practice, their randomness means that we do not."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:477
msgid "Simulating imperfect image acquisition by adding noise to an 'ideal' image."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:480
msgid "Despite the fact that noise is undesirable, adding noise images can be extremely useful when developing and validating image analysis methods."
msgstr ""

#: ../../chapters/2-processing/2-point_operations/point_operations.md:482
msgid "We can use it to create simulations in which the noise behaves statistically just like real noise, and add it to clean images. Using these simulations we can figure out things like how processing steps or changes during acquisition will affect or reduce the noise, or how sensitive our measurement strategies are to changes in image quality (see {ref}`chap_filters`, {ref}`chap_formation_noise` and {ref}`chap_macro_simulating`)."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:15
msgid "ImageJ: Thresholding"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:35
msgid "Here, we will explore some ImageJ's methods to apply thresholds to images, generating binary images, labeled images and ROIs. We will also confront some of the associated complications."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:38
#: ../../chapters/2-processing/3-thresholding/thresholding.md:177
msgid "Global thresholding"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:40
msgid "The main thresholding command in ImageJ is {menuselection}`Image --> Adjust --> Threshold...`, with the shortcut {kbd}`Shift+T`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:42
msgid "This opens a *Threshold* dialog that allows you to identify pixels above a threshold, below a threshold, or falling between two thresholds. These options are controlled using a combination of the threshold sliders and the {guilabel}`Dark background` checkbox. There is also a drop-down menu allowing you to select from a list of automated thresholding methods."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:51
msgid "During preview, the pixels that are considered foreground are shown in red by default (it's possible to change this, but I never do). After choosing suitable thresholds, pressing {guilabel}`Apply` produces a binary image. This replaces the original, so it may be wise to duplicate the image first."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:55
msgid "Binary images in ImageJ"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:58
msgid "Although only one 1 bit is really needed for each pixel in a binary image, the implementation in ImageJ currently uses 8 bits -- and so the actual pixel values allowed are 0 and 255. To complicate matters, ImageJ also permits _either_ of these to represent the foreground, with the choice hidden away under {menuselection}`Process --> Binary --> Options...`, and 0 taken to be 'black' and 255 'white'. Personally, I prefer for white to represent the foreground (i.e. the interesting things we have detected), and so I will assume that the {guilabel}`Black background` option has been checked."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:63
msgid "Nevertheless, you should be aware that this convention is not adopted universally. Furthermore, if you choose {guilabel}`Invert LUT` then the colors are flipped anyway – so yet more confusion arises. Therefore if you find that any processing of binary images gives odd results, be sure to check the binary options and LUT status."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:68
msgid "The *Threshold* dialog is good for interactively exploring different automated thresholding methods, but it can be hard to systematically compare them. {menuselection}`Image --> Adjust --> Auto Threshold...` helps with this, by providing an option to try *all* of the methods."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:76
msgid "Applying this to ImageJ's famous *blobs.gif* reveals that not all methods work equally well:"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:83
msgid "Automated threshold methods"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:85
msgid "The various automated thresholds are described at https://imagej.net/Auto_Threshold, often with references to the original published papers upon which they are based."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:90
msgid "Creating objects"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:92
msgid "Once we have a binary image, the next step is to identify objects for further exploration."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:94
msgid "Generating & measuring ROIs"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:96
msgid "ROIs are a good way to represent objects in ImageJ, because they are easy to measure. In 2D, there are several options to generate ROIs from a thresholded image, each with slightly different applications:"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:99
msgid "Click on an object with the *Wand tool* <img src=\"../../../images/imagej/icons/wand.png\" /> -- this is good for interactively choosing one connected region."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:100
msgid "{menuselection}`Edit --> Selection --> Create Selection` -- this makes a single ROI containing all the foreground pixels. Disconnected regions can be separated by adding the ROI to the *ROI Manager* and choosing {guilabel}`More >> Split`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:102
msgid "{menuselection}`Analyze --> Analyze Particles...` -- this detects and measures all the foreground regions as individual objects, optionally filtering out objects based on shape or area."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:104
msgid "Creating ROIs without applying a threshold"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:107
msgid "The *Wand tool* <img src=\"../../../images/imagej/icons/wand.png\" />, {menuselection}`Edit --> Selection --> Create Selection` & {menuselection}`Analyze --> Analyze Particles...` can also be used when a threshold is being previewed on an image, but it has not yet been converted to binary. Therefore you may not need to press {guilabel}`Apply` in the *Threshold* dialog at all."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:110
msgid "In fact, because it's not 100% clear whether black or white pixels represent the foreground in an ImageJ binary image, I tend to set a threshold even on an image that *is* already binary. That way I can visualize what any of these commands will treat as foreground: with the default thresholding display, the foreground is highlighted in red."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:114
msgid "I like the fact that {menuselection}`Edit --> Selection --> Create Selection` provides a very quick way to convert a thresholded region to a single ROI. I most often use it in combination with {menuselection}`Edit --> Selection --> Restore Selection` to visualize what has been detected on top of another image. I might not necessarily *use* the single ROI for measurements in the end, but it can be very good for orientation."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:118
msgid "When you want to measure multiple objects quickly, {menuselection}`Analyze --> Analyze Particles...` is arguably the most automated and versatile option. Its various options also make it possible to ignore regions that are particularly small or large, straight or round (using a {guilabel}`Circularity` metric). It can output summary results and add ROIs for each region to the *ROI Manager*."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:127
msgid "Redirecting measurements"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:131
msgid "Although binary images can show the shapes of things to be measured, pixel intensity measurements made on a binary image are not very helpful. You could use the above techniques to make ROIs from binary images, then apply those to the original image to get meaningful measurements."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:134
msgid "It's possible to do this by changing the {guilabel}`Redirect to:` option under {menuselection}`Analyze --> Set Measurements...`, which redirects measurements to be made on a specific image. Setting a redirection image before running {menuselection}`Analyze --> Analyze Particles...` means that the ROI 'particles' can be detected on one image and measured on a different image"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:137
msgid "I don't usually recommend this, since I imagine I might forget to reset the {guilabel}`Redirect to:` option when I am done. I'd rather add my ROIs to the *ROI Manager* and transfer them that way."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:142
msgid "Caution with holey ROIs"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:146
msgid "Historically, there has been a problem with my preferred approach to use the *ROI Manager* output from {menuselection}`Analyze --> Analyze Particles...`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:148
msgid "It seems that {menuselection}`Analyze Particles...` handles holes correctly when making measurements by itself, but by default it would generate ROIs that lacked holes. This meant that if you would measure the ROIs later you could get different results, because the ROIs included extra pixels that were actually excluded (as holes) in the thresholded image."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:155
msgid "Different results when using {menuselection}`Analyze --> Analyze Particles...` directly, and then subsequently measuring the ROI that it generated. The image is binary, so the mean value should be 255 if only the above-threshold pixels are measured."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:158
msgid "**However**, there is a solution -- which I only learned when writing about it here. Since ImageJ v1.53g, there is a {guilabel}`Composite ROIs` checkbox when using {menuselection}`Analyze Particles...`. If this is turned **on**, then ROIs with holes are generated as expected."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:166
msgid "Fixing the problem with holey regions by using {guilabel}`Composite ROIs`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:169
msgid "This demonstrates the need to be cautious with any image analysis software, and to check out the various options associated with even common commands. They aren't *always* doing what you might expect."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:175
msgid "Generating labeled images"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:177
msgid "ROIs are not the only way to represent image objects: sometimes labeled images are more useful."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:179
msgid "{menuselection}`Analyze --> Analyze Particles...` can generate labeled images by using the {guilabel}`Show: Count Masks` option. This will generate a new image in which each pixel has a unique integer value indicating the number of the object it is part of -- or zero if it is in the background. With a suitably colorful LUT (often {menuselection}`Image --> Lookup Tables --> Glasbey`), this can create a helpful and cheerful display of objects ({numref}`fig-blobs_binary_label`)."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:187
msgid "Creating a labeled image with {menuselection}`Analyze --> Analyze Particles`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:195
msgid "[Connectivity](sec_thresholds_connectivity) (4 or 8) is an important consideration when converting a binary image to objects, since it can have a major impact on the number and size of objects."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:197
msgid "Work out what kind of connectivity is used by"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:198
msgid "{menuselection}`Analyze --> Analyze Particles...`"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:199
msgid "the *Wand tool* <img src=\"../../../images/imagej/icons/wand.png\" />"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:201
msgid "**Note:** You can investigate this by applying the commands/tools to a binary image that has some diagonally connected pixels. One way to do this is by thresholding a suitable image, another is to use the *Brush tool* <img src=\"../../../images/imagej/icons/brush.png\" /> to draw your own pixels in the binary image."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:204
#: ../../chapters/2-processing/3-thresholding/imagej.md:284
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/)"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:210
msgid "At the time of writing, {menuselection}`Analyze --> Analyze Particles...` uses 8-connectivity."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:212
msgid "For the *Wand tool* the right answer will depend upon the setting you see if you double-click the tool. There are three options: 4-connectivity, 8-connectivity and 'legacy' (where 'legacy' seems to behave a bit like 8-connectivity)."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:224
#: ../../chapters/2-processing/3-thresholding/thresholding.md:1061
msgid "Local thresholding"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:226
msgid "A few methods to perform local thresholding can be found under {menuselection}`Image --> Adjust --> Auto Local Threshold`. The dialog again provides the option to try all of them."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:234
msgid "Using automated local filters is complicated by the fact that window sizes and parameters need to be tuned. What these mean in each case is described at https://imagej.net/Auto_Local_Threshold"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:237
msgid "Currently, ImageJ's local thresholding also requires that the image is converted to 8-bit. This should be done with some caution, since it can involve surreptitiously incorporating the [brightness & contrast settings](sec_bit_depths_converting) into the thresholding."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:240
msgid "For these reasons, I tend to avoid local thresholding."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:248
msgid "Explore several automated methods of thresholding the different channels of {menuselection}`File --> Open samples --> HeLa Cells`, using both local and global automated thresholds, to draw your own conclusions about which methods you might prefer for different images."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:257
msgid "Addendum: Practical issues"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:259
msgid "We end this section with a brief discussion of a few non-obvious practical issues that impact thresholding, related to bit-depths and image types."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:262
#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:283
msgid "Using NaNs"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:264
msgid "The first issue appears when you click {guilabel}`Apply` in the {menuselection}`Image --> Adjust --> Threshold...` dialog box for a 32-bit image. This leads to a prompt asking whether to {guilabel}`Set Background Pixels to NaN`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:267
msgid "If this is chosen, a binary image is no longer created. Instead, thresholding results in an image in which the foreground pixels retain their original values, while background pixels are **_NaN_**, or **_Not A Number_**."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:270
msgid "*NaN* is a special value that can only be stored in floating point images, which ImageJ ignores when making measurements later. It is therefore used to mask out regions, while preserving meaningful pixel values elsewhere."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:273
msgid "This is an advanced option that is *potentially* useful, but can be a bit challenging to work with. You have to be extra cautious when using an image containing NaNs, since some commands might behave in surprising ways."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:281
msgid "Create an image including NaN pixels, then measure some ROIs drawn on it. Are area measurements affected by whether NaNs are present or not?"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:290
msgid "They are! If you measure the area of an image containing NaNs, the result is less than if you measure the area of the same image converted to 8-bit -- since only the non-NaN parts are included. If you measure a region containing NaNs only, the area is 0."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:302
msgid "Through experiment or guesswork, what do you suppose happens to NaNs with a 32-bit image is converted to 8-bit or 16-bit?"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:307
msgid "Since NaN is not an integer, it cannot be stored in an 8-bit or 16-bit unsigned integer image. Instead, all NaNs simply become zero."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:315
msgid "Histogram binning"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:317
msgid "The second way in which bit-depths and types matter is that histograms of images > 8-bit involve _binning_ the data. For example, with a 32-bit image it would probably not make sense to create a histogram that has separate counts for all possible pixel values: in addition to counts for pixels with exact values 1 and 2, we would have thousands of counts for pixels with fractions in between and most of these counts would be 0."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:320
msgid "Instead, the histogram is generated by dividing the total data range (maximum – minimum pixel values) into 256 separate _bins_ with equal widths, and counting how many pixels have values falling into the range of each bin. It's therefore like a subtle conversion to 8-bit precision for the threshold calculation, but without actually changing the original data. The same type of conversion is used for 16-bit images -- _unless_ you use the {menuselection}`Image --> Adjust --> Auto Threshold` command, which can use a full 16-bit histogram with 65536 bins."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:324
msgid "This is where the {guilabel}`Don't reset range` option in ImageJ's thresholding dialog becomes relevant for 16-bit or 32-bit images, when used in combination with the {guilabel}`Auto` button."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:325
msgid "If {guilabel}`Don't reset range` **is selected**, then the binning uses the current minimum and maximum values in the brightness/contrast dialog"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:326
msgid "If {guilabel}`Don't reset range` **is *not* selected**, then the binning *resets* the minimum and maximum values in the brightness/contrast dialog before using them"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:328
msgid "Personally, I find this confusing; I don't like the brighness/contrast impacting thresholds, and my poor brain even struggles to process the negative in the {guilabel}`Don't reset range` to get an intuitive feeling for what effect the option will really have. And what makes things worse is that ImageJ's behavior in this regard has changed across versions, so there's a chance that any specific advice I give here won't match the version you're using anyway."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:331
msgid "I know I'm not alone in being confused, since this has been the subject of a [long discussion on the image.sc forum](https://forum.image.sc/t/auto-threshold-calculation-and-bright-and-contrast-auto-adjust-issue/19301). So the main message is: be aware that binning happens, and keep on the lookout for any unexpected effects that the brightness/contrast sliders might sneakily have on thresholding."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:348
msgid "Explore setting thresholds with and without {guilabel}`Don't reset range` selected for the image {menuselection}`File --> Open Samples --> M51 Galaxy (16-bits)`, and pressing the {guilabel}`Auto` button to determine a threshold."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:350
msgid "Keep {menuselection}`Image --> Adjust --> Brightness/Contrast...` open as you explore, so you can make adjustments before calculating the thresholds."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:357
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/open-in-imagej-js-badge.svg)](https://ij.imjoy.io/?run=https://gist.github.com/petebankhead/c5d2075777c458c70c69a1f2c8b37391)"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:362
msgid "This image shows a potential use of the {guilabel}`Don't reset range` option -- used cautiously."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:369
msgid "Thresholding a 16-bit image with and without 'Don't reset range' selected."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:382
msgid "What are the implications of using a 256-bin histogram for thresholding a 32-bit image?"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:384
msgid "In particular, how might any outlier pixels affect the accuracy with which you can define a threshold -- automatically or manually?"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:386
msgid "To explore this, you can use the extreme example of *cell_outlier.tif* along with the {menuselection}`Image --> Adjust --> Threshold...` command."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:388
msgid "How could you (manually) reduce the impact of any problems you find?"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:390
msgid "**Note:** {menuselection}`Analyze --> Histogram` lets you investigate the image histogram with different numbers of bins -- but any changes you make here will not be reflected in the histogram actually used for thresholding."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:392
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/launch-imagej-js-badge.svg)](https://ij.imjoy.io?open=https://github.com/bioimagebook/practical-data/blob/main/images/cell_outlier.tif)"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:399
msgid "First, a positive implication of using a 256-bit histogram for thresholding is that it can be fast: more bins add to the computations involved. Also, creating too many bins has the result of making most of them zero -- potentially causing some automated threshold-determination algorithms to fail."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:402
msgid "A negative implication is that using 256 bins means that only 256 different thresholds are possible: that is, if your image range is 0–25500, then the thresholds you could get are 0, 100, 200, ... 25500. If the optimal threshold is really 150, this will not be found. But usually if your range of pixel values is this large, you do not need a very fine-grained threshold for acceptable results anyway."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:406
msgid "This changes if you have outliers. A single extreme pixel -- which might occur when a pixel in a CCD camera is somehow 'broken' -- can cause most other pixels in the image to be squeezed into only a few bins. Then the histogram resolution might really be too small for reasonable thresholding."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:410
msgid "It's a sufficiently obscure problem that hopefully it won't bother you. However, if you do experience the issue then two possible ways to overcome it are:"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:413
msgid "Adjust the brightness/contrast sliders and ensure that {guilabel}`Don't reset range` **is** selected. This is the benefit of the option existing."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/imagej.md:414
msgid "Convert the image to 8-bit manually yourself. This allows you to effectively choose the range of the histogram bins (using {menuselection}`Brightness/Contrast...`; see {ref}`Types & bit-depths<sec_bit_depths_converting>`) Since the threshold is made using 256 bins, you are not really losing any information that was not going to be lost anyway."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:16
#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:86
msgid "Thresholding"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:21
msgid "**Image segmentation** is the process of detecting **objects** in an image"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:22
msgid "**Global thresholding** identifies pixel values above or below a particular threshold"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:23
msgid "The choice of threshold can introduce **bias**"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:24
msgid "**Automated thresholding methods** can often determine a good threshold based upon the **image histogram** and **statistics** -- but only if certain assumptions are met"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:25
msgid "Thresholding is more powerful when combined with **filtering & subtraction**"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:46
msgid "Before we can measure anything in an image, we first need to detect it."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:48
msgid "Sometimes, 'detection' might involve [manually drawing regions of interest (ROIs)](chap_rois). However, this laborious process does not scale very well. It can also be rather subjective."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:52
msgid "In this chapter, we will begin to explore alternative ways to identify **objects** within images. An 'object' is something we want to detect; depending upon the application, an object might be a nucleus, a cell, a vessel, a person, a bird, a car, a helicopter... more or less anything we might find in an image."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:55
msgid "This process of detecting objects is called **image segmentation**. If we can automate image segmentation, this is not only likely to be much faster than manually annotating regions but should also give more reproducible results."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:61
msgid "Binary & labeled images"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:63
msgid "Image objects are commonly represented using **binary images**."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:65
msgid "Each pixel in a binary image can have one of two values. Usually, these values are 0 and 1. In some software (including ImageJ) a binary image has the values 0 and 255, but this doesn't really make any difference to how it is used: the key point for our purposes is that one of the values represents the foreground (i.e. pixels that are part of an object), and the other value represents the background."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:69
msgid "For the rest of this chapter, we will assume that our binary images use 0 for the background (shown as black) and 1 for the foreground (shown as white)."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:71
msgid "This is important: if we can generate a binary image in which all our objects of interest are in the foreground, we can then use this binary image to help us make measurements of those objects."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:73
msgid "One way to do this involves identifying individual objects in the binary image by labeling **connected components**. A connected component is really just a connected group of foreground pixels, which together represent a distinct object. By labeling connected components, we get a **labeled image** in which the pixels belonging to each object have a unique integer value. All the pixels with the same value belong either to the background (if the value is 0) or to the same object."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:78
msgid "If required, we can then trace the boundaries of each labeled object to create **regions of interest (ROIs)**, such as those used to make measurement in ImageJ and other software."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:109
msgid "Examples of a grayscale (blobs.gif), binary and labelled image. In (C), each label has been assigned a unique color for display. In (D), ROIs have been generated from (C) and superimposed on top of (A). It is common to use a LUT for labeled images that assigns a different color to each pixel value."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:115
msgid "For that reason, a lot of image analysis workflows involve binary images along the way. Most of this chapter will explore the most common way of generating a binary image: **thresholding**."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:149
msgid "Connectivity"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:152
msgid "Identifying multiple objects in a binary image involves separating distinct groups of pixels that are considered 'connected' to one another, and then creating a ROI or label for each group. Connectivity in this sense can be defined in different ways. For example, if two pixels have the same value and are immediately beside one another (above, below, to the left or right, or diagonally adjacent) then they are said to be _8-connected_, because there are 8 different neighboring locations involved. Pixels are _4-connected_ if they are horizontally or vertically adjacent, but _not_ only diagonally."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:157
msgid "The choice of connectivity can make a big difference in the number and sizes of objects found, as the example on the right shows (distinct objects are shown in different colors)."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:165
msgid "What do you suppose _6-connectivity_ and _26-connectivity_ refer to?"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:169
msgid "6-connectivity is similar to 4-connectivity, but in 3D. If all 3D diagonals are considered, we end up with each pixel having 26 neighbors."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:179
msgid "The easiest way to segment an image is by applying a **global threshold**. This identifies pixels that are above or below a fixed threshold value, giving a binary image as the output."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:182
msgid "Global thresholding can be thought of as a [point operation](chap_point_operations) because the output is based solely on the value of each pixel, and not its location or its neighbors. For a global threshold to work, the pixels inside objects need to have higher or lower values than the other pixels. We will look at image processing tricks to overcome this limitation later, but for now we will focus on examples where we want to detect objects have values that are clearly distinct from the background -- and so global thresholding could potentially work."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:188
msgid "Thresholding using histograms"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:192
msgid "It's possible to tell quite a lot about an image just by looking at its histogram."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:194
msgid "Take the following example:"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:232
msgid "Even without seeing the image, we can make some educated guesses about its contents."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:234
msgid "Firstly, there is a large peak to the left and a much shallower peak to the right. This suggests that there are at least two distinct regions in the image. Since the background of an image tends to contain many pixes with similar values, I would guess that we might have an image with a dark background."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:238
msgid "In any case, a threshold around 20-25 looks like it would be a good choice to separate the regions... whatever they may be."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:240
msgid "If we then look at the image, we can see that we have in fact got a fluorescence image depicting two nuclei. Applying a threshold of 20 does achieve a good separation of the nuclei from the background: a successful segmentation."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:268
msgid "A simple fluorescence image containing two nuclei. We could determine a potentially useful threshold based only on looking at the histogram."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:273
msgid "Admittedly, that was a particularly easy example. We should try a slightly harder one."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:300
msgid "We still have a large peak, but this time it is towards the right. So I would guess a light background rather than a dark one."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:303
msgid "But the problem is that we seem to have *two* shallower peaks to the left. That suggests at least three different classes of pixels in the image."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:306
msgid "From visual inspection, we might suppose a threshold of 140 would make sense. Or perhaps around 220. It isn't clear."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:310
msgid "This time, we *do* need to look at the image to decide. Even then, there is no unambiguously 'correct' threshold. Rather, the one we choose depends upon whether our goal is to identify the entire leaf or rather just the darkest region."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:343
msgid "An image where evaluating the histogram suggests two candidate thresholds. The 'correct' threshold depends upon the desired outcome. Note that here we identify pixels *below* the threshold value, rather than above, because the background is ligher."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:347
msgid "Histograms can help us choose thresholds"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:350
msgid "Histograms can be really useful when choosing threshold values -- but we need to also incorporate knowledge of *why* we are thresholding."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:355
msgid "The importance of the threshold choice"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:357
msgid "We've seen that histograms can help us identify suitable thresholds, but they don't absolve us of the need to think. This is particularly evident when objects are not very distinct. The exact choice of threshold can then be crucial."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:361
msgid "{numref}`fig-thresholds_manual` shows an example where the goal is to detect the bright spots (lysosomes). No single global threshold can give us perfect results, but at first glance many different thresholds can appear to give *somewhat* sensible results. The histogram gives, at best, a vague hint where a good threshold may lurk."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:425
msgid "Applying different manually-chosen thresholds to the same image can give quite different results."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:430
msgid "I would like to convey three main messages from {numref}`fig-thresholds_manual`:"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:432
msgid "The **choice of threshold is crucial**, influencing the numbers *and* areas of spots"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:433
msgid "A **threshold that is too low** tends to **make structures bigger & merge some together**"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:434
msgid "A **threshold that is too high** tends to **make structures smaller & miss some**"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:435
msgid "Choosing a threshold manually gives a **huge opportunity to introduce bias**"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:436
msgid "We should **consider our errors when selecting output metrics**. For example, if we needed to estimate the size of a spot from any of these results then the median is likely to be preferable, because it is less impacted by artificially large spots caused by merging."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:438
msgid "A fourth point I would like to make is that **visualization matters too**. Looking only at the binary images, it is difficult to really evaluate *any* of the results. It helps enormously to overlay the detected regions on top of the original image ({numref}`fig-thresholds_manual_overlays`). From this we can see much more clearly that none of the results are terribly good: every threshold we tried misses some spots and merges others."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:448
msgid "The binary images of {numref}`fig-thresholds_manual` viewed as overlays instead."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:451
msgid "Beware summary plots!"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:455
msgid "I sometimes sit in lab meetings where people discuss their image analysis results without showing a single image. I don't approve of this at all."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:458
msgid "It's easy to generate summary data with image analysis. In fact, it's disturbingly easy to generate vastly different -- even conflicting -- summary data by analyzing the same images in different ways. But, most worryingly of all, one can often concoct a biologically-plausible-sounding story around almost any results."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:462
msgid "It's crucial to visualize *what* is being detected and measured in each image, not just a spreadsheet or plot of the results. This is especially important when applying batch processing to many images at once. It's tempting to check a few images and then trust the summary spreadsheet for the next 10,000, but I think there is no substitute for visualizing all (or at least a large proportion) of the images themselves."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:466
msgid "**For that reason, I would argue that devising an efficient visualization strategy is every bit as important as devising an analysis strategy.**"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:468
msgid "Image overlays are often a good way to do this: for each image you analyze, create an RGB copy that outlines everything that was detected and measured. Ideally, this would have brightness and contrast settings defined in such a way that you can see at a glance when something has gone wrong. You might only look at each image for a fraction of a second through *Windows Explorer* or *Mac Finder*, but that can be enough to spot issues that would otherwise be missed."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:473
msgid "In [the last section](sec_thresholding_difficult) we'll see how applying preprocessing steps to the image can allow us to reduce the proportion of spots that are merged or missed. But first we'll consider how to automate the threshold choice."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:478
msgid "Automated thresholds"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:480
msgid "We don't want to choose thresholds manually if we can avoid it, because it affords so much room for bias. On the other hand, there's no always-applicable strategy to determine a threshold automatically; images vary too much."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:483
msgid "Nevertheless, there are some widely-used techniques capable of determining reasonable thresholds for many images based upon the histogram. Each one is based upon some underlying assumptions about the histogram shape or image statistics. If these assumptions are met, the method often performs well; if not, it may perform well *sometimes* and disastrously at other times."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:487
msgid "In this section, we'll look at several of the most common automated thresholding methods using three images. Each image exhibits a different kind of histogram that is commonly found in bioimages:"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:490
msgid "**Bimodal:** with two distinct peaks, corresponding to foreground and background"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:491
msgid "**Unimodal:** mostly background noise, with some interesting signal at one end"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:492
msgid "**Dominant background:** one large background peak, with a long tail of foreground pixels"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:548
msgid "Images with three different types of histogram."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:554
msgid "Otsu's method"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:556
msgid "By its nature, global thresholding assumes that there are two classes of pixel in the image -- those that belong to interesting objects, and those that do not -- and pixels in each class have different intensity values [^fn_2]. In principle, if we could identify the pixels for each of the two classes, we could calculate statistics such as the mean and variance (i.e. standard deviation squared) for them both separately."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:562
msgid "Nobuyuki Otsu (1979). \"A threshold selection method from gray-level histograms\". *IEEE Trans. Sys. Man. Cyber.* 9 (1): 62–66. https://doi.org/10.1109/TSMC.1979.4310076"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:565
msgid "**Otsu's method**, introduced in 1979, has become an extremely popular approach to determining a threshold. It's commonly described, somewhat intimidatingly, as *'minimizing the intra-class intensity variance'*. In essence, calculating a threshold using Otsu's method involves adding the variance of the background pixels to the variance of the foreground pixels, for all possible thresholds. The threshold that is selected is the one for which the sum of the variances is smallest."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:570
msgid "We can think of this as trying to keep the distributions of foreground and background pixels 'compact': two peaks that spread as little as possible."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:572
msgid "Otsu's method performs very well on data with a bimodal histogram, with a deep valley in between. Unfortunately, a lot of microscopy images don't have clearly bimodal histograms, and so the method may not be such a good choice."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:602
msgid "Thresholding using Otsu's method. This performs best on the cell image with a bimodal histogram. For the spots image, there is no separation between peaks to find; as a result, approximately half the pixels are identified as foreground. The method also performs quite poorly for the nucleus image, despite this previously being identified as an 'easier' image for thresholding."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:607
msgid "Minimum method"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:609
msgid "The **Minimum method** provides an alternative threshold that also assumes a bimodal histogram."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:611
msgid "The starting point is the image histogram. As can be seen in {numref}`fig-thresholds_histogram_types`, the counts tend to be somewhat 'noisy' with lots of tiny spurious peaks. The Minimum method operates by smoothing the histogram, replacing each count value with the average of itself and the neighboring counts. By repeating this process, eventually the spurious peaks are removed until (hopefully) precisely two peaks remain. The threshold is then the location of the deepest point in the valley between those peaks."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:617
msgid "The result of this process is illustrated in {numref}`fig-thresholds_method_minimum`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:699
msgid "Thresholding using the Minimum method. The smoothed histograms used in the calculation are shown in red, with the original histograms shown (faintly) in gray. A line connecting the two final peaks is also included, and the threshold marked with a dot. <br/> This works well on the cells image and quite well on the nuclei image. However it fails badly on the spots image, where almost everything is detected as foreground. This is a case where the method converges (due to the image being noisy, so having lots of small peaks in the histogram) even though we might prefer it had not."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:703
msgid "One 'feature' of the Minimum method is that *it is not guaranteed to converge*. It is entirely possible that no amount of smoothing will result in a histogram with 2 peaks: perhaps there is only 1 peak, or none at all if all pixels are just a constant value."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:706
msgid "This could potentially be an advantage: it may be better to return no threshold than to return a really bad one. However, in most real images we cannot count on the method not converging: it often *does* converge, even if it does not necessarily converge to any desirable value."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:713
msgid "Triangle method"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:715
msgid "The 'triangle method' is a popular approach to determining a threshold that works especially well in images where there is one dominant background peak, and the ideal threshold should be at the base of that peak."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:717
msgid "The general idea is that a a line is drawn from the peak of the histogram to the last bin that contains any pixels. Then a perpendicular line is plotted to the histogram itself, and the distance to the histogram maximized. The direction of the line depends upon whether the peak is toward the left or the right of the histogram; all counts on the other side are ignored."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:721
msgid "The width and height of the histogram are normalized to deal with the fact that pixel values and intensity counts are in completely different units, and therefore in completely different scales."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:723
msgid "The explanation is confusing, but hopefully {numref}`fig-thresholds_method_triangle` depicts it more clearly -- and provides an intuition for when and why it might be appropriate."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:817
msgid "Thresholding using the Triangle method. Because all example histograms have a dominant peak, this performs quite well in all cases -- although tends to detect more foreground pixels in the cell image than other methods (because the threshold is at the base of the peak rather than between the two modes). <br/> The histograms depict the triangles that give the method its name. They have been normalized and truncated to include only the relevant part."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:824
msgid "Mean method"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:826
msgid "An alternative simple approach is to skip the histogram altogether, and just use the mean of all pixel values."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:828
msgid "This can actually give quite good reasons on many real-world images -- although this may be more through luck than design. It's not a method I typically use myself."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:861
msgid "Thresholding using the Mean method."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:866
msgid "Mean & Standard deviation"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:868
msgid "We can add a bit more to the *Mean method* by incorporating the standard deviation, scaled by a constant. The threshold becomes *mean + k x standard.deviation*, where we can adjust *k* based upon our attitude towards sensitivity vs. specificity."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:871
msgid "The main advantage of this approach is that it should not fail catastropically in cases where we have an image that is mostly just noise (assuming *k* is large enough), unlike methods that require a bimodal histogram. However the disadvantage is that it is not robust: the threshold can be pulled higher or lower by outliers, or by foreground values being very different from background values."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:905
msgid "Thresholding using the Mean + k x std.dev. method, with k = 3."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:910
msgid "Median & Median Absolute Deviation"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:912
msgid "A more robust alternative to using the mean and standard deviation is to use the **median and median absolute deviation (MAD)** to determine a threshold."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:914
msgid "If the pixel values of an image were to be sorted, the **median** is the value that would be in the middle. The **MAD** is calculated as follows:"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:917
msgid "Subtract the median from all pixels"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:918
msgid "Compute the absolute value of the result of (1) (i.e. flip the sign of negative values, so that all are positive)"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:919
msgid "Compute the median of the result of (2)"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:921
msgid "An intriguingly useful property of the MAD is that it can be scaled by 1.482 to resemble a (more robust) standard deviation. The [Wikipedia article](https://en.wikipedia.org/wiki/Median_absolute_deviation) explains this in more detail."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:924
msgid "Typically, we would use the *median + k x MAD x 1.482*, where we can adjust *k* as if it was used to scale a standard deviation. This is helpful because standard deviations are easier for (most of) us to tune."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:927
msgid "Using the MAD to define a threshold remains fairly uncommon, but I personally like the method a lot when working with very noisy fluorescence images. The three main requirements for this method to work are:"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:930
msgid "Most of the image should be background, and noisy (a completely constant background will give a MAD of 0, and a bad threshold)"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:931
msgid "The noise should (more or less) follow a normal distribution"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:932
msgid "The image shouldn't be too large, because calculating the median exactly is slow"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:934
msgid "The last point is not always an issue: we can calculate the median much more quickly if we use a histogram, although we may lose some precision due to the binning required when building the histogram."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:969
msgid "Thresholding using the MAD method, with *k = 3*. This is a strong candiate to be my preferred method for the 'spots' image, because it is effective when looking for small signals buried in noise."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:974
msgid "Clipping confounds automated thresholds"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:977
msgid "If the data is [clipped](chap_bit_depths), then the statistics of the pixel values and shape of the image histogram are changed. This means that the theory underlying why an automated threshold should work might well no longer apply."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:980
msgid "*This is another reason why clipping should always be avoided!*"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:984
msgid "Are automated thresholds less biased?"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:986
msgid "I sometimes see the use of automated thresholding methods justified because they are *'less biased than manual thresholds'*."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:988
msgid "I am unconvinced."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:990
msgid "I *do* agree that automated thresholds are strongly preferable to subjectively picking a threshold by eye -- but only if they can be shown to work reliably for a particular dataset. A bad automated threshold can easily introduce a systematic bias that is much worse than manually setting a threshold for each image."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:997
msgid "Thresholding difficult data"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:999
msgid "Applying global thresholds is all well and good in easy images for which a threshold clearly exists, but in practice things are rarely so straightforward – and often no threshold, manual or automatic, produces useable results. This section anticipates the next chapter on filters by showing that, with some extra processing, thresholding can be redeemed even if it initially seems to perform badly."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1002
msgid "Thresholding noisy data"
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1004
msgid "Noise is one problem that affects thresholds, especially in live cell imaging."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1006
msgid "The top half of {numref}`fig-thresholds_noisy` reproduces the nuclei from {numref}`fig-thresholds_nuclei_histogram` but with extra noise added to simulate less than ideal imaging conditions. Although the nuclei are still clearly visible in the image (A), the two classes of pixels (which were previously easy to separate) have now been merged together in the histogram (B). The triangle threshold method, which had performed well before, now gives less attractive results \\(C), because the noise has caused the ranges of background and nuclei pixels to overlap."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1010
msgid "*However,* if we apply a Gaussian filter to smooth the image, a lot of the the random noise is reduced (see {ref}`chap_filters`). This results in a histogram dramatically more similar to that in the original, (almost) noise-free image, and the threshold is again quite successful (F)."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1057
msgid "Noise can affect thresholding. After the addition of simulated noise to the image in {numref}`fig-thresholds_nuclei_histogram`, the distinction between nuclei and non-nuclei pixels is much harder to identify in the histogram (B). Any threshold would result in a large number of incorrectly-identified pixels. However, applying a Gaussian filter (here, $\\sigma = 2$) to reduce noise can dramatically improve the situation (E). Thresholds in \\(C) and (F) were computed using the triangle method."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1063
msgid "Another common problem is that the structures that should be detected appear on top of a background that itself varies in brightness. This was the reason no threshold performed very well in {numref}`fig-thresholds_manual`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1066
msgid "Ideally, we would like to apply a threshold that varies relative to the local background."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1069
msgid "W. Niblack, An introduction to Digital Image Processing, Prentice-Hall, 1986."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1072
msgid "There are a variety of **local thresholding** methods available, many of which are variations on the **Niblack method**. This calculates the mean and standard deviation of pixels *in a local window around each pixel*, for example a square of 25 x 25 pixels."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1075
msgid "A separate threshold is then generated for every pixel,defined as *local_mean - k x local_std.dev*. Note the sign: *-k* is used, because the original definition was focussed on recognizing dark text on a light background, but *k* itself can be a negative number if needed."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1078
msgid "An example is shown in {numref}`fig-thresholds_local_niblack`."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1115
msgid "Local thresholding to detect spots using Niblack's method."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1118
msgid "To be honest, I don't tend to use this approach for bioimages. I find the window size and *k* parameters difficult to tune, and it suffers the problem of the mean and standard deviation not being robust."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1121
msgid "However, local thresholding becomes more interesting and powerful if we take matters into our own hands by thinking about the problem from a slightly different angle."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1123
msgid "Suppose we had a second image that contained values equal to the thresholds we want to apply at each pixel. If we simply *subtract* this second image from the first, we can then apply a global threshold of 0 to detect what we want."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1126
msgid "Alternatively, we could subtract an image with values that aren't exactly equal to the local thresholds, but similar enough to effectively flatten out the background so that a global threshold can be applied. This then provides us access to all global automated thresholding methods, and an intuition of how the histograms ought to look for the methods to be appropriate. {numref}`fig-thresholds_local` shows this in action."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1176
msgid "Thresholding to detect structures appearing on a varying background. No global threshold may be sufficiently selective _(top row)_. However, if a 'background image' can be created, (here using a large median filter), and then subtracted, a single threshold can give much better results _(bottom row)_. This is equivalent to applying a varying threshold to the original image."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:1179
msgid "The difficult part is creating the second image. Filters are the key, and the subject of the [next chapter](chap_filters)."
msgstr ""

#: ../../chapters/2-processing/3-thresholding/thresholding.md:559
msgid "Of course there may be multiple classes for different kinds of objects, and perhaps multiple thresholds would make more sense. There is a variation of Otsu's method for identifying multiple thresholds."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:16
msgid "Filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:21
msgid "**Filtering** can make segmentation much easier by **enhancing features** and **reducing noise**"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:22
msgid "**Linear filters** replace each pixel by a weighted sum of surrounding pixels"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:23
msgid "**Nonlinear filters** replace each pixel with the result of another computation using surrounding pixels"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:24
msgid "**Gaussian filters** are linear filters with particularly useful properties, making them a good choice for many applications"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:45
msgid "Filters are phenomenally useful. Almost all interesting image analysis involves filtering in some way at some stage. In fact, the analysis of a difficult image can sometimes become (almost) trivial once a suitable filter has been applied to it. It's therefore no surprise that much of the image processing literature is devoted to the topic of designing and testing filters."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:50
msgid "The basic idea of filtering here is that each pixel in an image is assigned a new value depending upon the values of other pixels within some defined region (the pixel's **neighborhood**). Different filters work by applying different calculations to the neighborhood to get their output. Although the plethora of available filters can be intimidating at first, knowing only a few of the most useful filters is already a huge advantage."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:54
msgid "This chapter begins by introducing several extremely common **linear** and **nonlinear filters** for image processing. It ends by considering in detail some techniques based on one particularly important linear filter."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:58
#: ../../chapters/2-processing/4-filters/imagej.md:41
msgid "Linear filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:60
msgid "Linear filters replace each pixel with a **linear combination** ('sum of products') of other pixels. Therefore the only mathematical background they require is the ability to add and multiply."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:63
msgid "A linear filter is defined using a **filter kernel**, which is like a tiny image in which the pixels are called **filter coefficients**. To filter an image, we center the kernel over each pixel of the input image. We then multiply each filter coefficient by the input image pixel that it overlaps, summing the result to give our filtered pixel value. Some examples should make this clearer."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:68
#: ../../chapters/2-processing/4-filters/imagej.md:43
msgid "Mean filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:70
msgid "Arguably the simplest linear filter is the **mean filter**. Each pixel value is simply replaced by the average (mean) of itself and its neighbors within a defined area."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:73
msgid "A simple **3×3 mean filter** averages each pixel with its 8 immediate neighbors (above, below, left, right and diagonals). The filter kernel contains 9 values, arranged as a 3×3 square. Each coefficient is 1/9, meaning that together all coefficients sum to 1."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:77
msgid "The process of filtering with a 3×3 mean filter kernel is demonstrated below:"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:83
msgid "One of the main uses of a 3×3 mean filter is to reduce some common types of image noise, including Gaussian noise and Poisson noise."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:85
msgid "We'll discuss the subject of noise in much more detail in a later chapter, {ref}`chap_formation_noise`, and demonstrate *why* a mean filter works to reduce it. At this point, all we need to know about noise is that it acts like a random (positive or negative) error added to each pixel value, which obscures detail, messes with the histogram, and makes the image look grainy."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:88
msgid "{numref}`fig-filt_reduce_noise` provides an illustration of how effectively the 3×3 filter can reduce Gaussian noise in an image."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:139
msgid "Filters can be used to reduce noise. Applying a  3×3 mean filter makes the image smoother, as is particularly evident in the fluorescence plot made through the image center. Computing the difference between images shows what the filter removed, which was mostly random noise (with a little bit of image detail as well)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:144
msgid "Our simple 3×3 mean filter could be easily modified in at least two ways:"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:146
msgid "Its size could be increased. For example, instead of using just the pixels immediately adjacent to the one we are interested in, a 5×5 mean filter replaces each pixel by the average of a square containing 25 pixels, still centered on the main pixel of interest."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:147
msgid "The average of the pixels in some other shape of region could be computed, not just an _n×n_ square."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:149
msgid "Both of these adjustments can be achieved by changing the size of the filter kernel and its coefficients."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:151
msgid "One common change is to make a 'circular' mean filter. We can do this by defining the kernel in such a way that coefficients we want to ignore are set to 0, and the non-zero pixels approximate a circle. The size of the filter is then defined in terms of a radius value ({numref}`fig-filter_shapes`)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:215
msgid "The kernels used with several mean filters. Note that there's no clearly 'right' way to approximate a circle within a pixel grid, and as a result different software can create circular filters that are slightly different. Here, \\(B) and (C) match the 'circular' filters used by ImageJ's {menuselection}`Process --> Filters --> Mean...` command."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:221
msgid "Different names for (almost) the same thing"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:225
msgid "The world of filtering is full of concepts with multiple names, all meaning pretty much the same thing. For example:"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:227
msgid "**linear filtering** may be called **convolution** (very common) or **correlation**[^fn_conv] (less common)"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:228
msgid "a **filter kernel** might be called a **filter mask**"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:229
msgid "**mean filters** are sometimes referred to as **arithmetic mean filters**, **averaging filters** or **boxcar filters**"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:231
msgid "Take your pick. It's worth knowing the equivalence to avoid being confused by the literature. In particular, 'convolve' is used often enough as a synonym for 'filter' (with a linear filter) that it's important to remember."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:242
msgid "Increasing the size of a mean filter increases its impact. This is not only in terms of reducing noise, but also in terms of reducing detail, i.e. making the image more blurry ({numref}`fig-mean_filter_sizes`). If noise reduction is the primary goal, it's therefore best to avoid unnecessary blurring by using the smallest filter that gives acceptable results."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:312
msgid "Smoothing an image using circular mean filters with different radii."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:320
msgid "In ImageJ, creating a mean filter with *Radius = 6* results in a circular filter that replaces each pixel with the mean of 121 pixels. Using a square 11×11 filter would also replace each pixel with the mean of 121 pixels."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:324
msgid "Can you think of any advantages in using the circular filter rather than the square filter?"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:331
msgid "Circles are more 'compact'. Every point on the perimeter of a circle is the same distance from the center. Therefore using a circular filter involves calculating the mean of all pixels a distance of $\\leq$ *Radius* pixels away from the center."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:335
msgid "For a square filter, pixels that are further away in diagonal directions than horizontal or vertical directions are allowed to influence the results. If a pixel is further away, it's more likely to have a very different value because it is part of some other structure. Averaging across structures can blur them into one another, so is best avoided."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:346
msgid "Gradient filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:348
msgid "Linear filters can do much more than simply compute local averages. We only need to define a new filter kernel with different coefficients."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:351
msgid "Often, we want to detect structures in an image that are distinguishable from the background because of their edges. Being able to detect the edges could therefore be useful. Because an edge is usually characterized by a relatively sharp transition in pixel values -- i.e. by a steep increase or decrease in the profile across the image -- **gradient filters** can be used to help."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:355
msgid "A very simple gradient filter has the coefficients *-1, 0, 1*. Applied to an image, this replaces every pixel with the difference between the pixel to the right and the pixel to the left. The output is positive whenever the pixel values are increasing horizontally, negative when the pixel values are decreasing, and zero if the values are constant -- _no matter what the original constant value was_, so that flat areas are zero in the gradient image irrespective of their original brightness. We can also rotate the filter by 90 and get a vertical gradient image ({numref}`fig-processing_filters_gradient`)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:387
msgid "Using gradient filters and the gradient magnitude for edge enhancement."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:390
msgid "Having two gradient images with positive and negative values can be somewhat hard to work with. We can combine filtering with [point operations](chap_point_operations) to generate a single image representing the __gradient magnitude__ [^fn_3]. The gradient magnitude has high values around edges (regardless of their orientation), and low values everywhere else."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:396
msgid "The process of calculating the gradient magnitude is:"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:397
msgid "Apply linear filters to produce the horizontal and vertical gradient images"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:398
msgid "*Square* all the pixel values in both gradient images"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:399
msgid "Add the squared images together"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:400
#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:295
msgid "Take the square root of the result"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:408
msgid "Suppose the mean pixel value of an image is 100. What will the mean value be after applying a horizontal gradient filter?"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:415
msgid "After applying a gradient filter, the image mean will be 0: every pixel is added once and subtracted once when calculating the result."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:417
msgid "(Note that the mean value of a *gradient magnitude* image will be ≥ 0, because all pixels have either positive values or are equal to zero.)"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:427
msgid "Filtering at image boundaries"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:429
msgid "If a filter consists of more than one coefficient, the neighborhood will extend beyond the image boundaries when filtering some pixels nearby. We need to handle this somehow. There are several common approaches."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:433
msgid "The boundary pixels could simply be ignored and left with their original values, but for large neighborhoods this would result in much of the image being unfiltered. Alternative options include treating every pixel beyond the boundary as zero, replicating the closest valid pixel, treating the image as if it is part of a periodic tiling, or mirroring the internal values ({numref}`fig-filter_boundaries`)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:474
msgid "Methods for determining suitable values for pixels beyond image boundaries when filtering."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:477
msgid "Different software can handle boundaries in different ways. Often, if you are using an image processing library to code your own filtering operation you will be able to specify the boundary operation."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:481
#: ../../chapters/2-processing/4-filters/imagej.md:262
msgid "Nonlinear filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:483
msgid "Linear filters involve taking neighborhoods of pixels, scaling them by the filter coefficients, and adding the results to get new pixel values. **Nonlinear filters** also make use of neighborhoods of pixels, but can use any other type of calculation to obtain the output. Here we'll consider one especially important family of nonlinear filters."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:488
#: ../../chapters/2-processing/4-filters/imagej.md:264
msgid "Rank filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:490
msgid "**Rank filters** effectively sort the values of all the neighboring pixels in ascending order, and then choose the output based upon this ordered list."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:492
msgid "Perhaps the most common example is the **median filter**, in which the pixel value at the center of the list is used for the filtered output."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:499
msgid "Results of different 3×3 rank filters when processing a single neighborhood in an image. The output of a 3×3 mean filter in this case would also be 15."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:504
msgid "The result of applying a median filter is often similar to that of applying a mean filter, but has the major advantage of removing isolated extreme values completely, _without allowing them to have an impact upon surrounding pixels_. This is in contrast to a mean filter, which cannot ignore extreme pixels but rather will smooth them out into occupying larger regions ({numref}`fig-processing_filters_speckled`)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:507
msgid "However, a disadvantage of a median filter is that it can seem to introduce patterns or textures that were not present in the original image, at least whenever the size of the filter increases (see {numref}`fig-processing_filters`D below). Another disadvantage is that large median filters tend to be slow."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:567
msgid "Applying 3×3 mean and median filters to an image containing isolated extreme values (known as _salt and pepper noise_). A mean filter reduces the intensity of the extreme values but spreads out their influence. A small median filter is capable of removing the outliers completely, with a minimal effect upon the rest of the image."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:573
msgid "Other rank filters include the **minimum** and **maximum filters**, which replace each pixel value with the minimum or maximum value in the surrounding neighborhood respectively ({numref}`fig-processing_filters_rank`). They will become more important when we discuss [morphological operations](chap_morph)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:606
msgid "The result of applying 3×3 rank filters. The original noise-free image is shown below in {numref}`fig-processing_filters`A."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:633
msgid "What would happen if you subtract a minimum filtered image (e.g. {numref}`fig-processing_filters_rank`C) from a maximum filtered image (Figure {numref}`fig-processing_filters_rank`B)?"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:640
msgid "Subtracting a minimum from a maximum filtered image would be another way to accent the edges:"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:652
#: ../../chapters/2-processing/4-filters/imagej.md:60
msgid "Gaussian filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:654
msgid "Filters from Gaussian functions"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:656
msgid "We conclude this chapter with one fantastically important linear filter, and some variants based upon it."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:658
msgid "A **Gaussian filter** is a linear filter that also smooths an image and reduces noise. However, unlike a mean filter -- for which even the furthest away pixels in the neighborhood influence the result by the same amount as the closest pixels -- the smoothing of a Gaussian filter is weighted so that the influence of a pixel decreases with its distance from the filter center. This tends to give a better result in many cases ({numref}`fig-filt_smoothing`)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:699
msgid "Comparing a mean and Gaussian filter. The mean filter can introduce patterns and maxima where previously there were none. For example, the brightest region in (B) is one such maximum – _but the values of all pixels in the same region in (A) were zero!_ By contrast, the Gaussian filter produces a smoother, more visually pleasing result, somewhat less prone to this effect \\(C)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:704
msgid "The coefficients of a Gaussian filter are determined from a Gaussian function ({numref}`fig-gaussian_2d`)"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:706
msgid "\n"
"g(x, y) = Ae^{-(\\frac{x^2 + y^2}{2\\sigma^2})}\n"
""
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:710
msgid "The scaling factor $A$ is used to make the entire volume under the surface equal to 1. In terms of filtering, this means that the coefficients add to 1 and the image will not be unexpectedly scaled. The size of the function is controlled by $\\sigma$, rather than a filter radius. $\\sigma$ is equivalent to the standard deviation of a normal (i.e. Gaussian) distribution."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:761
msgid "Surface plot of a 2D Gaussian function."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:765
msgid "A comparison of several filters is shown in {numref}`fig-processing_filters`."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:812
msgid "The effects of various filters upon a noisy image of a fixed cell."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:817
msgid "Filters of varying sizes"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:819
msgid "Gaussian filters have useful properties that make them generally preferable to mean filters, some of which will be mentioned in {ref}`chap_formation_spatial` (others require a trip into Fourier space, beyond the scope of this book). Therefore if you're not sure which filter to use for smoothing, Gaussian is likely to be a safer choice than mean -- particularly if the filter is large. Nevertheless, your decisions are not at an end since the precise size of the filter still needs to be chosen."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:823
msgid "A small filter will mostly suppress noise, because noise masquerades as tiny random fluctuations at individual pixels. As the filter size increases, Gaussian filtering starts to suppress larger structures occupying multiple pixels -- reducing their intensities and increasing their sizes, until eventually they would be smoothed into surrounding regions ({numref}`fig-gaussian_effects`). By varying the filter size, we can then decide the **scale** at which the processing and analysis should happen."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:890
msgid "The effect of Gaussian filtering on the size and intensity of structures."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:894
msgid "{numref}`fig-edge_sigma` shows an example of when this is useful. Here, gradient magnitude images are computed, similar to what was shown in {numref}`fig-processing_filters_gradient`, but because the original image is now noisy the initial result is not very useful -- with even strong edges being buried amid noise (B). Applying a small Gaussian filter prior to computing the gradient magnitude gives much better results \\(C). If we only want the very strongest edges, then apply a larger filter would be better (D)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:937
msgid "Applying Gaussian filters before computing the gradient magnitude changes the scale at which edges are enhanced."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:942
msgid "Difference of Gaussians filtering"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:944
msgid "So Gaussian filters can be chosen to suppress small structures. But what if we also wish to suppress large structures -- so that we can concentrate on detecting or measuring structures with sizes inside a particular range?"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:947
msgid "We already have the pieces necessary to construct one solution."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:949
msgid "Suppose we apply one Gaussian filter to reduce small structures. Then we apply a *second* Gaussian filter, bigger than the first, to a duplicate of the original image. This will remove even more structures, while still preserving the largest features in the image."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:953
msgid "The trick is that, if we subtract this second filtered image from the first, we are left with an image that contains the information that 'falls between' the two smoothing scales we used."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:955
msgid "This process is called **difference of Gaussians (DoG) filtering**, and it is a technique that I use *all the time*. It is especially useful for detecting small structures, or as an alternative to the gradient magnitude for enhancing edges ({numref}`fig-dog_red_hela`)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:988
msgid "Difference of Gaussian filtering of the same image at various scales."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1046
msgid "DoG filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1050
msgid "In fact, to get the result of DoG filtering it's not necessary to filter the image twice and subtract the results. We could equally well subtract the coefficients of the larger filter from the smaller first (after making sure both filters are the same size by adding zeros to the edges as required), then apply the resulting filter to the image only once ({numref}`fig-dog_plots`)."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1058
msgid "Surface plots of two Gaussian filters with small and large $\\sigma$, and the result of subtracting the latter from the former. The sum of the coefficients for (A) and (B) is one in each case, while the coefficients of (C) add to zero."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1063
msgid "Laplacian of Gaussian filtering"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1065
msgid "One minor complication with DoG filtering is the need to select two different values of $\\sigma$. A similar operation, which requires only a single $\\sigma$ and a single filter, is **Laplacian of Gaussian (LoG) filtering**."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1068
msgid "The appearance of a LoG filter is like an upside-down DoG filter ({numref}`fig-log_plots`), but if the resulting image is [inverted](sec_points_inversion) then the results are comparable [^fn_4]."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1114
msgid "Surface plot of a LoG filter. This closely resembles {numref}`fig-dog_plots`, but inverted so that the negative values are found in the filter center."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1142
msgid "Application of DoG and LoG filtering to an image. Both methods enhance the appearance of spot-like structures, and (to a lesser extent) edges, and result in an image containing both positive and negative values with an overall mean of zero. In the case of LoG filtering, inversion is involved: darker points become bright after filtering."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1148
msgid "Unsharp masking"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1150
msgid "Finally, a related technique widely-used to enhance the visibility of details in images -- although certainly _not_ advisable for quantitative analysis -- is **unsharp masking**."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1152
msgid "This uses a Gaussian filter first to blur the edges of an image, and then subtracts it from the original. But rather than stop there, the subtracted image is multiplied by some weighting factor and _added back_ to the original. This gives an image that looks much the same as the original, but with edges sharpened by an amount dependent upon the chosen weight."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1184
msgid "The application of unsharp masking to a blurred image. First a Gaussian-smoothed version of the image ($\\sigma = 1$) is subtracted from the original, scaled ($weight = 0.7$) and added back to the original."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1188
msgid "Unsharp masking can improve the visual appearance of an image, but it's important to remember that it modifies the image content in a way that might well be considered suspicious in scientific circles. Therefore, if you apply unsharp masking to any image you intend to share with the world you should have a good justification and certainly admit what you have done. The technique is included here not as a recommendation that you use it, but rather to show how Gaussian filters can be combined with point operations in creative ways."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1192
msgid "If you want a more theoretically justified method to improve image sharpness in microscopy, it may be worth looking into *'(maximum likelihood) deconvolution'* algorithms."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:236
msgid "I feel obliged to admit that there *is* a subtle difference between convolution and correlation: the kernel is rotated 180° for convolution. This is something we almost never need to care about for two reasons:"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:238
msgid "Convolution and correlation end up the same if the filter is symmetric -- and most filters we care about are symmetric"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:239
msgid "The distinction is often ignored in practice anyway. For example, ImageJ has a {menuselection}`Process --> Filters --> Convolve...` command that (last time I checked) actually implements correlation."
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:394
msgid "The equation then looks like Pythagoras' theorem: $G_{mag} = \\sqrt{G_x^2 + G_y^2}$"
msgstr ""

#: ../../chapters/2-processing/4-filters/filters.md:1070
msgid "A LoG filter is also often referred to as a _mexican-hat filter_, although clearly the filter (or the hat-wearer) should be inverted for the name to make more sense"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:15
msgid "ImageJ: Filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:38
msgid "Most of the filters we've considered are available through the {menuselection}`Process --> Filters` submenu. This section adds a little more information about their implementation in ImageJ, and asks a few questions."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:45
msgid "The easiest way to apply a 3×3 mean filter in ImageJ is through the {menuselection}`Process --> Smooth` command. The fact that the shortcut is {kbd}`Shift+S` can almost make this *too* easy, as I find myself accidentally smoothing when I really wanted to save my image. Take care."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:49
msgid "To apply larger mean filters, the command is {menuselection}`Process --> Filters --> Mean...`. It uses approximately circular neighborhoods, and the neighborhood size is adjusted by choosing a {guilabel}`Radius` value. The {menuselection}`Process --> Filters --> Show Circular Masks` command displays the neighborhoods used for different values of {guilabel}`Radius`. If you happen to choose *Radius = 1*, you get a 3×3 filter -- and the same results as using {menuselection}`Smooth`."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:62
msgid "{menuselection}`Process --> Filters --> Gaussian Blur...` is the command that implements a Gaussian filter."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:64
msgid "In the event that you want a Gaussian filter that isn't isotropic (i.e. has a different size along different dimensions), {menuselection}`Process --> Filters --> Gaussian Blur 3D...` can be used."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:66
msgid "Although not *really* recommended, unsharp masking is available through {menuselection}`Process --> Filters --> Unsharp mask...`."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:68
#: ../../chapters/appendices/macros/macro_dog.md:16
msgid "Difference of Gaussians"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:69
msgid "There's currently no direct command in ImageJ to implement difference of Gaussians filtering, rather the steps need to be pieced together with image duplication and subtraction. However {ref}`chap_macro_dog` describes how to generate a macro for DoG filtering."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:73
msgid "Custom linear filters"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:75
msgid "{menuselection}`Process --> Filters --> Convolve...` makes it possible to define any custom linear filter by entering the values of the desired coefficients, separated by spaces and arranged in rows and columns. If you {guilabel}`Normalize Kernel` is selected, then the coefficients are scaled so that they add to 1, by dividing by the sum of all the coefficients -- unless the sum is 0, in which case requesting normalizion does nothing."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:88
msgid "When defining an _n_×_n_ filter kernel with {menuselection}`Convolve...`, ImageJ insists that __n__ is an odd number. Why?"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:94
msgid "If *n* is an odd number, the filter has a clear central pixel. This makes it possible to center the filter kernel on a pixel on the image."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:112
msgid "Predict what happens when you convolve an image using a filter that consists of a single coefficient with a value -1 in the following cases:"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:114
msgid "{guilabel}`Normalize Kernel` is checked"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:115
msgid "You have a 32-bit image, {guilabel}`Normalize Kernel` is unchecked"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:116
msgid "You have an 8-bit image, {guilabel}`Normalize Kernel` is unchecked"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:121
msgid "The results of convolving with a single -1 coefficient in different circumstances:"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:122
msgid "_{guilabel}`Normalize Kernel` is checked_: Nothing at all happens. The normalization makes the filter just a single 1... and convolving with a single 1 leaves the image unchanged."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:123
msgid "_You have a 32-bit image ({guilabel}`Normalize Kernel` unchecked)_: The pixel values become negative, and the image looks inverted."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:124
msgid "_You have an 8-bit image ({guilabel}`Normalize Kernel` unchecked)_: The pixel values would become negative, but then cannot be stored in an 8-bit unsigned integer form. Therefore, all pixels simply become clipped to zero."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:135
msgid "Using any image, work out which of the methods for dealing with boundaries shown in {numref}`fig-filter_boundaries` is used by ImageJ's {menuselection}`Convolve...` command."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:137
msgid "**Note:** This requires a bit of creativity. It will certainly help to use an image with some variation at the image boundary. I used {menuselection}`File --> Open Samples --> Blobs`."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:141
#: ../../chapters/2-processing/4-filters/imagej.md:187
#: ../../chapters/2-processing/4-filters/imagej.md:246
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/launch-imagej-js-badge.svg)](https://ij.imjoy.io?run=https://gist.github.com/petebankhead/cbbb6f210d173c8488247799efc3b970)"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:148
msgid "Replication of boundary pixels is the default method used by {menuselection}`Process --> Filters --> Convolve...` in ImageJ (although other filtering plugins by different authors might use different methods)."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:150
msgid "My approach to test this involved using {menuselection}`Convolve...` with a filter that consisting of a 1 followed by a lot of zeros (e.g. `1 0 0 0 0 0 0 0 0 0 0 0 0...`). This basically shifts the image to the right, bringing whatever is outside the image boundary into view."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:167
msgid "Gradient magnitude"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:175
msgid "Practice using the commands we've met so far by determining the **gradient magnitude** of an image, as described [here](sec_filters_gradient)."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:177
msgid "You will need to use"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:178
msgid "{menuselection}`Image --> Duplicate...`"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:179
msgid "{menuselection}`Process --> Filters --> Convolve...`"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:180
msgid "{menuselection}`Process --> Image Calculator...`"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:181
msgid "Several commands in the {menuselection}`Process --> Math` submenu"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:182
msgid "Something else we've used before... possibly"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:184
msgid "If you need a sample image, you can use {menuselection}`File --> Open samples --> Blobs (25K)`. _(Be sure to pay attention to the bit-depth!)_"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:191
msgid "The process to calculate the gradient magnitude is:"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:193
msgid "Convert the image to 32-bit (if it isn't already 32-bit)"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:194
msgid "Duplicate the image"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:195
msgid "Convolve one copy of the image with the horizontal gradient filter, and one with the vertical (i.e. coefficients `-1 0 1` arranged as a row or column)"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:196
msgid "Compute the square of both images ({menuselection}`Process --> Math --> Square`)"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:197
msgid "Use the image calculator to add the images together"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:198
msgid "Compute the square root of the resulting image ({menuselection}`Process --> Math --> Square Root`)"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:200
msgid "Here's a macro that implements these steps:"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:219
msgid "The convolution results in negative values, which is why the 32-bit conversion is needed."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:221
msgid "**Note:** This is (almost) what is done by the command {menuselection}`Process --> Find Edges`, except the gradient filters are slightly different."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:232
msgid "The 'Edges' LUT"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:240
msgid "ImageJ has a LUT called **edges** under {menuselection}`Image --> Lookup Tables --> Edges`. Applied to {menuselection}`File --> Open samples --> Blobs (25K)`, it does a rather good job of highlighting edges -- without actually changing the pixels at all."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:243
msgid "How does it work? Does it apply a filter?"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:251
msgid "The {menuselection}`edges` LUT shows most low and high pixel values as black -- and uses lighter shades of gray only for a small range of values in between (see {menuselection}`Image --> Color --> Edit LUT...`). In any image with a good separation of background and foreground pixels, but which still has a somewhat smooth transition between them, this means everything but the edges can appear black."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:254
msgid "All this is achieved by a LUT: no pixels were harmed, there was no filtering applied."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:266
msgid "The main rank filters are to be found exactly where you might expect them:"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:268
msgid "{menuselection}`Process --> Filters --> Median...`"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:269
msgid "{menuselection}`Process --> Filters --> Minimum...`"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:270
msgid "{menuselection}`Process --> Filters --> Maximum...`"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:272
msgid "ImageJ uses circular neighborhoods with its built-in rank filters, similar to how mean filters are implemented. We will meet these filters again in {ref}`chap_morph`."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:276
msgid "Removing outliers"
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:278
msgid "{numref}`fig-processing_filters_speckled` shows that median filtering is much better than mean filtering for removing outliers. We might encounter this if something in the microscope is not quite functioning as expected or if dark noise is a problem, but otherwise we expect the noise in fluorescence microscopy images to produce few really extreme values (see {ref}`chap_formation_noise`)."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:281
msgid "Nevertheless, {menuselection}`Process --> Noise --> Remove Outliers...` provides an alternative if isolated bright values are present. This is a nonlinear filter that inserts median values _only whenever a pixel is found that is further away from the local median than some adjustable threshold_."
msgstr ""

#: ../../chapters/2-processing/4-filters/imagej.md:284
msgid "It's therefore like a more selective median filter that will only modify the image at pixels where it is considered really necessary."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:15
msgid "ImageJ: Morphological operations"
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:35
msgid "ImageJ's {menuselection}`Process --> Binary` submenu contains various useful commands for working with binary images, including some of the morphological operations we've looked at."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:37
msgid "However, there are other useful morphological operations lurking elsewhere -- although most require extra plugins, or switching to Fiji."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:40
msgid "Erosion, dilation, opening & closing"
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:42
msgid "{menuselection}`Process --> Binary` contains the commands {menuselection}`Erode`, {menuselection}`Dilate`, {menuselection}`Open` and {menuselection}`Close-` commands."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:44
msgid "These are relevant here, but my advice is to avoid them. By default they work with fixed 3×3 pixel neighborhoods, but they *could* do something different if someone has been messing about with the {guilabel}`Iterations (1-100)` or {guilabel}`Count (1-8)` options under {menuselection}`Process --> Binary --> Options...` -- and this unpredictability could well cause trouble."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:47
msgid "To perform erosion, dilation, opening and closing with more control and possibly larger neighborhoods, I strongly prefer to use the {menuselection}`Process --> Filters --> Maximum...` and {menuselection}`Process --> Filters --> Minimum...` commands, combining them if necessary."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:50
msgid "Morphological operations in Fiji"
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:53
msgid "Fiji contains {menuselection}`Process --> Morphology --> Gray Morphology`, which provides a more flexible implementation of erosion, dilation, opening and closing using a variety of shapes for both grayscale and binary images."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:55
msgid "You can also find the plugin for ImageJ at https://imagej.nih.gov/ij/plugins/gray-morphology.html"
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:60
msgid "Outlines, holes & skeletonization"
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:62
msgid "The {menuselection}`Process --> Binary --> Outline` command, predictably, removes all the interior pixels from 2D binary objects, leaving only the perimeters ({numref}`fig-outline_fill_skeleton`A)."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:65
msgid "{menuselection}`Process --> Binary --> Fill Holes` would then fill these interior pixels in again, or indeed fill in any background pixels that are completely surrounded by foreground pixels ({numref}`fig-outline_fill_skeleton`B)."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:67
msgid "{menuselection}`Process --> Binary --> Skeletonize` shaves off all the outer pixels of an object until only a connected central line remains ({numref}`fig-outline_fill_skeleton`C)."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:69
msgid "Analyzing skeletons"
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:72
msgid "If you are analyzing linear structures (e.g. blood vessels, neurons), then this command or those in Fiji's {menuselection}`Plugins --> Skeleton -->` submenu may be helpful."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:107
msgid "The effects of the {menuselection}`Outline`, {menuselection}`Fill holes` and {menuselection}`Skeletonize` commands."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:115
msgid "The outline of an object in a binary image can also be determined by applying one other morphological operation to a duplicate of the image, and then using the {menuselection}`Image Calculator`. How?"
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:121
msgid "To outline the objects in a binary image, you can simply calculate the difference between the original image and an eroded (or dilated, if you want the pixels just beyond the objects) duplicate of the image."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:128
msgid "Other morphological operations"
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:130
msgid "ImageJ doesn't contain an implementation of morphological reconstruction, and therefore doesn't support all the extra operations that derive from it."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:132
msgid "However, there's an extremely library called [**MorphoLibJ**](https://imagej.net/plugins/morpholibj) that can be added to ImageJ or Fiji, which contains morphological reconstruction and much more."
msgstr ""

#: ../../chapters/2-processing/5-morph/imagej.md:134
msgid "Check out the excellent documentation at https://imagej.net/plugins/morpholibj for more details."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:17
#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:408
msgid "Morphological operations"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:22
msgid "**Morphological operations** can be used to refine or modify the shapes of objects in images"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:23
msgid "Many morphological operations can be applied to **binary images** to improve an image segmentation"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:24
msgid "**Grayscale morphological operations** can also be used as processing steps before binarization, or to help identify regional maxima and minima"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:45
msgid "Image filters and thresholds enable us to detect structures of various shapes and sizes for different applications. Nevertheless, despite our best efforts, the binary images produced by our thresholds often still contain inaccurate or undesirable detected regions. They could benefit from some extra cleaning up."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:49
msgid "At this stage, we are primarily working with shapes -- morphology -- so most of the techniques we describe here are often called **morphological operations**."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:53
msgid "Morphological operations using rank filters"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:111
msgid "Overview of erosion, dilation, opening and closing. The original image is shown at the top, while the processed part is at the bottom in each case."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:115
msgid "Erosion & dilation"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:117
msgid "Our first two morphological operations, **erosion** and **dilation**, are actually identical to minimum and maximum filtering respectively, described [in the previous chapter](sec_filters_rank). The names erosion and dilation are used more often when speaking of binary images, but the operations are the same irrespective of the kind of image."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:120
msgid "Structuring elements"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:121
msgid "The neighborhood used to calculate the result for each pixel is defined by a **structuring element**. This is similar to a [filter kernel](sec_filters_linear), except that it only has values 0 and 1 (for ignoring or including the neighborhood pixel, respectively)."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:126
msgid "Here, we assume the background value in our binary image is 0 (black) and foreground is 1 (white)."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:129
msgid "**Erosion** will make objects in the binary image smaller, because a pixel will be set to the background value if _any_ other pixels in the neighborhood are background. This can split single objects into multiple pieces."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:132
msgid "Conversely, **dilation** makes objects bigger, since the presence of a single foreground pixel anywhere in the neighborhood will result in a foreground output. This can also cause objects to merge."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:189
msgid "The effects of erosion and dilation on a binary image of small structures."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:195
msgid "Opening & closing"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:197
msgid "The fact that erosion and dilation alone affect sizes can be a problem: we may like their abilities to merge, separate or remove objects, but prefer that they had less impact upon areas and volumes. Combining both operations helps achieve this."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:200
msgid "**Opening** consists of an erosion followed by a dilation. It therefore first shrinks objects, and then expands whatever remains to _approximately_ its original size."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:203
msgid "Such a process is not as pointless as it may first sound. If erosion causes very small objects to completely disappear, clearly the dilation cannot make them reappear: they are gone for good. Barely-connected objects separated by erosion are also not reconnected by the dilation step."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:207
msgid "**Closing** is the opposite of opening, i.e. a dilation followed by an erosion, and similarly changes the shapes of objects. The dilation can cause almost-connected objects to merge, and these often then remain merged after the erosion step. If you wish to count objects, but they are wrongly subdivided in the segmentation, closing may help make the counts more accurate."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:241
msgid "The effects of opening and closing on a binary image of small structures. Unlike when using erosion or dilation alone, the sizes of objects are largely preserved although the contours are modified. Opening has the effect of completely removing the smallest or thinnest objects."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:246
msgid "Boundaries & outlines"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:248
msgid "We can make use of the operations above to identify outlines in a binary image. To do this, we first need a clear definition of what we mean by 'outline'."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:251
msgid "The **inner boundary** may be defined as *the foreground pixels that are adjacent to background pixels*. We can determine the inner boundary by"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:253
#: ../../chapters/2-processing/5-morph/morph.md:259
msgid "Duplicating the binary image"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:254
msgid "Eroding with a 3×3 structuring element"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:255
msgid "Subtracting the eroded image from the original"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:257
msgid "The **outer boundary** may be defined as *the background pixels that are adjacent to foreground pixels*. We can determine the outer boundary by"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:260
msgid "Dilating with a 3×3 structuring element"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:261
msgid "Subtracting the original image from the dilated image"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:263
msgid "Thicker boundaries"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:266
msgid "There's no reason to limit outlines to being 1 pixel thick. Choosing a larger structuring element makes it possible create thicker outlines. We might also subtract an eroded image from a dilated image to identify a thicker boundary that contains both inner and outer pixels."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:270
msgid "One application of creating thick boundaries in microscopy images of cells is to generate a binary image of the nuclei, and then a second binary image representing a ring around the nucleus. This makes it possible to make measurements that are likely to be within the cytoplasm, just outside the nucleus, without the task of identifying the full area of the cell -- which is often difficult if the cell or membrane are not clearly visible."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:304
msgid "Calculating inner and outer boundaries, using erosion or dilation. The radius of the structuring element can be used to tune the boundary thickness."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:309
msgid "Finding local minima & maxima"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:311
msgid "Erosion and dilation can be used to find pixels that are **local maxima** or **local minima** very easily, with the caveat that the results are inexact and often unusable. Nevertheless, the trick works 'well enough' sufficiently often to be worth knowing."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:314
msgid "Here, we focus on maxima; the process for detecting local minima is identical, except that either the image should be inverted or erosion used instead of dilation."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:316
msgid "A local maximum can be defined as a pixel with a value greater than all its neighbors, or a connected group of pixels with the same higher value than the surrounding pixels. An easy way to detect these pixels is to dilate the image with 3×3 maximum filter, and check for pixel values that are unchanged (i.e. where the pixel was already a maximum within its neighborhood)."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:319
msgid "This is inexact because it does not *only* identify maxima; it also detections some 'plateaus' where pixels have identical values to their neighbors. In practice, this is not always a problem because noise can make plateaus virtually non-existent for many real-world images (at least ones that haven't been clipped)."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:322
msgid "A bigger problem is that the approach often identifies far too many maxima to be useful ({numref}`fig-morph_simple_maxima`)."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:356
msgid "Identifying local maxima with the help of a 3×3 dilation tends to find too many maxima to be useful."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:359
msgid "We can reduce these by either increasing the size of the maximum filter (therefore requiring pixels to be maximal across a larger region), or by pre-smoothing the image (usually with a [Gaussian filter](sec_filters_gaussian)). However, tuning the parameters becomes difficult."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:362
msgid "We will see an alternative approach that is often more intuitive in {ref}`sec_h_extrema`."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:392
msgid "Identifying local maxima with the help of a larger dilation (here, 7×7 pixels) can sometimes give better results than using a smaller dilation {numref}`fig-morph_simple_maxima`."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:396
msgid "More morphological operations"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:398
msgid "Area opening"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:400
msgid "**Area opening** is similar to *opening*, except it avoids the need for any kind of maximum or minimum filtering."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:402
msgid "It works by identifying [**connected components** in the binary image](sec_binary_labeled), which are contiguous regions of foreground pixels. For each connected component, the number of pixels is counted to give an area in px². If the area of a component falls below a specified area threshold, the pixels for that component are set to the background, i.e. the component is removed."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:406
msgid "*Area opening* is often preferable to *opening*, because it has *no impact* on the shape of any structures larger than the area threshold. It simply applies a minimum area threshold, removing everything smaller."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:439
msgid "Using area opening to remove small objects."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:444
msgid "Filling holes"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:446
msgid "**Filling holes** involves identifying connected components of *background pixels* that are entirely surrounded by foreground pixels. These components are then 'flipped' to become foreground pixels instead."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:449
msgid "Should we then want to identify the holes themselves, we can subtract the original image from the filled image."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:477
msgid "Filling holes in a binary image. Image subtraction makes it possible to extract the holes themselves."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:501
msgid "Small holes filled."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:509
msgid "We don't always want to fill *all* the holes within a binary image, but rather only the smaller ones. Can you think of a way to fill *only holes smaller than 1000 px²*, using area opening?"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:512
msgid "You'll need at least one operation described in previous chapter."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:517
msgid "One way to fill holes below a fixed size:"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:519
msgid "Invert the binary image"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:520
msgid "Perform area opening with an area threshold of 1000 px²"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:521
msgid "Invert the result"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:528
msgid "Thinning & skeletonization"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:530
msgid "**Thinning** and **skeletonization** are related operations that aim to 'thin down' objects in a binary image to just their centerlines. They are particularly useful with filamental or tube-like structures, such as axons or blood vessels."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:559
msgid "The effects of thinning and skeletonization on a binary image."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:563
msgid "What's the difference between thinning & skeletonization?"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:566
msgid "The truth is: I'm not entirely sure. There is quite a bit of overlap in the literature, and I've seen the same algorithm referred to by both names. Furthermore, there are different thinning algorithms that give different results; the situation is similar for skeletonization algorithms."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:570
msgid "Software occasionally offers both thinning and skeletonization, but often just offers one or the other. It's worth trying any thinning/skeletonization methods available to see which performs best for any particular application."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:576
msgid "Morphological reconstruction"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:578
msgid "**Morphological reconstruction** is a somewhat advanced technique that underpins several powerful image processing operations. It's useful with both grayscale and binary images."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:581
msgid "Morphological reconstruction requires two images of the same size: a **marker** image and a **mask** image. The pixel in the *mask* image should all have values greater than or equal to the corresponding pixels in the *marker* image."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:584
msgid "The reconstruction algorithm progressively *dilates* the marker image (e.g. applies a 3×3 maximum filter), while constraining the marker to remain 'within' the mask; that is, the pixel values in the marker are never allowed to exceed the values in the mask. This dilation is repeated iteratively until the marker cannot change any further without exceeding the mask. The output is the new marker image, after all the dilations have been performed."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:588
msgid "Some examples will help demonstrate how this works and why it's useful. The crucial difference in the methods below is how the marker and mask images are created."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:591
msgid "Hysteresis thresholding"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:593
msgid "One use of morphological reconstruction is to implement a **double threshold**, also known as **hysteresis thresholding**."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:596
msgid "For *low threshold* and *high threshold*, I assume we're detecting light structures on a dark background."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:599
msgid "This involves defining both a **low threshold** and a **high threshold.** The low threshold operates like any [global threshold](chap_thresholding) to identify regions. However, a region is discarded from the binary image if it does not also contain at least one pixel that exceeds the high threshold."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:603
msgid "This is achieved using morphological reconstruction by defining the *marker* as all pixels exceeding the high threshold, and the *mask* as all pixels exceeding the low threshold. The markers will expand to fill the mask regions that contain them. But any mask regions that don't contain marker pixels are simply ignored."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:635
msgid "Applying a hysteresis threshold to an image. The size and area of the objects detected by this method are determined by the low threshold, but at least one of the pixel values within the object must exceed the high threshold. This slightly mitigates the problem of a single global threshold having [a huge impact on analysis results](chap_thresholding), by the same threshold simultaneously influencing both what is detected and its size."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:641
msgid "H-Maxima & H-Minima"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:643
msgid "We [saw previously](fig-morph_simple_maxima) that we could (kind of) identify local maxima in a very simple way using an image dilation, but the results are often too inaccurate to be useful."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:645
msgid "**H-Maxima** and **H-Minima** can help us overcome this. These operations both require only one intuitive parameter: they enable us to identify maxima or minima using a local intensity threshold *H*."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:648
msgid "This is achieved using morphological reconstruction. For H-maxima, the process is:"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:650
msgid "Set the original grayscale image as the *mask*"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:651
msgid "Subtract *H* from the mask to create the *markers*"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:652
msgid "Apply morphological reconstruction using the markers and mask"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:653
msgid "Subtract the reconstruction result from the *mask*"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:654
msgid "Threshold the subtracted image with a global threshold of *H*"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:656
msgid "The main steps are illustrated in {numref}`fig-morph_h_maxima`. We can apply the same process to an inverted image to find *H-minima*."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:693
msgid "Calculating H-maxima using morphological reconstruction. Here, *H* is set (arbitrarily) to be the image standard deviation."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:698
msgid "Opening & closing by reconstruction"
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:700
msgid "H-maxima and H-minima use morphological reconstruction to effectively generate a background image that can be subtracted from the original. We do this by subtracting a constant *H*, which acts as a local intensity threshold."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:703
msgid "We can also use morphological reconstruction to generate a background image based upon spatial information, rather than an intensity threshold *H*, by using **opening by reconstruction**. This effectively introduces a size component into our local threshold. **Closing by reconstruction** is an analogous operation that can be defined using morphological closing."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:707
msgid "The starting point for opening by reconstruction is a *morphological opening* [as defined above](sec_morph_opening_closing), i.e. an erosion followed by a dilation. This defines the marker image. The original image is used as the mask."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:740
msgid "Using opening by reconstruction to obtain a background estimate. The estimate can be subtracted from an image before applying a global threshold."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:743
msgid "As before, opening alone removes structures that are smaller than the structuring element, while slightly affecting the shapes of everything else. Opening by reconstruction essentially adds some further (constrained) dilations so that the structures that were *not* removed are more similar to how they were originally. This can make opening by reconstruction more attractive for generating background images that will be used for subtraction."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:747
msgid "Opening by reconstruction can also be applied to binary images as an alternative to *opening* and *area opening*. Like area opening, opening by reconstruction is able to remove some objects while retaining the shapes of larger objects exactly."
msgstr ""

#: ../../chapters/2-processing/5-morph/morph.md:778
msgid "Using opening by reconstruction to remove small (and thin) objects from a binary image, while retaining the original shape of everything that remains."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:15
msgid "ImageJ: Image transforms"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:35
msgid "ImageJ has excellent 2D distance and watershed transforms... although not necessarily everything about them is quite what you might expect."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:39
msgid "Distance transform"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:46
msgid "A 2D distance transform can be calculated in ImageJ using the {menuselection}`Process --> Binary --> Distance Map` command."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:48
msgid "A non-obvious feature of this is that the type of output given is determined by the {guilabel}`EDM output` option tucked away under {menuselection}`Process --> Binary --> Options...` (where EDM stands for 'Euclidean Distance Map'). This makes a difference, because the distance between two diagonal pixels is considered $\\sqrt{2} \\approx 1.414$ (by Pythagoras' theorem) -- which means that a 32-bit output can give more exact straight-line distances without rounding."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:70
msgid "Outputs from several distance transform-related commands in ImageJ."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:75
msgid "Ultimate points"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:77
msgid "{menuselection}`Process --> Binary --> Ultimate Points` is a related command. It uses the distance transform to identify the last points that would be removed if the objects would be eroded until they disappear. In other words, it identifies centers. But these are not simply single center points for each object; rather, they are maximum points in the distance map, and therefore the pixels furthest away from the boundary."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:82
msgid "This means that if a structure has several 'bulges', then an ultimate point exists _at the center of each of them_. If segmentation has resulted in structures being merged together, then each distinct bulge could actually correspond to something interesting -- and the number of bulges actually means more than the number of separated objects in the binary image."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:169
msgid "Although conceptually straightforward, and easy to use in ImageJ, implementing 'Ultimate points' in other software can be tricky. Here, I've tried to replicate it in Python. The results aren't necessarily identical to ImageJ's implementation, but should be pretty close."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:173
msgid "Select to {guilabel}`Show code cell contents` above to see how it works."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:181
msgid "Computing the ultimate points from a binary image can be an effective step towards counting the objects in the image -- even if these have been merged. It works best when the true objects are round in shape."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:188
msgid "Watershed (after distance transform)"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:190
msgid "As the name suggests, ImageJ's {menuselection}`Process --> Binary --> Watershed` command applies a watershed transform."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:192
msgid "However, as the name conceals, the watershed transform is always applied to a distance map -- which is calculated automatically in the background."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:194
msgid "The clue to this is only that it appears in a {menuselection}`Process --> Binary` submenu, and therefore requires a binary image as input; a 'regular' watershed transform isn't normally applied to a binary image."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:196
msgid "Effectively, the seeds of the watershed transform are the 'ultimate points' described above. The effect of the command is therefore to split 'roundish' objects."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:204
msgid "Watching the distance transform"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:208
msgid "If you click the {guilabel}`Dev` toolbar button and select {menuselection}`Debug Mode` from the drop-down menu, then running {menuselection}`Process --> Binary --> Watershed` will generate an image stack that visualizes how the seeds expanded during the watershed processing."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:213
msgid "Voronoi"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:215
msgid "{menuselection}`Process --> Binary --> Voronoi` is another distance-and-watershed-based command for binary images."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:217
msgid "It will partition the image into different regions so that the separation lines have an equal distance to the nearest foreground objects."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:231
msgid "Imagine you have created a binary image containing detected cells, but you are only interested in the region inside the cell that is close to the membrane, i.e. within 5 pixels of the edge of each detected object. Any pixels outside the objects or closer to their centers do not matter."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:234
msgid "How would you go about finding these regions using ImageJ and the distance transform?"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:236
msgid "**Note:** There other ways to do this using techniques we've discussed, although these don't necessarily give identical results."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:242
msgid "This is the approach I was thinking of:"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:243
msgid "Run {menuselection}`Edit --> Invert`"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:244
msgid "Run {menuselection}`Process --> Binary --> Distance Map`"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:245
msgid "Run {menuselection}`Image --> Adjust --> Threshold...`"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:246
msgid "Choose {guilabel}`Set` and enter *Lower Threshold Level: 1* and *Higher Threshold Level: 5*."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:248
msgid "There are more possible ways, such as applying a maximum filter and subtracting the original binary image -- but I think the distance transform is more elegant. The distance transform is also likely to be much faster for large distances, and more precise (assuming you use a 32-bit output)."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:256
msgid "Watershed transform"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:263
msgid "So if ImageJ has a watershed transform, but it's not the command called {menuselection}`Watershed`, then where is it?"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:265
msgid "The answer is that it's hidden in the phenomenally useful {menuselection}`Process --> Find maxima` command."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:267
msgid "I say 'hidden', because you specifically have to choose the output {guilabel}`Segmented Particles` to use it. And you'll need to flip your expectations: unlike most watershed transforms, it will start at the *intensity peaks* of the image (i.e. the maxima) and expand outwards, rather than starting at minima."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:270
msgid "But don't let those things discourage you: I highly recommend exploring the various options of {menuselection}`Process --> Find maxima` to see what all it can do. Depending upon which options are selected, this includes finding structures using a global threshold, a local threshold, generating point ROIs and generating binary regions."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:275
msgid "Check out MorphoLibJ"
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:278
msgid "Echoing my recommendation at the end of the last chapter, you should check out **MorphoLibJ** if you would like more transform options -- particularly when it comes to watersheds of various kinds."
msgstr ""

#: ../../chapters/2-processing/6-transforms/imagej.md:280
msgid "See https://imagej.net/plugins/morpholibj for more details."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:16
#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:418
msgid "Image transforms"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:21
msgid "The **watershed transform** can be used to split structures using intensity values"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:22
msgid "The **distance transform** calculates the distance between foreground and background pixels in a binary image"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:23
msgid "The **distance & watershed transforms** can be combined to separate round structures"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:44
msgid "An **image transform** converts an image into some other form, in which the pixel values can have a (sometimes very) different interpretation."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:46
msgid "There are lots of ways to transform an image. We will focus on two that are especially useful for bioimage segmentation and analysis: the distance transform and the watershed transform. We will briefly introduce both, before then showing how they can be used in combination."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:52
msgid "The distance transform"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:54
msgid "The **distance transform** (sometimes called the **Euclidean distance transform**) replaces each pixel of a binary image with the distance to the closest background pixel. If the pixel itself is already part of the background then this is zero. The result is an image called a **distance map**."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:88
msgid "A binary image and its corresponding distance map, including pixel values as an overlay."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:93
msgid "A natural question when considering the distance transform is: *why*?"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:95
msgid "Although its importance may not be initially obvious, we will see that creative uses of the distance transform can help solve some other problems rather elegantly."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:97
msgid "For example, eroding or dilating binary images by a large amount can be very slow, because we have to use large maximum or minimum filters. However, erosion and dilation can be computed from a distance map very efficiently simply by applying a global threshold. This can be much faster in practice."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:130
msgid "Implementing erosion (C) and dilation (F) of binary images by thresholding distance maps."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:135
msgid "But the distance map contains useful information that we can use in other ways."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:137
msgid "For example, we can also use distance maps to estimate the **local thickness** of a structure. An application of this would be to assess blood vessel diameters. If we have a binary image representing a vessel, we can generate both a distance map and a thinned binary image. The distance map values corresponding to foreground pixels in the thinned image provide a local estimate of the vessel radius at that pixel, because the distance map gives the distance to the nearest background pixel -- and thinned pixels occur at the vessel center."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:142
msgid "However, the distance transform can become even more useful if we combine it with other transforms."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:146
msgid "The watershed transform"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:148
msgid "The **watershed transform** is an example of a **region growing** method: beginning from some **seed regions**, the seeds are progressively expanded into larger regions until all the pixels of the image have been processed. This provides an alternative to straightforward thresholding, which can be *extremely* useful when need to partition an image into many different objects."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:151
msgid "To understand how the watershed transform works, picture the image as an uneven landscape in which the value of each pixel corresponds to a height."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:196
msgid "Visualizing an image as a landscape, using surface plots. Higher pixel values are generally viewed as peaks, although can easily switched to become valleys by inverting the image before plotting. This may be useful when providing input to the watershed transform."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:201
msgid "Now imagine water falling evenly upon this surface and slowly flooding it. The water gathers first in the deepest parts; that is, in the places where pixels have values lower than all their neighbors. These define the **seeds** of the watershed transform; we can think of them as separate water basins."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:205
msgid "As the water level rises across the image, occasionally it will reach a ridge between two basins -- and, in reality, water could spill from one basin into the other. However, in the watershed transform this is not permitted; rather a dam is constructed at such ridges. The water then continues to rise, with dams being built as needed, until in the end every pixel is either part of a basin or a ridge, and there are exactly the same number of basins afterwards as there were at first."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:211
msgid "The operation of the watershed transform is illustrated in the video below and example output shown in {numref}`fig-transform_surface_watershed`."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:259
msgid "Applying the watershed transform to an image. Here, we passed the inverted image to the watershed transform because we want to identify bright spots rather than dark ones. The full watershed transform will expand the seeds to create a labeled image including all pixels, but we can optionally mask the expansion to prevent it filling the background. Here, we defined the mask by applying a global threshold using the triangle method. Note that the masked watershed segmentation is able to split some spots that were merged using the global threshold alone."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:262
msgid "Crucially, as the seeds are expanded during the watershed transform, regions are not allowed to overlap. Furthermore, once a pixel has been assigned to a region then it cannot be moved to become part of any other region."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:265
msgid "Using the 'rain falling on a surface' analogy, the seeds would be **regional minima** in an image, i.e. pixels with values that are lower than all neighboring pixels. This is where the water would gather first."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:268
msgid "In practice, we often need to have more control over the seeds rather than accepting all regional minima (to see why too many local minima could be a problem, observe that {numref}`fig-transform_surface_watershed` contains more regions that we probably would want). This variation is called the **seeded watershed transform**: the idea is the same, but we simply provide the seeds explicitly in the form of a labeled image, and the regions grow from these. We can generate seeds using other processing steps, such as by identifying [H-minima](sec_h_extrema)."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:274
msgid "Combining transforms"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:276
msgid "The watershed transform can be applied to any image, but it has some particularly interesting applications when it is applied to an image that is a distance map."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:278
msgid "Splitting round objects"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:280
msgid "A distance map has regional maxima whenever a foreground pixel is further from the background than any of its neighbors."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:282
msgid "This tends to occur towards the center of objects: particularly round objects that don't contain any holes. Importantly, regional maxima can still be present even if the 'round objects' are connected to one another in the binary image used to generate the distance map originally."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:285
msgid "This means that by applying a watershed transform to a distance map, we are able to split 'roundish' structures in binary images. The process is as follows:"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:288
msgid "Compute the distance map of the image"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:289
msgid "Invert the distance map (e.g. multiply by -1), so that peaks become valleys"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:290
msgid "Apply the watershed transform, starting from the regional minima of the inverted distance map"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:320
msgid "Splitting round objects using the distance and watershed transforms."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:323
msgid "The objects to be split do not have to be perfectly round. The only requirement is that there are clearly distinct regional maxima in the distance transform -- or, alternatively, we can define suitable seeds using other processing steps."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:368
msgid "Splitting merged blobs based on 'roundness' using the distance and watershed transforms. Because there are many small regional maxima in the distance transform, here we define seeds using H-maxima followed by a 3×3 dilation to avoid excessive splitting."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:372
msgid "Watershed lines"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:375
msgid "When applying a watershed transform, it is often possible to specify whether the separations between regions are assigned one of the region labels, or are left as background pixels."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:377
msgid "Here, we have shown the separations as background pixels. This is consistent with how ImageJ's default watershed command works, and also makes the splits clearer in the figures shown here. In Python code using scikit-image, that means we are using the `watershed_lines=True` option."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:384
msgid "Partitioning images with Voronoi"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:386
msgid "Calculating the distance transform of an *inverted* binary image gives a distance map in which each pixel gives the distance to the closest foreground object."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:388
msgid "If we apply a watershed transform to this distance map, using the objects in the binary image as seeds, we effectively partition the image into different regions according to the closest object in the binary image."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:390
msgid "This is sometimes called the **Voronoi transform** of the image."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:422
msgid "Expanding blobs to compute the Voronoi transform of a labeled image, partitioning it into different regions according to the closest seed object."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:427
msgid "Expanding without overlaps"
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:429
msgid "Building upon the Vononoi idea in the last section, we can expand the objects themselves in such a way that they don't overlap."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:435
msgid "QuPath's cell detection, based upon nucleus detection + watershed expansion."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:438
msgid "Our goal is to dilate each object in the image by 10 pixels, but without merging. If seed objects are closer than 20 pixels apart, they each expand the same amount -- until they meet in the middle. This technique may be used to approximate a cell boundary based upon detected nuclei by expansion using a fixed distance."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:442
msgid "Firstly, we look at what *won't* work. We can't simply dilate a labeled image with a maximum filter, because there's nothing to prevent regions merging into one another. When seeds are close together, the higher label will 'win' the expansion race in every case, dominating the output."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:473
msgid "Expanding blobs using a maximum filter only. This approach is too simple; it results in overlapping labels and a lot of confusion."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:478
msgid "Instead, we need to build upon the Voronoi approach shown in {numref}`fig-morph_voronoi_expand`. The only difference we need to incorporate is that we prevent the watershed expansion from growing beyond 10 pixels."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:481
msgid "Fortunately, this criterion is easy to set: our distance map already gives us the distance to every seed object. We can threshold that to define a binary mask that indicates where regions should no longer expand. If we update our watershed output to have background pixels at the same locations where our binary mask has background pixels, we have achieved a constrained expansion of 10 pixels without overlap."
msgstr ""

#: ../../chapters/2-processing/6-transforms/transforms.md:522
msgid "Using distance and watershed transforms to expand regions by a fixed distance, without overlap. The final output (F) is obtained using information from all images (A) - (E)."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:15
msgid "ImageJ: Multidimensional processing"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:19
#: ../../chapters/appendices/python/python.md:19
msgid "Work in progress!"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:22
msgid "This section isn't complete yet. It's really just a scattered collection of thoughts for now."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:44
msgid "This section gives a brief overview of some things to think about when working with z-stacks and time series in ImageJ."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:48
msgid "Point operations, contrast & conversion"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:50
msgid "Point operations are straightforward: they depend only on individual pixels, so the number of dimensions is unimportant. Image arithmetic involving a 3D stack and a 2D image can also be carried out in ImageJ using the {menuselection}`Process --> Image Calculator`, where the operation involving the 2D image is applied to each slice of the 3D stack in turn. Other options, such as filtering and thresholding, are possible, but bring with them extra considerations -- and often significantly higher computational costs."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:54
msgid "Setting the LUT of a 3D image requires particular care. The normal {menuselection}`Brightness/Contrast...` tool only takes the currently-displayed slice into consideration when pressing {guilabel}`Reset` or {guilabel}`Auto`. Optimizing the display for a single slice does not necessarily mean the rest of the stack will look reasonable if the brightness changes much. {menuselection}`Process --> Enhance Contrast...` is a better choice, since here you can specify that the information in the entire stack should be used. You can also specify the percentage of pixels that should be saturated (clipped) _for display_, i.e. those that should be shown with the first or last colors in the LUT. So long as {guilabel}`Normalize` and {guilabel}`Equalize histogram` are not selected, the pixel values shouldn't be changed."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:66
msgid "By default, the percentage of saturated pixels in {menuselection}`Enhance Contrast...` is set to 0.4. Why might this be chosen instead of 0?"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:75
msgid "If the percentage of saturated pixels is 0, then the minimum and maximum pixel values throughout the image will be given the first and last LUT colors respectively, with all other colors devoted to values in between. This is sensitive to outliers, and often results in images that have poor contrast. It's usually better to accept some small amount of visual saturation, in order to give more LUT colors to the pixel values between the extremes."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:83
msgid "Converting bit-depths of multidimensional images"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:86
msgid "As described in {ref}`Types & bit-depths<sec_bit_depths_converting>`, the minimum and maximum display range values are used by default when reducing the bit-depth of an image. To minimize the information lost, these should usually be set to the minimum and maximum pixel values within the image – otherwise values will be clipped."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:89
msgid "In 2D it's enough to press {guilabel}`Reset` in the {menuselection}`Brightness/Contrast` window, _but in 3D this will only work if the minimum and maximum values from the entire stack happen to appear on the current slice!_"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:91
msgid "For this reason, it's good practice to run {menuselection}`Enhance Contrast...` prior to reducing bit-depths of stacks, setting the saturation to 0 and using the entire stack. This means no pixels will be clipped in the output (although rescaling and rounding will still occur)."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:97
msgid "3D filtering"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:99
msgid "Many filters naturally lend themselves to being applied to as many dimensions as are required. For example, a 3×3 mean filter can easily become a 3×3×3 filter if averaging across slices is allowed. Importantly, it then replaces each pixel by the average of 27 values, rather than 9."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:103
msgid "This implies the reduction in noise is *somewhat* similar to that of applying a 5×5 filter (25 values), but with a little less blurring in 2D and a little more along the third dimension instead. Several 3D filters are available under the {menuselection}`Plugins --> Process -->` submenu."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:108
msgid "Fast, separable filters"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:110
msgid "{menuselection}`Process --> Filters --> Gaussian Blur 3D...` uses this approach."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:115
msgid "Fast filters & the Fourier transform"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:118
msgid "Not all linear filters are separable, and applying a large, non-separable linear filter can also be extremely time-consuming. However, when this is the case a whole other method can be used to get the same result using the Fourier transform – where the speed no longer has the same dependence upon the filter size. Unfortunately, the Fourier method cannot be used for non-linear filters such as the median filter."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:124
msgid "Dimensions & isotropy"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:126
msgid "If applying a filter in 3D instead of 2D, it may seem natural to define it as having the same size in the third dimension as in the original two. But for a __z__-stack, the spacing between slices is usually larger than the width and height of a pixel. And if the third dimension is time, then it uses another scale entirely. Therefore more thought usually needs to be given to what sizes make most sense."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:131
msgid "In some commands (e.g. {menuselection}`Plugins --> Process --> Smooth (3D)`), there is a {guilabel}`Use calibration` option to determine whether the values you enter are defined in terms of the units found in the {menuselection}`Properties...` and therefore corrected for the stored pixel dimensions. Elsewhere (e.g. {menuselection}`Gaussian Blur 3D...`) the units are pixels, slices and time points – and so you are responsible for figuring out how to compensate for different scales and units."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:137
msgid "Thresholding multidimensional data"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:139
msgid "When thresholding an image with more than 2 dimensions using the {menuselection}`Threshold...` command, it is necessary to choose whether the threshold should be determined from the histogram of the entire stack, or from the currently-visible 2D slice only. If the latter, you will also be asked whether the same threshold should be used for every slice, or if it should be calculated anew for each slice based upon the slice histogram. In some circumstances, these choices can have a very large impact upon the result."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:147
msgid "When you threshold a stack, you have an option to choose {guilabel}`Stack Histogram`. Then, when you choose {guilabel}`Apply` you are asked if you want to {guilabel}`Calculate Threshold for Each Image`. What difference do you expect these two options to make, and what combinations would you use for:"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:151
msgid "a stack consisting of 2D images from different color channels"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:152
msgid "a __z__-stack"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:153
msgid "a time series"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:155
msgid "_Note:_ Have a look at what happens when you click {guilabel}`Auto` while scrolling through one channel of the stack {menuselection}`File --> Open samples --> Mitosis (26 MB, 5D Stack)`, with and without {guilabel}`Stack Histogram` selected. You will have to split the channels for this because ImageJ currently refuses to threshold multichannel images with extra dimensions (which helps avoid some confusion). {guilabel}`Dark Background` should always be selected here."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:164
msgid "If {guilabel}`Stack Histogram` is checked, the thresholds are computed from a histogram of all the pixels in the entire image stack; otherwise, the histogram of only the currently-displayed image slice is used."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:166
msgid "BUT! If {guilabel}`Calculate Threshold for Each Image` is chosen, then this is ignored: the threshold is always determined by the selected automatic method using the histogram of the corresponding slice only."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:168
msgid "Therefore, the most sensible combinations of thresholding options to use depend upon the type of data."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:171
msgid "_color channels_ – There is often no good reason to suppose the amount of fluorescence in different color channels will be similar, and so thresholds should be calculated from each channel independently."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:172
msgid "_z-Stacks_ – It is normally a good idea to use the stack histogram with __z__-stacks. If you do not, then your threshold will be affected by whatever slice you happen to be viewing at the time of thresholding – introducing a potentially weird source of variability in the results. It is probably _not_ a good idea to calculate a new threshold for each slice, because this would lead to at least _something_ being detected on every slice. But in the outer slices there may well only be blur and noise – in which case nothing _should_ be detected!"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:176
msgid "_Time series_ – In a time series, bleaching can sometimes cause the image to darken over time. In such a case, using the stack histogram might cause fewer pixels to exceed the threshold at later time points simply for this reason, and recalculating the threshold for each image may be better. On the other hand, if images were previously normalized somehow to compensate for bleaching [^fn_1], then the stack threshold might be preferable again. It's tricky."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:184
msgid "There is one other implementation issue that needs attention. When {guilabel}`Dark Background` is checked and an automated threshold is computed, then it is only really the low threshold that matters – the high threshold is always set to the maximum in the histogram to ensure that all brighter pixels are designated 'foreground' in the result. However, if not using {guilabel}`Stack Histogram`, then for non-8-bit images the histograms are calculated using the minimum and maximum pixels on the slice, and consequently the high threshold cannot be higher than this maximum value (look at how the high threshold value changes in {menuselection}`Mitosis` as you compute auto thresholds for different slices). This means that any brighter pixels will be _outside_ the threshold range (and therefore 'background') if they occur on a different slice. This can cause holes to appear in the brightest parts of structures, and is probably not what you want. A similar situation occurs with the low threshold when {guilabel}`Dark Background` is unchecked."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:196
msgid "Measurements in 3D data"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:198
msgid "ImageJ has good support for making measurements in 2D, particularly the {menuselection}`Measure` and {menuselection}`Analyze Particles...` commands. The latter can happily handle 3D images, but only by creating and measuring 2D ROIs independently on each slice. Alternatively, {menuselection}`Image --> Stacks --> Plot Z-axis Profile` is like applying {menuselection}`Measure` to each slice independently, making measurements either over the entire image or any ROI. It will also plot the mean pixel values, but even if you do not particularly want this the command can still be useful. However, if single measurements should be made for individual objects that extend across multiple slices, neither of these options would be enough."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:218
msgid "Suppose you have a cell, nucleus or some other large 3D structure in a __z__-stack, and you want to draw the smallest 2D ROI that completely contains it on every slice. An example is shown below for the green structure in the {menuselection}`Confocal Series` sample image."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:221
msgid "How would you create such a ROI, and be confident that it is large enough for all slices?"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:223
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/launch-imagej-js-badge.svg)](https://ij.imjoy.io?run=https://gist.github.com/petebankhead/55b02288a529512fee0f321fee0da693)"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:233
msgid "My strategy would be to create a z-projection (max intensity) and then draw the ROI on this – or, preferably, create the ROI by thresholding using {menuselection}`Image --> Adjust --> Threshold` and the {guilabel}`Wand` tool. This ROI can then be transferred over to the original stack, either via the ROI Manager or {menuselection}`Edit --> Selection --> Restore Selection`."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:241
msgid "Histograms & threshold clipping"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:243
msgid "One way to measure in 3D is to use the {menuselection}`Histogram` command and specify that the entire stack should be included – this provides some basic statistics, including the total number, mean, minimum, maximum and standard deviation of the pixels [^fn_2]. This will respect the boundaries of a 2D ROI if one has been drawn."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:249
msgid "This is a start, but it will not adjust to changes in the object boundary on each 2D plane. A better approach could be to use {menuselection}`Image --> Adjust --> Threshold...` to set a threshold that identifies the object – but do _not_ press {guilabel}`Apply` to generate a binary image. Rather, under {menuselection}`Analyze --> Set Measurements...` select {guilabel}`Limit to threshold`. Then when you compute the stack histogram (or press {menuselection}`Measure` for 2D) only above-threshold pixels will be included in the statistics. Just be sure to reset {guilabel}`Limit to threshold` later."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:261
msgid "How can you translate the total number of pixels in an object into its volume, e.g. in µm<sup>3</sup>? Give some thought to how accurate your method will be."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:270
msgid "You could treat each pixel as a rectangular cuboid, with a volume equal to _pixel width_×_pixel height_×_voxel depth_ (as given in {menuselection}`Image --> Properties...`). Then multiply this by the number of pixels within the object. This is what the {ref}`3D Objects Counter<sec_multidimensional_counter>`  plugin does when measuring volumes."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:274
msgid "Whenever you want to compare object sizes across images acquired with different pixel sizes, this is certainly better than just taking the raw pixel counts as measures of volume. However, it is unlikely to be very accurate – and volume measurements obtained this way should not be trusted too much, especially when dealing with very small sizes. They are also likely to be quite sensitive to spacing."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:286
msgid "I am not a fan of {guilabel}`Limit to threshold`, because I am likely to forget to reset it afterwards and may subsequently measure the wrong things for days thereafter."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:288
msgid "An alternative that I prefer is to set my threshold on a 32-bit copy of the image I am working with, and then {guilabel}`Apply` the threshold using the {guilabel}`Set Background Pixels to NaN` option. Then all below-threshold pixels will automatically be excluded from any measurements I make on the result, since they are 'no longer numbers' (see {ref}`Thresholding <sec_thresholding_nans>` for more details)."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:292
msgid "The 3D Objects Counter"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:294
msgid "Currently, the closest thing to {menuselection}`Analyze Particles...` for measuring connected objects in 3D built-in to Fiji is the 3D Objects Counter ({menuselection}`Analyze --> 3D Objects Counter`) [^fn_3]. Its settings (analogous to {menuselection}`Set Measurements...`) are under {menuselection}`Analyze --> 3D OC Options`. In addition to various measurements, it provides labelled images as output, either of the entire objects or only their central pixels – optionally with labels, or expanded to be more visible."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:302
msgid "Find Connected Regions"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:305
msgid "{menuselection}`Plugins --> Process --> Find Connected Regions` is a command primarily for creating labelled images from thresholded 3D data, which can also give the total number of pixels per object. If the main thing you want is the labelled image without many more results, it may be faster than {menuselection}`3D Objects Counter`."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:310
msgid "Additional 3D tools"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:313
msgid "For working with 3D data, it may be very useful to download the '3D ImageJ Suite' from https://imagej.net/plugins/3d-imagej-suite/. his not only includes a range of fast filters and commands for segmentation, but also a 3D version of the ROI Manager."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:316
msgid "While created for bone image analysis, _BoneJ_ (https://bonej.org) also includes some components that are useful for general applications –- including a fast [3D Particle Analyser](https://bonej.org/particles) (another alternative to the 3D Objects Counter) and a tool to [interpolate ROIs across image slices](https://bonej.org/utilities)."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:181
msgid "See https://imagej.net/Bleach_Correction"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:246
msgid "Be careful! If you have multiple channels, these should be split first"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/imagej.md:298
msgid "See See S Bolte and F P Cordelières. “A guided tour into subcellular colocalization analysis in light microscopy.” Journal of Microscopy 224.Pt 3 (Dec. 2006), pp. 213–32. url: https://pubmed.ncbi.nlm.nih.gov/17210054/"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:16
msgid "Multidimensional processing"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:21
msgid "Many processing operations can be extended **beyond 2 dimensions**"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:22
msgid "Adding extra dimensions can greatly increase the **computational requirements**"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:43
msgid "So far, in terms of image processing we have concentrated only on 2D images. Most of the operations we have considered can also be applied to 3D data -- and sometimes data with more dimensions, in cases where this is meaningful."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:46
msgid "This very short overview of multidimensional processing describes a few of the issues to consider when extending analysis beyond two dimensions, and gives some pointers towards specialist tools."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:48
msgid "We will focus on 3D images: specifically, on *z*-stacks."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:50
msgid "What about channels and time?"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:52
msgid "The [5 main dimensions](chap_dimensions) commonly encountered in bioimage analysis are *x*, *y*, *z*, *channels*, and *time*. The first three are similar (spatial), whereas the last two are somewhat different."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:55
msgid "Although we considered channels to be another dimension [in previous chapters](chap_dimensions), we don't usually apply operations (e.g. filters, thresholds) *across* channels or time. Rather, we usually split the channels or timepoints during processing (e.g. to detect nuclei from one channel and a cell boundary in a second channel), then combine the ROIs or measurements at the end."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:59
msgid "Tinevez, J.-Y., et al. (2017). TrackMate: An open and extensible platform for single-particle tracking. *Methods*, 115, 80–90. [(DOI)](https://doi.org/10.1016/j.ymeth.2016.09.016)"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:62
msgid "This means that the key processing steps don't require an extra dimension for channels or time."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:64
msgid "In the case of time, the 'combining' step may involve linking objects to track them. Tools such as the fantastic [**Trackmate**](https://imagej.net/plugins/trackmate/) can be used for this."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:69
msgid "nD image analysis"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:72
msgid "If a technique works for ***nD*** images, this indicates it can handle any number of dimensions. The SciPy [Multidimensional image processing](https://docs.scipy.org/doc/scipy/reference/ndimage.html) package embraces this, being imported as `scipy.ndimage`."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:78
msgid "Segmentation in 3D"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:80
msgid "Image segmentation generally involves generating binary and labeled images."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:82
msgid "Most of the processing operations we have discussed to help perform image segmentation extend naturally into 3D (and beyond), although there are some extra considerations."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:88
msgid "Thresholds are typically determined using the image histogram. This is computed from all pixels in the image -- the number of dimensions does not really matter."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:91
msgid "The main consideration for thresholding in 3D is whether the other *z*-slices could introduce any kind of sneaky bias. One occasion when that could happen is if the images are acquired with different numbers of slices, e.g. some containing more out-of-focus planes than others ({numref}`fig-multi_thresholds`). These extra planes *could* impact the histogram and image statistics, and therefore any automated thresholds. An image with many out-of-focus slices might be thresholded differently from an image with few slices."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:96
msgid "A solution for that may be to extract a fixed number of slices from each image, for example 10 slices centered upon the volume of interest within the image. This should generally make the images more comparable."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:228
msgid "Thresholding a z-stack can be influenced by the number of out-of-focus slices. Here, an automated threshold determined using [Otsu's method](sec_thresholds_otsu) is applied to two z-stacks showing the same object. The top stack contains few out-of-focus slices, while the bottom stack contains the exact same data plus additional slices that contain only noise. Otsu's method is well-suited to the top stack and performs well, however it fails badly on the bottom stack, where there is a much higher proportion of background pixels -- and so the background peak is more dominant."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:236
msgid "How would you expect {numref}`fig-multi_thresholds` to differ if the [triangle method](sec_thresholds_triangle) was used to determine the threshold, rather than [Otsu's method](sec_thresholds_otsu)?"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:240
msgid "Here, the triangle method performs well. It sets the threshold appropriately at the foot of the background peak in both cases."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:254
msgid "Filtering"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:256
msgid "**Linear filters** can be easily extended to *nD* by defining a filter kernel with the desired number of dimensions. However, this can dramatically increase the computational requirements and so we need to begin considering performance."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:259
msgid "For example, suppose we have a 3×3 filter. Following the algorithm for linear filtering [described previously](sec_filters_linear), we would have to perform 9 multiplications and additions to determine the value for *every* pixel in the output image. If our image is 1000×1000 pixels in size, that suggests 9,000,000 multiplications and additions. This seems quite a lot, but modern computers are fast so we're unlikely to notice it."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:264
msgid "However, if we have a 3×3×3 filter then each output pixel depends upon 27 input pixels. And the additional slices mean our image is likely to be bigger; say, 1000×1000×10 pixels. Now we have to perform calculations involving 270,000,000 pixels, i.e. a lot more. Still, even that is probably fast nowadays."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:269
msgid "But how big can we go? An 11×11 filter involves 121 pixels. But an 11×11×11 filter involves 1331. For larger filters and images, we can rapidly increase the computations involved until processing *is* very slow."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:276
msgid "The situation improves *dramatically* if a filter is **separable**. This means that instead of applying, for example, a single 11×11×11 filter (1331 coefficients) we can instead apply three separate 11×1 filters oriented along each dimension (33 coefficients)."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:279
msgid "Not all linear filters are separable, but many common ones are. This includes mean filters (depending upon neigborhood shape) and Gaussian filters. The result of applying the filter separably should be the same as the result of applying one dense multidimensional filter ({numref}`fig-gauss_separable`). Some small differences may arise through the handling of [rounding and bit-depths](chap_bit_depths), but the improvement in performance is almost certainly worth any tiny error introduced by applying a filter separably."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:332
msgid "2D Gaussian smoothing can be applied using a single 2D filter, or by sequentially filtering either rows or columns of the image: the end result is the same (up to rounding error). The order of the separable filtering doesn't matter."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:337
msgid "Considerations are similar for **nonlinear filters**: when we add more dimensions, the neighborhood size can increase quickly and make the calculations slow. Separability can help with some nonlinear filters (e.g. minimum and maximum, depending on window shape), but not all. Median filters in particular are difficult to optimize, and can be *extremely* slow when the neighborhood is large and/or more than 2D."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:341
msgid "Isotropy and anisotropy"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:344
msgid "As discussed {ref}`chap_pixel_size`, the pixel width and height are usually the same. For a *z*-stack, the *z*-spacing *might* be the same as the width and height, in which case the pixels are called **isotropic**. But very often the *z*-spacing is different, meaning that the pixels are **anisotropic**."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:348
msgid "It helps to keep this in mind when choosing filter sizes. For example, I would usually set the $\\sigma$ value for a 3D Gaussian filter based upon the pixel size."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:351
msgid "Suppose that the pixel width and height are both 0.5 µm, and the *z*-spacing is 1 µm. I might then choose $\\sigma_x$ = 2 px, $\\sigma_y$ = 2 px and $\\sigma_z$ = 1 px to compensate for the difference."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:354
msgid "Note that some software may allow you to enter the $\\sigma$ in µm directly, and perform the conversion to pixels automatically."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:403
msgid "A 15×15 minimum filter applied separably."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:410
msgid "Erosion, dilation, opening and closing can all be implemented using minimum and maximum nonlinear filters, so the above considerations apply. Morphological reconstruction can also work in *nD*. Therefore all the new operations and tricks derived from these methods (e.g. creating outlines, finding regional maxima) should work."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:414
msgid "Thinning algorithms are often designed to work in 3D, although not usually higher dimensions."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:420
msgid "The distance and watershed transforms extend readily to 3D, but require a little caution."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:422
msgid "One thing to look out for, especially with the distance transform, is whether pixel anisotropy is taken into consideration. If not, the the distance transform will not be capable of properly identifying the 'nearest' foreground or background pixel in calibrated units, but rather only in pixel units."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:425
msgid "A cumbersome workaround may be to resize the image so that the pixels *are* isotropic, but that may make every other analysis step more complicated and/or require a huge amount more memory to store the image. A preferable approach is to try to find a distance transform implementation that incorporates pixel size information into its calculations."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:430
msgid "Accelerating analysis"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:432
msgid "One of the common themes of processing multidimensional images is performance."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:434
msgid "Even though *conceptually* most of the image processing techniques we've discussed can be extended to 3D and beyond, it's usually not easy to do from the programmer's perspective. As someone who writes software, I can attest that I don't tend to support more dimensions than I have to because extra dimensions make the task of coding, debugging and optimizing much, much harder."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:437
msgid "'Optimizing' really matters because, as mentioned above, computational requirements can increase quickly and dramatically with multidimensional data. That doesn't just mean the software itself needs to be optimized to run fast: the user plays a huge role in choosing what they ask the software to do. Keep in mind:"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:441
msgid "The most important performance consideration is the algorithm!"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:444
msgid "Before investing in a bigger computer to try to speed up a slow analysis workflow, look for ways to make it more efficient without compromising accuracy."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:446
msgid "For example, do you really need to apply a 49×49×49 pixel filter to a large image, at a cost of 117,649 multiplications & additions for *every pixel*? If a separable filter can be used instead, you can shrink that figure to 147 (~0.12%). Perhaps the calculation can also be performed on a lower resolution image, saving even more effort."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:450
msgid "Alternatively, if you find you're applying large minimum or maximum filters to a binary image, perhaps you could instead use a [distance transform for erosion and dilation](fig-morph_distance)."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:452
msgid "When processing is slow, it's worth trying to get the computer to work smarter, not harder."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:455
msgid "Nevertheless, there comes a time when better hardware really can help -- assuming the software can take advantage of it."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:457
msgid "Most modern computers capable of image analysis contain multiple processors, which can do multiple things at the same time. Image analysis software that supports **multiprocessing** is able to use these processors to operate on different parts of the data simultaneously. It's more work for the programmer, but better for the user."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:461
msgid "The benefits of multiprocessing can be important, but still tend to be fairly modest. A typical desktop computer today could have between 2 and 8 processors (although particularly powerful machines can have more). However, doubling the numbers of processors doesn't mean that the computation time is likely to be halved, because it's hard for software to keep all the processors occupied. Tasks tend to depend upon one another, and so it's common for one processor to have to lounge around while another processor is completing its part of the job. Our performance aspirations can also be thwarted by other bottlenecks, such as reading or writing images."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:467
msgid "To see a **dramatic** improvement in image processing performance, we usually need to look into **Graphics Processing Unit (GPUs)**, aka. **graphics cards**."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:469
msgid "A GPU can't do everything that a general-purpose processor can do, but it is very good at what it *can* do -- which includes core operations like image filtering or matrix multiplication."
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:472
msgid "Haase, R., Royer, L.A., Steinbach, P. et al. CLIJ: GPU-accelerated image processing for everyone. *Nat Methods* 17, 5–6 (2020). [(DOI)](https://doi.org/10.1038/s41592-019-0650-1)"
msgstr ""

#: ../../chapters/2-processing/7-multidimensional_processing/multidimensional_processing.md:475
msgid "Programming for GPUs is rather specialized, but there are some tools to help. **Robert Haase** has worked extensively on using GPUs for multidimensional bioimage analysis -- I highly recommend checking out [**CLIJ**](https://clij.github.io/) and [**clEsperanto**](https://clesperanto.github.io) for more details."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:16
msgid "From photons to pixels"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:21
msgid "The **pixel values** in a fluorescence image depend upon **numbers of detected photons**"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:22
msgid "Our images can't be perfect: **blur & noise** are inevitable"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:43
msgid "One of the most common imaging modalities associated with bioimage analysis is fluorescence microscopy. Applying the analysis techniques described in this book meaningfully to fluorescence images involves understanding a bit about the imaging process."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:46
msgid "Part III aim to provide an introduction to the main ideas, along with some useful mental models to help relate analysis techniques to imaging realities. These ideas can help with figuring out how to acquire and analyze fluorescence microscopy data in scientifically justifiable ways."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:51
msgid "The big picture of fluorescence imaging"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:53
msgid "Images in fluorescence microscopy are formed by detecting light. The amounts of light involved are so small that they can be thought of in terms of individual photons."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:56
msgid "The photons are emitted from fluorescent molecules within the sample being imaged. Sometimes these photon-emitting molecules may be the very things we are interested in studying, but often they have only been introduced to the sample because they have the helpful property of fluorescing in the presence of the (otherwise non-fluorescent) molecules or structures we would _really_ like to see."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:59
msgid "Either way, the most that the image can tell us is how much light was emitted from any particular point in the sample. From this information we make our interpretations, such as about the presence of absence of some feature, about the size and shape of a structure, or about the relative concentration of a molecule. But in no case are we *seeing* the feature, structure or molecule directly in the recorded images: we only have measurements of the numbers of photons we could detect, encoded in pixel values."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:63
msgid "We won't give much attention here to what any particular number of photons emanating from a sample really indicates from a biological point of view -- this would depend too much upon the design and details of the experiment, i.e. on the cells, stains and other substances involved. We can, however, often make general assumptions. One such assumption is that if we were to see (on average) twice as many photons originating from one region as from another, the number of fluorescing molecules must be around twice as high in the first region [^fn_1]. But before we can worry about such things, we should consider how accurately we can even determine the number and origins of photons being emitted from the sample in the first place, given the limited quality of the images we can actually record."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:72
msgid "Recording images"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:74
msgid "We already introduced a simple model of fluorescence image formation in {ref}`chap_pixels` with two animations. The first animation shows the overall process:"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:85
msgid "The second animation zooms in to give more detail on photon detection, and how this ultimately leads to pixel values being stored in a digital image:"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:95
msgid "It will be helpful to keep this model in mind throughout the following sections."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:97
msgid "Once a sample has been prepared and is waiting underneath the microscope, the basic process of recording a fluorescence image comprises four main steps:"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:99
msgid "**Fluorophore excitation.** The fluorescent molecules (fluorophores) first need to be raised into an excited state. This happens upon the absorption of a photon, the energy (i.e. wavelength) of which should fall into a range specific to the fluorophore itself. This is carried out by illuminating the sample, e.g. with a lamp or laser."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:103
msgid "**Photon emission.** When returning to its ground state, each fluorophore may emit a photon –- this time with a lower energy (i.e. longer wavelength) than the photon previously absorbed."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:104
msgid "**Photon detection.** Most emitted photons can be thought of, rather informally, as 'shooting off in the wrong direction', in which case we have no hope of detecting them. But a proportion of the light should enter the objective lens of the microscope and be focussed towards a detector. When a photon strikes the detector, it is registered as a 'hit' by the release of an electron (if we're lucky; detectors are imperfect so this might not occur, meaning the photon is effectively lost)."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:107
msgid "**Quantification & storage.** After fixed time intervals, the charges of the electrons produced by photons striking the detector are quantified, and from these quantifications pixel values are determined. A larger charge indicates more photons, which translates into a higher pixel value."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:111
msgid "Errors and imprecisions"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:113
msgid "From the above summary, it's clear that we are quite some distance away from knowing exactly how much light is emitted from the sample: most photons do not reach the detector, and many that do are still not registered. But since we can expect to always lose track of a similar proportion of emitted light -- perhaps as much as 90% -- this does not matter much: we can expect all parts of the image to be similarly affected, so relative differences in brightness would still be reflected in our pixel values."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:116
msgid "However, this isn't our only limit. There are two more critical ways in which the images we can record are worse than the images we would like:"
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:120
msgid "**Uncertainty in space.** Ideally, all light originating from a particular point in the sample would strike the detector in exactly the same place, and therefore contribute to exactly the same pixel. In practice, however, _the light originating from one point can't be focused back to a single point on the detector_. Consequently, it can end up being spread over several pixels. The end result is that the image is _blurred_."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:124
msgid "**Uncertainty in brightness.** When an image is blurry we would also expect it to be smooth, but this is not usually what we get in fluorescence microscopy. Rather, there are seemingly random variations in brightness everywhere throughout the image: the _noise_. Some noise can come from imprecisions when determining the charge of small clouds of electrons quickly. But, more fundamentally, _the emission of the photons is itself random_. This means that even if we could detect every photon perfectly we would *still* get noisy images."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:130
msgid "These issues are depicted in {numref}`fig-colored_spots`."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:212
msgid "The difference between what we might wish to image, and what we actually can image. *(Top)* Ideally, the small colored spots in reality would directly map to colored spots of a related size and separation in the image. This would make measuring the structures relatively straightforward: whatever we measure in the image accurately corresponds to the reality. *(Bottom)* In practice, the light emitted from our real structures would actually end up producing larger, blurry objects in the image with noise added on top. The *Blurred + Noisy* image then represents what we can *actually* acquire with a light microscope. For analysis, we need to use this decidedly imperfect image to try to figure out what the measurements of the real structures should be."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:215
msgid "The twin issues of blur and noise do not affect all images equally. For example, blur can cause us to misjudge the size of something by several hundred nanometers; if the thing we are measuring is much larger than this then the relative error may be trivial, but if it is smaller then the relative error may be huge. Similarly, if we are detecting many thousands of photons then the uncertainty due to noise may be extremely small relative to the numbers involved, but if we have few photons then noise could dominate our results."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:219
msgid "The biggest challenges arise whenever we are interested in measuring tiny structures in images containing only tens of photons at their brightest points. This is inconventiently common. In such cases, the effects of blur and noise can't be ignored."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:223
msgid "The good news is that image processing can help us. However, we need to understand the problem so that we can choose appropriate processing techniques to apply. For that reason, the next two chapters will describe blur and noise in more detail -- and point towards ways we can deal with them."
msgstr ""

#: ../../chapters/3-fluorescence/1-formation_overview/formation_overview.md:68
msgid "This assumes a linear relationship, which does not always hold (e.g. if there's dye saturation, or high laser powers are used for illumination)."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:16
msgid "Blur & the PSF"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:21
msgid "Measurements in fluorescence microscopy are affected by **blur**"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:22
msgid "Blur acts as a convolution with the microscope's **Point Spread Function (PSF)**"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:23
msgid "The size of the PSF depends on the **microscope type**, **light wavelength** & **objective lens Numerical Aperture (NA)**, and is on the order of hundreds of nm"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:24
msgid "In the focal plane, the PSF is an **Airy pattern**"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:25
msgid "**Spatial resolution** is a measure of how close structures can be distinguished. It's better in _xy_ than along the _z_ dimension."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:47
msgid "Microscopy images normally look blurry because light originating from one point in the sample is not all detected at a single pixel: usually it is detected over several pixels and _z_-slices. This is _not_ simply because we cannot use perfect lenses; rather, it's caused by a fundamental limit imposed by the nature of light. The end result is as if the light that we detect is redistributed slightly throughout our data ({numref}`fig-castles`)."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:65
msgid "Schematic diagram showing the effects of blur. Think of the sand as photons, and the [height of the sandcastle as the intensity values of pixels](fig-transform_surface) (a greater height indicates more photons, and thus a brighter pixel). The ideal data would be sharp and could contain fine details (A), but after blurring it's not only harder to discriminate details, but intensities in the brighter regions have been reduced and sizes increased (B). If we then wish to determine the size or height of one of the sandcastle's towers, for example, we need to remember that any results we get by measuring (B) will differ from those we would have got if we could have measured (A) itself. Note, however, that approximately the same _amount_ of signal (sand or photons) is present in both cases –- only the arrangement has been changed."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:68
msgid "This is important for three reasons:"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:70
msgid "Blur affects the apparent **size** of structures"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:71
msgid "Blur affects the apparent **intensity** (i.e. brightnesses) of structures"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:72
msgid "Blur (sometimes) affects the apparent **number** of structures"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:74
msgid "Therefore, _almost every measurement_ we might want to make can be affected by blurring to some degree."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:76
msgid "That's the bad news about blur. The good news is that it's rather well understood, and we can take some comfort that it is not random. In fact, the main ideas have already been described in {ref}`chap_filters`, because blurring in fluorescence microscopy is mathematically described by a **convolution** involving the microscope's **Point Spread Function (PSF)**. In other words, the PSF acts like a linear filter applied to the perfect, sharp data we would like but can never directly acquire."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:81
msgid "Previously, we saw how smoothing (e.g. mean or Gaussian) filters could helpfully reduce noise, but as the filter size increased we would [lose more and more detail](chap_filters_gaussian_size). At that time, we could choose the size and shapes of filters ourselves, changing them arbitrarily by modifying coefficients to get the noise-reduction vs. lost-detail balance we liked best. But the microscope's blurring differs in at least two important ways. Firstly, it's effectively applied to our data _before_ noise gets involved, so offers no noise-reduction benefits. Secondly, because it occurs before we ever set our eyes on our images, the size and shape of the filter used (i.e. the PSF) are only indirectly (and in a very limited way) under our control. It would therefore be much nicer just to dispense with the blurring completely since it offers no real help, but unfortunately light conspires to make this not an option: we just need to cope with it."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:88
msgid "The purpose of this chapter is to offer a practical introduction to why the blurring occurs, what a widefield microscope's PSF looks like, and why all this matters. Detailed optics and threatening integrals are not included, although several equations make appearances. Fortunately for the mathematically unenthusiastic, these are both short and useful."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:92
msgid "Blur & convolution"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:94
msgid "As stated above, the fundamental cause of blur is that light originating from an infinitesimally small point cannot then be detected at a similar point, no matter how great our lenses or detectors might be. Rather, it ends up being focused to some larger volume known as the PSF, which has a minimum size dependent upon both the light's wavelength and the lens being used."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:113
msgid "Although it might not be obvious at low magnification (A), an image can be viewed as composed of small points (B). This gives us a useful way to understand what has happened in a blurred image: each point has simply been replaced by a more diffuse blob, the PSF. Images appear more or less blurred depending upon how large the blobby PSFs are \\(C) and (D). This is equivalent to applying the PSF to an image as a linear filter."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:117
msgid "This becomes more practically relevant if we consider that _any_ fluorescing sample can be viewed as composed of many similar, exceedingly small light-emitting points -- you may think of each point being a fluorophore. Our image would ideally then include individual points too, digitized into pixels with values proportional to the emitted light. But what we get instead is an image in which every point has been replaced by its PSF, scaled according to the point's brightness. Where these PSFs overlap, the detected light intensities are simply added together. Exactly how blurry this causes the image to be depends upon the size of the PSF ({numref}`fig-psf_sizes`)."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:123
msgid "This blurring process is equivalent to **convolving** the (impossible) ideal point image with the PSF: i.e. applying a linear filter, as described in {ref}`chap_filters`. Because every point is blurred in the same way (at least in the ideal case; extra aberrations can cause some variations), this means that if we know the PSF then we can characterize the blur throughout the entire image -- and thereby make inferences about the extent to which blurring will impact upon anything we measure."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:126
msgid "The shape of the PSF"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:128
msgid "We can gain an initial impression of a microscope's PSF by recording a *z*-stack of a small, fluorescent bead, which represents an ideal light-emitting point. {numref}`fig-psf_bead` shows that, for a widefield microscope, the bead appears like a bright blob when it is in focus. More curiously, when viewed from the side (__xz__ or __yz__), it has a somewhat hourglass-like appearance -- albeit with some extra patterns. This exact shape is well enough understood that PSFs can also be generated theoretically based upon the type of microscope and objective lenses used (C)."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:148
msgid "PSFs for a widefield microscope. (A) and (B) are from z-stacks acquired of a small fluorescent bead, displayed using linear contrast and after applying a gamma transform to make fainter details easier to discern (see {ref}`chap_point_operations` for more information). \\(C) shows a theoretical PSF for a similar microscope. It differs in appearance partly because the bead is not really an infinitesimally small point, and partly because the real microscope's objective lens is less than perfect. Nevertheless, the overall shapes are similar."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:153
msgid "Generating PSFs"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:156
msgid "ImageJ plugins to create theoretical PSFs are available from"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:157
msgid "<https://imagej.net/Diffraction_PSF_3D>"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:158
msgid "<http://bigwww.epfl.ch/algorithms/psfgenerator/>"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:161
msgid "In & out of focus"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:163
msgid "{numref}`fig-psf_planes` attempts to show that the hourglass aspect of the PSF is really perfectly intuitive. When recording a *z*-stack of a light-emitting point, we would _prefer_ that the light ended up at a single pixel in a single slice. But the light itself is oblivious to our wishes, and will cheerfully be detected if it happens to strike a detector, no matter where that is. Therefore we should expect the light to be detected across a small region only if the image is in-focus; otherwise it will be spread out to an extent that depends upon how far from the focal point it is detected. From the side (__xz__ or __yz__), this leads to an hourglass shape."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:175
msgid "Simplified diagram to help visualize how a light-emitting point would be imaged using a widefield microscope. Some of the light originating from the point is captured by a lens. If you imagine the light then being directed towards a focal point, this leads to an hourglass shape. If a detector is placed close to the focal point, the spot-like image formed by the light striking the detector would be small and bright. However, if the detector were positioned above or below this focal plane, the intensity of the spot would decrease and its size would increase."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:183
msgid "In focus, a light-emitting point looks like a small, bright blob. Out of focus, it's much less bright and extends over a wider area."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:186
msgid "However, how would you expect the _total amount_ of light to differ in a widefield image depending upon whether a plane is in-focus or not? In other words, would you expect more or less light in the focal plane than in other planes above or below it?"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:194
msgid "In a widefield image, every plane we can record contains in-focus light along with _all_ the detectable light from _all_ other planes added together. Therefore we should expect approximately _the same total amount of light_ within each plane of a *z*-stack – just differently distributed. That's potentially a lot of light in the 'wrong' place, especially if looking at a thick sample."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:198
msgid "At least, this would be so for an infinitely-large detector, or a small, centered sample. In practice, if the light originates from a location so out-of-focus that its light spills over the side of the detector then this plane would contain less light."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:206
msgid "The appearance of interference"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:208
msgid "{numref}`fig-psf_planes` is quite limited in what it shows: it doesn't begin to explain the extra patterns of the PSF, which appear on each 2D plane as concentric rings (see {numref}`fig-bead_slices`) nor why the PSF doesn't shrink to a single point in the focal plane. These factors relate to the interference of light waves. While it's important to know that the rings occur -- if only to avoid ever misinterpreting them as extra ring-like structures being really present in a sample -- they have limited influence upon any analysis because the central region of the PSF is overwhelmingly brighter. Therefore for our purposes they can mostly be disregarded."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:228
msgid "Ten slices from a z-stack acquired of a fluorescent bead, starting from above and moving down to the focal plane. The same linear contrast settings have been applied to each slice for easy comparison, although this causes the in-focus bead to appear saturated since otherwise the rings would not be visible at all. Because the image is (approximately) symmetrical along the z-axis, additional slices moving below the focal plane would appear similar."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:232
msgid "The Airy disk"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:234
msgid "Finally for this section, the PSF in the focal plane is important enough to deserve some attention, since we tend to want to measure things where they are most in-focus. This entire *xy* plane, including its interfering ripples, is called an **Airy pattern**, while the bright central part alone is the **Airy disk** ({numref}`fig-airy`). In the best possible case, when all the light in a 2D image comes from in-focus structures, what we can image would already have been blurred by a filter that looks like this."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:283
msgid "George Biddell Airy and the Airy pattern. (A) During his schooldays, Airy had been renowned for being skilled _'in the construction of peashooters and other such devices'_ (see <https://mathshistory.st-andrews.ac.uk/Biographies/Airy/>). The rings surrounding the Airy disk have been likened to the ripples on a pond. Although the rings phenomenon was already known, Airy wrote the first theoretical treatment of it in 1835 (<https://en.wikipedia.org/wiki/Airy_disk>). (B) An Airy pattern looks much like a 2D Gaussian function, although when the contrast is enhanced (C) small outer rings can be seen surrounding the Airy disk."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:290
msgid "The Airy disk should look familiar. If we ignore the little interfering ripples around its edges, it can be very well approximated by a Gaussian function ({numref}`fig-psf_surface`). Therefore _the blur of a microscope in 2D is similar to applying a Gaussian filter_, at least in the focal plane."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:347
msgid "Comparison of an Airy disk and a Gaussian of a similar size, using two wireframe plots and a correspnding 1D cross-section. The Gaussian is a *very* close match to the Airy disk, apart from the faint ripples at the sides, so we can often approximate the blur of a PSF using a Gaussian filter."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:353
msgid "The size of the PSF"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:355
msgid "So much for appearances. To judge how the blurring will affect what we can see and measure, we need to know the _size_ of the PSF. Because we don't tend to want our images to be blurry, smaller would be preferable."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:359
msgid "The size requires some defining: the PSF actually continues indefinitely, but has extremely low intensity values when far from its center. One approach for characterizing the Airy disk size is to consider its radius $r_{airy}$ as the distance from the center to the first _minimum_: the lowest point before the first of the outer ripples begins. This is is given by:"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:363
msgid "r_{airy} = \\frac{0.61 \\lambda}{\\textrm{NA}}"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:368
msgid "where $\\lambda$ is the light wavelength and NA is the numerical aperture of the objective lens [^fn_1]."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:373
msgid "A comparable measurement to $r_{airy}$ between the center and first minimum along the *z* axis is:"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:375
msgid "z_{min} = \\frac{2 \\lambda \\times \\eta}{\\textrm{NA}^2}"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:380
msgid "where $\\eta$ is the refractive index of the objective lens immersion medium (which is a value related to the speed of light through that medium)."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:382
msgid "The practical importance of these equations is that they reveal the key factors that influence how blurry an image will be. This hints at some ways we might be able to reduce blurring at the acquisition stage."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:390
msgid "According to Equation {eq}`eqn-res_lateral`, the equation for the Airy disk size, what are the two variables we _may_ be able to control that influence the amount of blur in our images? And how must they be changed (increased or decreased) for the images to have less blur?"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:396
msgid "If the wavelength $\\lambda$ is _lower_ or the objective NA is _higher_, $r_{airy}$ decreases and we have less blur."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:408
msgid "Does the NA have more influence on blur in the *xy* plane, or along the *z* axis?"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:414
msgid "Because of the squaring, the NA has a much greater influence on blur along the *z* axis than in *xy*. This can be seen clearly in {numref}`fig-psf_na`."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:439
msgid "Examples of theoretical PSFs generated with different Numerical Apertures."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:448
msgid "Numerical Aperture"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:450
msgid "The equations for the PSF size show that if you can use an objective lens with a higher NA, you can potentially reduce blur in an image -- especially along the *z* axis ({numref}`fig-psf_na`). Unfortunately, one soon reaches another limit in terms of what increasing the NA can achieve. This can be seen from the equation used to define it:"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:453
msgid "\\textrm{NA} = \\eta \\sin{\\theta}"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:457
msgid "where $\\eta$ is again the refractive index of the immersion medium and $\\theta$ is the half-angle of the cone of light accepted by the objective. Because $\\sin{\\theta}$ can never exceed 1, the NA can never exceed $\\eta$, which itself has fixed values (e.g. around 1.0 for air, 1.34 for water, or 1.5 for oil). High NA lenses can therefore reduce blur only to a limited degree."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:462
msgid "An important additional consideration is that the highest NAs are possible when the immersion refractive index is high, but if this does not match the refractive index of the medium surrounding the sample we get **spherical aberration**. This is a phenomenon whereby the PSF becomes asymmetrical at increasing depth and the blur becomes weirder. Therefore, matching the refractive indices of the immersion and embedding media is often _strongly_ preferable to using the highest NA objective available: it's usually better to have a larger PSF than a highly irregular one."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:466
msgid "For an interactive tutorial on the effect of using different NAs, see <https://www.microscopyu.com/tutorials/imageformation-airyna>."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:475
msgid "Convince yourself that $z_{min}$ will be considerably higher than $r_{airy}$ using one of the following methods:"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:478
msgid "Put an example refractive index (e.g. $\\eta = 1.34$ for water), and some reasonable values of $\\lambda$ and the NA into the equations for the lateral {eq}`eqn-res_lateral` and axial {eq}`eqn-res_axial` resolution, and compare the results"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:479
msgid "Calculate the ratio $z_{min} / r_{airy}$ and substitute in the equation for the NA. This should reveal that the ratio is bigger than 1, i.e. that $z_{min}$ is larger."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:482
msgid "What is the main implication of this observation, in terms of how separated structures need to be along different dimensions for them still to be distinguishable?"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:489
msgid "The ratio is"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:491
msgid "\\frac{z_{min}}{r_{airy}} = \\frac{2 \\lambda \\times \\eta}{\\textrm{NA}^2} \\times \\frac{\\textrm{NA}}{0.61 \\lambda} = \\frac{3.28\\eta}{\\textrm{NA}} = \\frac{3.28}{\\sin\\theta}"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:495
msgid "Therefore, even as $\\sin\\theta$ becomes close to 1 (i.e. a very high NA objective is used), the value of $z_{min}$ remains over 3 times larger than $r_{airy}$ -- the *z* resolution is much worse. When the NA is lower, the difference is even more."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:499
msgid "The main practical implication is that it's more likely that you will be able to distinguish structures that are separated from one another by a short distance in *xy* than similarly separated in *z*. If you really need information along the *z*-dimension more than anywhere else, maybe rotating your sample could help?"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:507
msgid "Spatial resolution"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:509
msgid "**Spatial resolution** is concerned with how close two structures can be while they are still distinguishable. This is a somewhat subjective and fuzzy idea, but one way to define it is by the **Rayleigh Criterion**, according to which two equally bright spots are said to be resolved (i.e. distinguishable) if they are separated by the distances calculated in the lateral {eq}`eqn-res_lateral` and axial {eq}`eqn-res_axial` equations above. If the spots are closer than this, they are likely to be seen as one. In the in-focus plane, this is illustrated in {numref}`fig-rayleigh`."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:577
msgid "Airy patterns separated by different distances, defined in terms of Airy disk radii. The top row contains the patterns themselves, while the bottom row shows intensity profiles computed across the centers of the patterns. Two distinct spots are clearly visible whenever separated by at least one disk radius, and there is a dip apparent in the profile. However, if the separation is less than one radius, the contrast rapidly decreases until only one structure is apparent. By a separation of 0.5 radii, the two structures appear indistinguishable as a single, brighter structure."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:581
msgid "It should be kept in mind that the use of $r_{airy}$ and $z_{min}$ in the Rayleigh criterion is somewhat arbitrary -- and the effects of brightness differences, finite pixel sizes and noise further complicate the situation, so that in practice a greater distance may well be required for us to confidently distinguish structures. Nevertheless, the Rayleigh criterion is helpful to give some idea of the scale of distances involved, i.e. hundreds of nanometers when using visible light."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:589
msgid "Suppose the diameter of the Airy disk is around 500 nm, and you are looking at an image containing separate, well-spaced structures that are 2 nm, 20 nm and 200 nm in size. Assuming that you have imaged all of these exactly in focus (after all, you are a brilliant microscopist), how will these structures appear in the image?"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:592
msgid "_Note:_ This is a particularly important question! Think of both the size and brightness."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:599
msgid "Because even an infinitesimally small point cannot appear smaller than the Airy disk in the recorded image, _potentially all 3 of these structures look the same!_ There may be _some_ increase in size visible with the 200 nm structure (because it is larger than a single point, this makes it like many different, slightly-shifted-but-mostly-overlapping Airy disks added together), but it will certainly not appear 10 or 100 times larger than the others."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:601
msgid "_However_, because smaller objects typically emit fewer photons, the smaller structures may well appear less bright -- if they are bright enough to be visible at all. Therefore, at this scale accurate measurements of size are impossible from (conventional, non-super-resolution) fluorescence microscopy images, but the actual size may have some relationship with brightness."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:609
msgid "Measuring PSFs & small structures"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:611
msgid "Knowing that the Airy disk resembles a Gaussian function is extremely useful, because any time we see an Airy disk we can fit a 2D Gaussian to it. The parameters of the function will then tell us the Gaussian's center exactly, which corresponds to where the fluorescing structure really is -- admittedly not with complete accuracy, but potentially still beyond the accuracy of even the pixel size (noise is the real limitation). This idea is fundamental to single-molecule localization techniques, including those in super-resolution microscopes like STORM and PALM, but requires that PSFs are sufficiently well-spaced that they do not interfere with one another and thereby ruin the fitting."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:615
msgid "In ImageJ, we can somewhat approximate this localization by drawing a line profile across the peak of a PSF and then running {menuselection}`Analyze --> Tools --> Curve Fitting...`. There we can fit a 1D Gaussian function, for which the equation used is"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:618
msgid "y = a + (b-a)e^{\\frac{-(x-c)^2)}{2d^2}}"
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:622
msgid "$a$ is simply a background constant, $b$ tells you the peak amplitude (i.e. the maximum value of the Gaussian with the background subtracted), and $c$ gives the location of the peak along the profile line. But potentially the most useful parameter here is $d$, which corresponds to the $\\sigma$ value of a Gaussian filter. So if you know this value for a PSF, you can approximate the same amount of blurring with a Gaussian filter. This may come in useful in {ref}`chap_macro_simulating`."
msgstr ""

#: ../../chapters/3-fluorescence/2-formation_spatial/formation_spatial.md:370
msgid "Note that this is the _limit_ of the Airy disk size, and assumes that the system is free of any aberrations. In other words, this is the best that we can hope for: the Airy disk cannot be made smaller simply by better focusing, although it could easily be made worse by a less-than-perfect objective lens"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:16
msgid "Noise"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:21
msgid "There are two main types of noise in fluorescence microscopy: **photon noise & read noise**"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:22
msgid "**Photon noise** is _signal-dependent_, varying throughout an image"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:23
msgid "**Read noise** is _signal-independent_, and depends upon the detector"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:24
msgid "**Detecting more photons** reduces the impact of both noise types"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:45
msgid "We could reasonably expect that a noise-free microscopy image should look pleasantly smooth, not least because the convolution with the PSF has a blurring effect that softens any sharp transitions. Yet in practice raw fluorescence microscopy images are not smooth. They are always, to a greater or lesser extent, corrupted by noise. This appears as a random 'graininess' throughout the image, which is often strong enough to obscure details."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:50
msgid "This chapter considers the nature of the noisiness, where it comes from, and what can be done about it. Before starting, it may be helpful to know the one major lesson of this chapter for the working microscopist is simply:"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:54
msgid "**If you want to reduce noise, you need to detect more photons**"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:57
msgid "This general guidance applies in the overwhelming majority of cases when a good quality microscope is functioning properly. Nevertheless, it may be helpful to know a bit more detail about why -- and what you might do if detecting more photons is not feasible."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:63
msgid "Background"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:122
msgid "Illustration of the difference between a noisy image that we can record (A), and the noise-free image we would prefer (B). The 'noise' itself is what would be left over if we subtracted one from the other \\(C). The histogram in (D) resembles a normal (i.e. Gaussian) distribution and shows that the noise consists of positive and negative values, with a mean of 0."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:126
msgid "In general, we can assume that noise in fluorescence microscopy images has the following three characteristics, illustrated in {numref}`fig-noise_demo`:"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:129
msgid "**Noise is random** -- For any pixel, the noise is a random positive or negative number added to the 'true value' the pixel should have."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:130
msgid "**Noise is independent at each pixel** -- The value of the noise at any pixel does not depend upon where the pixel is, or what the noise is at any other pixel."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:131
msgid "**Noise follows a particular distribution** -- Each noise value can be seen as a _random variable_ drawn from a particular distribution. If we have enough noise values, their histogram would resemble a plot of the distribution [^fn_1]."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:136
msgid "There are many different possible noise distributions, but we only need to consider the **Poisson** and **Gaussian** cases. No matter which of these we have, the most interesting distribution parameter for us is the **standard deviation**. Assuming everything else stays the same, if the standard deviation of the noise is higher then the image looks worse ({numref}`fig-gaussian_hists`)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:181
msgid "Gaussian noise with different standard deviations added to an image. Noise with a higher standard deviation has a worse effect when added to an image. Its impact can be seen in the histogram, as the distribution of foreground and background pixels overlap more -- which is problematic for things like [thresholding](chap_thresholding)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:184
msgid "The reason we will consider two distributions is that there are two main types of noise for us to worry about:"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:187
msgid "**Photon noise**, from the emission (and detection) of the light itself. This follows a Poisson distribution, for which _the standard deviation changes with the local image brightness_."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:189
msgid "**Read noise**, arising from inaccuracies in quantifying numbers of detected photons. This follows a Gaussian distribution, for which _the standard deviation stays the same throughout the image_."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:192
msgid "Therefore the noise in the image is really the result of adding two [^fn_2] separate random components together. In other words, to get the value of any pixel $P$ you need to calculate the sum of the 'true' (noise-free) value $T$, a random photon noise value $N_p$, and a random read noise value $N_r$, i.e."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:201
msgid "P = T + N_p + N_r"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:205
msgid "In this case, we have $P$ in the image but we want $T$. Unfortunately, we don't know precisely what the random values $N_p$ and $N_r$ are."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:208
msgid "Finally, some useful maths:"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:209
msgid "Suppose we add two random noisy values together. Both are independent and drawn from distributions (Gaussian or Poisson) with standard deviations $\\sigma_1$ and $\\sigma_2$. The result is a third random value, drawn from a distribution with a standard deviation $\\sqrt{\\sigma_1^2 + \\sigma_2^2}$."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:211
msgid "If we multiply a noisy value from a distribution with a standard deviation $\\sigma_1$ by $k$, the result is noise from a distribution with a standard deviation $k\\sigma_1$."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:213
msgid "These are all my most important noise facts, upon which the rest of this chapter is built. We will begin with Gaussian noise because it's easier to work with, found in many applications, and widely studied in the image processing literature. However, in _most_ fluorescence images photon noise is the more important factor. Fortunately, there's a close relationship between the Gaussian and Poisson noise -- and it's even possible to convert the latter to behave like the former."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:218
msgid "Gaussian noise"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:220
msgid "Gaussian noise is a common problem in fluorescence images acquired using a CCD camera (see {ref}`chap_microscope_types`). It arises at the stage of quantifying the number of photons detected for each pixel. Quantifying photons is hard to do with complete precision, and the result is likely to be wrong by at least a few photons. This error is the read noise."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:224
msgid "Read noise typically follows a Gaussian distribution and has a mean of zero: this implies there is an equal likelihood of over or underestimating the number of photons. Furthermore, according to the properties of Gaussian distributions, we should expect around ~68% of measurements to be ±1 standard deviation from the true, read-noise-free value. If a detector has a low read noise standard deviation, this is then a good thing: it means the error should be small."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:228
msgid "Signal-to-Noise Ratio (SNR)"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:230
msgid "Read noise is said to be **signal independent**: its standard deviation is constant, and does not depend upon how many photons are being quantified. However, the extent to which read noise is a problem probably _does_ depend upon the number of photons. For example, if we have detected 20 photons, a noise standard deviation of 10 photons is huge; if we have detected 10 000 photons, it's likely not so important."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:234
msgid "A better way to assess the noisiness of an image is then the ratio of the interesting component of each pixel (called the **signal**, which is here what we would ideally detect in terms of photons) to the noise standard deviation, which is known as the __Signal-to-Noise Ratio__ [^fn_3]:"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:241
msgid "\\textrm{SNR} = \\frac{\\textrm{Signal}}{\\textrm{Noise standard deviation}}"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:252
msgid "Calculate the SNR in the following cases:"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:255
msgid "We detect an average of 10 photons, read noise standard deviation 1 photon"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:256
msgid "We detect an average of 100 photons, read noise standard deviation 10 photons"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:257
msgid "We detect an average of 1000 photons, read noise standard deviation 10 photons"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:259
msgid "For the purposes of this question, you should assume that read noise is the only noise present (ignore photon noise)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:266
msgid "We detect an average of 10 photons, read noise std. dev. 1 photon: _SNR = 10_"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:267
msgid "We detect an average of 100 photons, read noise std. dev. 10 photons: _SNR = 10_"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:268
msgid "We detect an average of 1000 photons, read noise std. dev. 10 photons: _SNR = 100_"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:270
msgid "The noise causes us a similar degree of uncertainty in the first two cases. In the third case, the noise is likely to be less problematic: higher SNRs are good."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:276
msgid "Exploring noise"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:279
msgid "I find the best way to learn about noise is by creating simulation images, and exploring their properties through making and testing predictions."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:281
msgid "The figures in this chapter are generated using such simulations in Python. If you want to do something similar in ImageJ, you can add Gaussian noise with a fixed standard deviation to any image using {menuselection}`Process --> Noise --> Add Specified Noise...`."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:284
msgid "If needed, you can create an empty 32-bit image with {menuselection}`File --> New --> Image...` add noise to get an image containing nothing but noise."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:289
msgid "Adding & averaging noisy images"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:291
msgid "{ref}`At the beginning of this chapter<sec_noise_background>`, I stated how to calculate the new standard deviation of the noise whenever two noisy pixels are added together:"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:293
msgid "Square the original noise standard deviation to get the variance for each pixel"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:294
msgid "Add the variances"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:297
msgid "Suppose that we have two (independent) images with the same Gaussian noise standard deviation, let's say 5. Applying this calculation, if we add the images together then the noise standard deviation of the resulting image is"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:300
msgid "\n"
"\\sqrt{5^2 + 5^2} = \\sqrt{50} \\approx 7.07\n"
""
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:304
msgid "The noise standard deviation of the resulting image is higher."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:306
msgid "We might expect that the sum of two noisy image is therefore *worse*: we have increased the noise. *However*, we need to remember that the signal is also higher: in fact, it has been doubled (because we added two similar images)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:309
msgid "If we want an output image with similar signal to the originals, we should *average* the corresponding pixel values instead of adding. In this case, averaging is the same as adding, except that we divide by two. When we do this, the noise standard deviation is also halved and becomes approximately 3.54 -- i.e. it is *lower* than in either of the original two images."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:313
msgid "This matters, because it implies that if we were to average two independent noisy images of the same scene with similar SNRs, we would get a result that contains _less_ noise, i.e. a higher SNR."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:315
msgid "But you shouldn't just take my word for it. We can check that it really works by using a simulation. {numref}`fig-fig_noise_sum` demonstrates this, and has a very practical implication: noise reduction by averaging images creates a better peak separation in the histogram. This means it should usually give us an image that is more amenable to thresholding."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:362
msgid "Adding and averaging two independent images with Gaussian noise. Both adding and averaging give an image with an improved SNR, as can be seen in the improved separation between the histogram peaks."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:366
msgid "Adding & averaging within an image"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:368
msgid "All this means that *if* can acquire the same image multiple times, then averaging our different images would give a result with reduced noise."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:370
msgid "Of course, we don't usually have multiple independent images of everything we might want to analyze. Instead, we just have one image. However, we can explore the idea by splitting a single image into two -- provided we are willing to sacrifice some spatial resolution."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:374
msgid "If we take the pixels from every second column of the image, we can extract these and combine them to form another image that looks like a squished version of the original. We can do the same process for all the columns we skipped -- thereby giving us two squished images, one from the even-numbered columns and one from the odd-numbered columns."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:377
msgid "You can see in Figure {numref}`fig-fig_noise_split` that our squished images do look almost identical, because adjacent pixels usually do have very similar values -- apart from the differences caused by noise. If we average these images together, these differences average out and we have another similar-looking image -- but with reduced noise."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:429
msgid "Creating two images from one by taking even and odd-numbered columns. If we then average our two images, noise is reduced. The difference is subtle, but can be seen in the better separation of the peaks in the histogram."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:432
msgid "Of course, this trick has an obvious downside: the squishing is undesirable. Fortunately, we can avoid it simply by averaging adjacent columns but not splitting them into separate image. Then we can do the same with adjacent rows. And perhaps even adjacent diagonals, if we wish."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:437
msgid "This is *precisely* the idea underlying our use of a [3×3 mean filter to reduce noise](chap_filters): we don't have independent images to average, so we average within an image instead ({numref}`fig-noise_filt_averaging`)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:519
msgid "Noise reduction by averaging adjacent pixels. Even though the overall appearance of the image has not changed much, the histograms indicate a much bigger separation of the foreground and background -- meaning that thresholds are more likely to work well. In (C), the result is equivalent to applying a 3×3 mean filter."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:522
msgid "Hopefully this discussion helps build your intuition as to *why* filters are able to reduce Gaussian noise. In the next section, we'll see how many of the same ideas apply to Poisson noise as well."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:526
msgid "Poisson noise"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:528
msgid "In 1898, Ladislaus Bortkiewicz published a book entitled _The Law of Small Numbers_. Among other things, it included a now-famous analysis of the number of soldiers in different corps of the Prussian cavalry who were killed by being kicked by a horse, measured over a 20-year period. Specifically, he showed that these numbers follows a **Poisson distribution**."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:531
msgid "This distribution, introduced by Siméon Denis Poisson in 1838, gives the probability of an event happening a certain number of times, given that we know (1) the average rate at which it occurs, and (2) that all of its occurrences are independent. However, the usefulness of the Poisson distribution extends far beyond gruesome military analysis to many, quite different applications -- including the probability of photon emission, which is itself inherently random."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:571
msgid "Siméon Denis Poisson and his distribution. (A) Poisson is said to have been extremely clumsy and uncoordinated with his hands. This contributed to him giving up an apprenticeship as a surgeon and entering mathematics, where the problem was less debilitating -- although apparently this meant his diagrams tended not to very well drawn (see https://mathshistory.st-andrews.ac.uk/Biographies/Poisson/). (B) The 'Probability Mass Function' of the Poisson distribution for several different values of λ. This allows one to see for any 'true signal' λ the probability of actually counting any actual value k. Although it's more likely that one will count exactly k = λ than any other possible k, as λ increases the probability of getting precisely this value becomes smaller and smaller."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:575
msgid "Suppose that, on average, a single photon will be emitted from some part of a fluorescing sample within a particular time interval. The randomness entails that we cannot say for sure what will happen on any one occasion when we look; sometimes one photon will be emitted, sometimes none, sometimes two, occasionally even more. What we are really interested in, therefore, is not precisely _how many_ photons are emitted, which varies every time we look, but rather the _rate_ at which they would be emitted under fixed conditions, which is a constant. The difference between the number of photons actually emitted and the true rate of emission is the **photon noise**. The trouble is that keeping the conditions fixed might not be possible: leaving us with the problem of trying to figure out rates from single, noisy measurements."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:581
msgid "Signal-dependent noise"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:583
msgid "Clearly, since it's a rate that we want, we could get that with more accuracy if we averaged many observations: just like with Gaussian noise, averaging reduces photon noise. Therefore, we can expect smoothing filters to work similarly for both noise types -- and they do."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:586
msgid "The primary distinction between the noise types, however, is that Poisson noise is **signal-dependent**, and _does_ change according to the number of emitted (or detected) photons. Fortunately, the relationship is simple: if the rate of photon emission is $\\lambda$, the noise variance is also $\\lambda$, and the noise standard deviation is $\\sqrt{\\lambda}$."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:589
msgid "This is not really as unexpected as it might first seem (see {numref}`fig-fishing`). It can even be observed from a very close inspection of {numref}`fig-noise_neuron`, in which the increased variability in the neuron causes its ghostly appearance even in an image that ought to consist (almost) exclusively of noise."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:598
msgid "__'The standard deviation of photon noise is equal to the square root of the expected value.'__ To understand this better, it may help to imagine a fisherman, fishing many times at the same location and under the same conditions. If he catches 10 fish on average, it would be quite reasonable to catch 7 or 13 on any one day -- while 20 would be exceptional. If, however, he caught 100 on average, then it would be unexceptional if he caught 90 or 110 on a particular day, although catching only 10 would be strange (and presumably disappointing). Intuitively, the range of values that would be considered likely is related to the expected value. If nothing else, this imperfect analogy may at least help remember the name of the distribution that photon noise follows."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:625
msgid "A demonstration that Poisson noise changes throughout an image. (A) Part of a fluorescence microscopy image. (B) A Gaussian filtered version of (A) using a very small filter ($\\sigma$=0.25). Gaussian filtering reduces the noise in an image by replacing each pixel with a weighted average of neighboring pixels (see {ref}`chap_filters`). \\(C) The difference between the original and filtered image contains the noise that the filtering removed. The brighter areas in the original image are still visible in this 'noise image' as regions of increased variability. This is partly an effect of Poisson noise having made the noise standard deviation larger in the brighter parts of the acquired image."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:635
msgid "The formula for the probability mass function of the Poisson distribution is:"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:637
msgid "\\mathcal{P}(\\lambda) \\sim \\frac{e^{-\\lambda}\\lambda^{k}}{k!}"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:642
msgid "where"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:645
msgid "$\\lambda$ is the mean rate of occurrence of the event (i.e. the noise-free photon emission rate we want)"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:647
msgid "$k$ is an actual number of occurrences for which we want to compute the probability"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:648
msgid "$k!$ is the _factorial_ of $k$ (i.e. $k \\times (k-1) \\times (k-2) \\times ... \\times 1$)"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:650
msgid "So if you know that the rate of photon emission is 0.5, for example, you can put $\\lambda = 0.5$ into the equation and determine the probability of getting any particular (integer) value of $k$ photons. Applying this, the probability of not detecting any photons ($k = 0$) is 0.6065, while the probability of detecting a single photon ($k = 1$) is $0.3033$."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:653
msgid "What we know for sure is that we can't possibly detect 0.5 photons: we'll get an integer value, not 'part of a photon'."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:655
msgid "Assuming the mean rate of photon emission is 1, use Equation {eq}`eqn-poisson` to calculate the probability of actually detecting 5 (which, at 5 times the true rate, would be an extremely inaccurate result). How common do you suppose it is to find pixels that are so noisy in the background region of a dark image?"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:662
msgid "The probability of detecting 5 photons is approximately 0.0031."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:664
msgid "\\frac{e^{-1}}{5!} = \\frac{1}{120e} = 0.0031"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:668
msgid "Although this is a very low probability, images contain so many pixels that one should expect to see such noisy values often. For example, in a rather dark and dull 512×512 pixel image in which the average photon emission rate is 1, we would expect 800 pixels to have a value of 5 -- and two pixels even to have a value of 8. The presence of isolated bright or dark pixels therefore usually tells us very little indeed, and it is only by processing the image more carefully and looking at surrounding values that we can (sometimes) discount the possibility these are simply the result of noise."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:677
msgid "The SNR for Poisson noise"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:679
msgid "If the standard deviation of noise was the only thing that mattered, this would suggest that we are better not detecting much light: then the photon noise standard deviation is lower. But the SNR is a much more reliable guide. For noise that follows a Poisson distribution this is particularly easy to calculate. Substituting into the formula for the SNR (Equation {eq}`eqn-snr`):"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:684
msgid "\\textrm{SNR}_{Poiss} = \\frac{\\lambda}{\\sqrt{\\lambda}} = \\sqrt{\\lambda}"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:688
msgid "Therefore **the SNR of photon noise is equal to the square root of the signal**!"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:690
msgid "This means that as the average number of emitted (and thus detected) photons increases, so too does the SNR. More photons &rarr; a better SNR, directly leading to the assertion"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:693
msgid "If you want to reduce photon noise, you need to detect more photons"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:696
msgid "We can visualize this using a simulation that displays how an image and its histogram change over time as more photons are detected."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:702
msgid "This is really just the same as the insight that averaging reduces noise. Averaging and summing have the same effect, differing only by a constant scale factor."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:732
msgid "Why relativity matters: a simple example"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:736
msgid "The SNR increases with the number of photons, even though the noise standard deviation increases too, because it's really _relative_ differences in the brightness in parts of the image that we are interested in. Absolute numbers usually are of very little importance -- which is fortunate, since not all photons are detected."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:739
msgid "Yet if you remain unconvinced that the noise standard deviation can get bigger while the situation gets better, the following specific example might help. Suppose the true signal for a pixel is 4 photons. Assuming the actual measured value is within one noise standard deviation of the proper result (which it will be, about 68% of the time), one expects it to be in the range 2–6. The true signal at another pixel is twice as strong -- 8 photons -- and, by the same argument, one expects to measure a value in the range 5–11. _The ranges for both pixels overlap!_ With photon counts this low, even if one pixel has twice the value of another, we often cannot discern with confidence that the *true*, noise-free value for both pixels would be different at all."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:745
msgid "On the other hand, suppose the true signal for the first pixel is 100 photons, so we measure something in the range of 90–110. The second pixel, still twice as bright, gives a measurement in the range 186–214. These ranges are larger, but crucially they are not even close to overlapping, so it's very easy to tell the pixels apart. Thus the noise standard deviation alone is not a very good measure of how noisy an image is. The SNR is much more informative: the simple rule is that higher is better. Or, if that still does not feel right, you can turn it upside down and consider the noise-to-signal ratio (the _relative noise_), in which case lower is better ({numref}`fig-snr_plot`)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:756
msgid "For Poisson noise, the standard deviation increases with the square root of the signal. So does the SNR, with the result that plots (A) and (B) look identical. This improvement in SNR despite the growing noise occurs because the signal is increasing faster than the noise, and so the noise is relatively smaller. Plotting the relative noise (1/SNR) shows this effect \\(C)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:760
msgid "Poisson noise & detection"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:762
msgid "So why should you care that photon noise is signal-dependent?"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:764
msgid "One reason is that it can make features of identical sizes and brightnesses easier or harder to detect in an image purely because of the local background. This is illustrated in {numref}`fig-poisson_ramp`."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:831
msgid "The signal-dependence of Poisson noise affects how visible (and therefore detectable) structures are in an image. (A) Nine spots of the same _absolute_ brightness are added to an image with a linearly increasing background _(top)_ and Poisson noise is added _(bottom)_. Because the noise variability becomes higher as the background increases, the spots in the darkest part of the image can be clearly seen in the profile but it's more difficult to discern spots in the brighter part. (B) Spots of the same brightness _relative_ to the background are added, along with Poisson noise. Because the noise is now relatively lower as the brightness increases, only the spots in the brightest part of the image can be seen, while those in the darker part are buried within the noise."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:835
msgid "In general, if we want to see a fluorescence increase of a fixed number of photons, this is easier to do if the background is very dark. But if the fluorescence increase is defined _relative_ to the background, it will be much easier to identify if the background is high. Either way, when attempting to determine the number of any small structures in an image, for example, we need to remember that the numbers we will be able to detect will be affected by the background nearby. Therefore results obtained from bright and dark regions might not be directly comparable."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:846
msgid "Open the images *mystery_noise_1.tif* and *mystery_noise_2.tif* in ImageJ."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:848
msgid "Both are noisy, but in one the noise follows a Gaussian distribution (like read noise) and in the other it follows a Poisson distribution (like photon noise). Which is which?"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:851
msgid "[![launch ImageJ.JS](https://ij.imjoy.io/assets/badge/launch-imagej-js-badge.svg)](https://ij.imjoy.io?open=https://github.com/bioimagebook/practical-data/blob/main/images/mystery_noise_1.tif&open=https://github.com/bioimagebook/practical-data/blob/main/images/mystery_noise_2.tif)"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:857
msgid "The noise in *mystery_noise_1.tif* is Gaussian; the noise in *mystery_noise_2.tif* follows a Poisson distribution. Since there are reasonably flat regions within the cell and background, I would test this by drawing a ROI within each and measuring the standard deviations. Where these are similar, the noise is Gaussian; if there is a big difference, the noise is likely to be Poisson."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:861
msgid "If no flat regions were available, I would try applying a gradient filter with the coefficients `-1 1 0`, and inspecting the results. Alternatively, I might try plotting a fluorescence profile or subtracting a very slightly smoothed version of each image."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:868
msgid "Combining noise sources"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:870
msgid "Combining our noise sources then, we can imagine an actual pixel value as being the sum of three values: the true rate of photon emission, the photon noise component, and the read noise component [^fn_5]. The first of these is what we want, while the latter two are random numbers that may be positive or negative."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:906
msgid "An illustration of how photon noise differs from read noise. When both are added to a signal (here, a series of steps in which the value doubles at each higher step), the relative importance of each depends upon the value of the signal. At low signal levels this doubling is very difficult to discern amidst either type of noise, and even more so when both noise components are present."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:910
msgid "This is illustrated in {numref}`fig-noise_steps` using a simple 1D signal consisting of a series of steps. Random values are added to this to simulate photon and read noise. Whenever the signal is very low (indicating few photons), the variability in the photon noise is very low -- but high _relative_ to the signal (B)! This variability increases when the signal increases. However, in the read noise case \\(C), the variability is similar everywhere. When both noise types are combined in (D), the read noise dominates completely when there are few photons, but has very little impact whenever the signal increases. Photon noise has already made detecting relative differences in brightness difficult when there are few photons; with read noise, it can become hopeless."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:918
msgid "Therefore overcoming read noise is critical for low-light imaging, and the choice of detector is extremely important (see {ref}`chap_microscope_types`). But, where possible, detecting more photons is an _extremely_ good thing anyway, since it helps to overcome _both_ types of noise."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:922
msgid "Other noise sources"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:925
msgid "Photon and read noise are the main sources of noise that need to be considered when designing and carrying out an experiment. One other source often mentioned in the literature is _dark noise_, which can be thought of as arising when a wayward electron causes the detector to register a photon even when there was not actually one there. In very low-light images, this lead to spurious bright pixels. However, dark noise is less likely to cause problems if many true photons are detected, and many detectors reduce its occurrence by cooling the sensor."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:930
msgid "If the equipment is functioning properly, other noise sources could probably not be distinguished from these three. Nevertheless, brave souls who wish to know more may find a concise, highly informative, list of more than 40 sources of imprecision in _The 39 steps: a cautionary tale of quantitative 3-D fluorescence microscopy_ by James Pawley (available online from various sources)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:939
msgid "Suppose you have an image that does not contain much light, but has some isolated bright pixels."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:941
msgid "Which kind of filter could you use to remove them? And is it safe to assume they are due to dark noise or something similar, or might the pixels correspond to actual bright structures?"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:948
msgid "A median filter is a popular choice for removing isolated bright pixels, although when using ImageJ I sometimes prefer {menuselection}`Process --> Noise --> Remove Outliers...` because this only puts the median-filtered output in the image if the original value was really extreme (according to some user-defined threshold). This then preserves the independence of the noise at all other pixels -- so it still behaves reliably and predictably like Poisson + Gaussian noise. We can reduce the remaining noise with a Gaussian filter if necessary."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:952
msgid "Assuming that the size of a pixel is smaller than the PSF (which is usually the case in microscopy), it's a good idea to remove these outliers. They _cannot_ be real structures, because any real structure would have to extend over a region at least as large as the PSF. However if the pixel size is very large, then we may not be able to rule out that the 'outliers' are caused by some real, bright structures."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:961
msgid "Finding photons"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:963
msgid "There are various places from which the extra photons required to overcome noise might come. One is to simply acquire images more slowly, spending more time detecting light. If this is too harsh on the sample, it may be possible to record multiple images quickly. If there is little movement between exposures, these images could be added or averaged to get a similar effect ({numref}`fig-noise_averaging`)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:999
msgid "The effect of adding (or averaging) multiple noisy images, each independent with a similar SNR."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:1002
msgid "An alternative would be to increase the pixel size, so that each pixel incorporates photons from larger regions -- although clearly this comes at a cost in spatial information. One way to do this is though [binning](sec_detectors_binning)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:1005
msgid "However, noise cannot be completely eliminated during acquisition. Understanding its behavior, and especially how [filters](chap_filters) can reduce it, can help us cope with it during analysis."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:1040
msgid "Nyquist sampling & choosing a pixel size"
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:1042
msgid "Small pixels are needed to see detail, but also reduce the number of photons per pixel and thereby increase noise. However, {ref}`chap_formation_spatial` has already argued that ultimately it's not pixel size, but rather the PSF that limits spatial resolution -- which suggests that there is a minimum pixel size below which nothing is gained, and the only result is that more noise is added."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:1045
msgid "This size can be determined based upon knowledge of the PSF and the **Nyquist-Shannon sampling theorem** ({numref}`fig-nyquist_shannon`). Images acquired with this pixel size are said to be **Nyquist sampled** (although see Alvy Ray Smith's epic *A Biography of the Pixel* for the case why credit for the sampling theorem really belongs to **Vladimir Kotelnikov**)."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:1048
msgid "The easiest way I know to determine the corresponding pixel size for a given experiment is to use the online calculator provided by *Scientific Volume Imaging* at https://svi.nl/NyquistCalculator. You may need larger pixels to reduce noise or see a wider field of view, but you do not get anything extra by using smaller pixels."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:1056
msgid "Harry Nyquist (1889-1975) and Claude Shannon (1916-2001), sampled using different pixel sizes. Their work is used when determining the pixel sizes needed to maximize the available information when acquiring images, which depends upon the size of the PSF."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:134
msgid "Specifically its probability density or mass function -- which for a Gaussian distribution is the familiar bell curve."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:196
msgid "Actually more. But the two mentioned here are usually by far the most significant, and it does not matter to our model at all if they contain various other sub-components. The important fact remains that there is some noise that varies throughout the image, and some that does not."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:236
msgid "This is one definition of SNR. Many other definitions appear in the literature, leading to different values. The fact that any interesting image will vary in brightness in different places means that the SNR is not necessarily the same at all pixels -- therefore computing it in practice involves coming up with some summary measurement for the whole image. This can be approached differently, but the general principle is always to compare how much noise we have relative to interesting things: where higher is better."
msgstr ""

#: ../../chapters/3-fluorescence/3-formation_noise/formation_noise.md:873
msgid "For a fuller picture, gain and offset also need to be taken into consideration, see {ref}`chap_microscope_types`."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:16
msgid "Microscopes & detectors"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:21
msgid "The **choice of microscope** influences the **blur**, **noise** & **temporal resolution** of images"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:22
msgid "An **ideal detector** would have a high **Quantum Efficiency** & **low read noise**"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:43
msgid "Successfully analyzing an image requires that it actually contains the necessary information in the first place. There are various practical issues related to the biology (e.g. not interfering too much with processes, for example by inadvertently killing things) and data handling (bit-depths, file formats, anything else in Part I of this book). However, assuming that these are in order, there are three other main factors to consider connected to the image contents:"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:47
msgid "**Spatial information**, dependent on the size and shape of the PSF,"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:48
msgid "**Noise**, dependent on the number of photons detected,"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:49
msgid "**Temporal resolution**, dependent on the speed at which the microscope can record images."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:51
msgid "No one type of microscope is currently able to optimize all of these simultaneously, and so decisions and compromises need to be made. Temporal resolution and noise have an obvious relationship: a high temporal resolution means that less time is spent detecting photons in the image, leading to more photon noise. However, improving spatial information is also often related to one or both of the other two factors."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:55
msgid "This chapter gives a very brief overview of the main features of several fluorescence microscopes from the point of view of how they balance the tradeoffs mentioned."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:58
msgid "**This discussion does _not_ do justice to all the complexities, variations and features of the microscopes it describes!**"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:60
msgid "I'm by no means an expert in microscopy: I just analyze the data. But this chapter tries to distil the main things I learned that are relevant for analysis while working in an imaging center. It's a bit dated, but I've kept it anyway in case it might be useful to someone as a starting point."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:64
msgid "For a more extensive, and authoritative, description of the topics considered here, consider seeking out the _Handbook of Biological Confocal Microscopy_ edited by James Pawley. This contains many excellent chapters, some of which may be available to download from the publisher's website."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:69
msgid "Types of microscope"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:89
msgid "Schematic diagrams to show the differences in excitation patterns. Here, an inverted microscope is assumed (the cell is resting on a coverslip, and illuminated from below). During the recording of a pixel, light can potentially be detected if it arises from any part of the green-illuminated region, although in the laser scanning and spinning disk confocal cases the pinhole will only permit a fraction of this light to pass through. Note that, for the 2-photon microscope, the excitation is confined to only the small, central region, while the red light above and below is not capable of exciting the fluorophores that have been used."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:96
msgid "Widefield"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:98
msgid "So far, our schematic diagrams and PSF discussion have concentrated on **widefield microscopes**. In widefield microscopy, the entire sample is bathed in light, so that many fluorophores throughout the sample can be excited and emit photons simultaneously. All of the light that enters the objective may then be detected and contribute to any image being recorded. Because photons are potentially emitted from everywhere in the sample, there will be a lot of blur present for a thick specimen (for a thin specimen there is not much light from out-of-focus planes because the planes simply do not contain anything that can fluoresce)."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:103
msgid "What we get in any single recorded image is effectively the sum of the light from the in-focus plane, and every other out-of-focus plane. Viewed in terms of PSFs, we capture part of the hourglass shape produced by every light-emitting point depending upon how in-focus it is in every image."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:106
msgid "This is bad news for spatial information and also for detecting small structures in thick samples, because the out-of-focus light is essentially unhelpful background. On the other hand, widefield images tend to include a lot of photons, which overcomes read noise, even when they are recorded fast."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:109
msgid "Laser scanning confocal"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:111
msgid "**Optical sectioning** is the ability to detect photons only from the plane of focus, rejecting those from elsewhere. This is necessary to look into thick samples without getting lost in the haze of other planes. **Laser Scanning Confocal Microscopy (LSCM)** achieves this by only concentrating on detecting light for one pixel at any time, and using a pinhole to try to only allow light from a corresponding point in the sample to be detected."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:115
msgid "Because at most only one pixel is being recorded at any given moment, it does not make sense to illuminate the entire sample at once, which could do unnecessary damage. Rather, a laser illuminates only a small volume. If this would be made small enough, then a pinhole would not actually be needed because we would know that all emitted light _must_ be coming from the illuminated spot; however, the illumination itself is like an hour-glass PSF in the specimen. The pinhole is needed to make sure only the light from the central part reaches the detector. This then causes the final PSF, as it appears _in the image_, to take on more of a rugby-ball (or American football) appearance."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:121
msgid "The end result is an image that has relatively little out-of-focus light. Compared to widefield microscopy, LSCM provide a significant improvement in what can be seen along the *z*-dimension, although the *xy* resolution is not very different. Also, because single pixels are recorded separately, the image can (potentially) be more or less any size and shape -- rather than limited by the pixel count on a camera."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:125
msgid "However, these advantages comes with a major drawback. Images usually contain thousands to millions of pixels, and so only a tiny fraction of the time required to record an image is spent detecting photons for any one pixel in a LSCM image -- unlike in the widefield case, where photons can be detected for all pixels over the entire image acquisition time. This can cause LSCM image acquisition to be comparatively slow, noisy (in terms of few detected photons) or both. Spatial information is therefore gained at a cost in noise and/or temporal resolution."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:134
msgid "Why is it often recommended that the pinhole in LSCM be set to have the same size as one Airy disk? And why is it sometimes better not to strictly follow this recommendation?"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:140
msgid "As described in {ref}`chap_formation_spatial`, the vast majority of the light from the in-focus plane falls within the Airy disk. Using a pinhole smaller than this can result in so little light being detected that the image becomes too noisy to be useful. On the other hand, increasing the size of the pinhole will result in some more of the remaining light located in the outer rings of the Airy pattern, but _most_ extra photons will come from out-of-focus planes. This causes a reduction in the effectiveness of the optical sectioning. Therefore, a pinhole diameter of approximately 1 Airy disk provides a reasonable balance between detecting most of the in-focus light and achieving good optical sectioning."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:146
msgid "Nevertheless, sometimes a reduction in optical sectioning is a worthwhile cost -- such as when photons are very scarce, and some extra background is tolerable. Also, when recording a multichannel image then you may well have to set the pinhole size according to the Airy disk for one channel. But because the size of the disk depends upon the light wavelength (as described in Equation {eq}`eqn-res_lateral`), the pinhole diameter will differ in terms of Airy disk sizes for other channels."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:155
msgid "Spinning disk confocal"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:157
msgid "So a widefield system records all pixels at once without blocking the light from reaching the detector anywhere, whereas a LSCM can block out-of-focus light by only recording a single pixel at a time. Both options sound extreme: could there not be a compromise?"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:160
msgid "**Spinning disk confocal microscopy (SDCM)** implements one such compromise by using a large number of pinholes punched into a disk, so that the fluorophores can be excited and light detected for many different _non-adjacent_ pixels simultaneously. By not trying to record adjacent pixels at the same time, pinholes can be used to block _most_ of the out-of-focus light for each pixel, since this originates close to the region of interest for that pixel (i.e. the PSF becomes very dim at locations far away from its center) -- but sufficiently-spaced pixels can still be recorded simultaneously with little influence on one another."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:163
msgid "In practice, spinning disk confocal microscopy images are likely to be less sharp than laser scanning confocal images because some light does scatter through other pinholes. Also, the pinhole sizes cannot be adjusted to fine-tune the balance between noise and optical sectioning. However, the optical sectioning offered by SDCM is at least a considerable improvement over the widefield case, and an acceptable SNR can be achieved with much faster frame-rates using SDCM as opposed to LSCM."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:166
msgid "Multiphoton microscopy"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:168
msgid "As previously mentioned, if the size of excitation volume could be reduced enough, then we would know where the photons originated even without a pinhole being required -- but focused excitation is generally still subject to PSF-related issues, so that fluorophores throughout a whole hourglass-shaped volume can end up being excited. The main idea of **multiphoton microscopy** is that fluorophore excitation requires the _simultaneous absorption of multiple photons_, rather than only a single photon. The excitation light has a longer wavelength than would otherwise be required to cause molecular excitation with a single photon, but the energies of the multiple photons combine to cause the excitation."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:172
msgid "The benefit of this is that the multiphoton excitation only occurs at the focal region of the excitation -- elsewhere within the 'specimen PSF' the light intensities are insufficient to produce the 'multiphoton effect' and raise the fluorophores into an excited state. This means that the region of the specimen emitting photons at any one time is much smaller than when using single photon excitation (as in LSCM), and also less damage is being caused to the sample outside of the sample plane. Furthermore, multiphoton microscopy is able to penetrate deeper into a specimen -- up to several hundred µm."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:176
msgid "Total Internal Reflection Fluorescence"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:178
msgid "As previously mentioned, widefield images of very thin specimens do not suffer much from out-of-focus blur because light is not emitted from many other planes. **Total Internal Reflection Fluorescence (TIRF)** microscopy makes use of this by stimulating fluorescence only in a very thin section of the sample close to the objective. Very briefly, TIRF microscopy involves using an illumination angled so that the change in refractive index encountered by the light as it approaches the specimen causes a further change in angle sufficient to prevent the light from directly entering the specimen (i.e. it is 'totally internally reflected'). Nevertheless, fluorophores can still be excited by an evanescent wave that is produced when this occurs. This wave decays exponentially, so that only fluorophores right at the surface are excited -- meaning fluorophores deeper within the specimen do not interfere with the recording."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:184
msgid "Importantly, because the subsequent recording is essentially similar to that used when recording widefield images, photons are detected at all pixels in parallel and fast recording-rates are possible. Therefore if it's only necessary to see to a depth of about 100 nm, TIRF microscopy may be a good choice."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:187
msgid "Photon detectors"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:189
msgid "Certain detectors are associated with certain types of microscopy, and differ according to the level and type of noise you can expect. Understanding the basic principles greatly helps when choosing sensible values for parameters such as gain, pixel size and binning during acquisition to optimize the useful information in the image. The following provides a very brief introduction to two common detectors, and extra one variation."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:193
msgid "PMTs: one pixel at a time"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:195
msgid "If you only need to record one pixel at a time, a **photomultiplier tube (PMT)** might be what you need. The basic principle is this: a photon strikes a photocathode, hopefully producing an electron. When this occurs, the electron is accelerated towards a dynode, and any produced electrons accelerated towards further dynodes. By adjusting the 'gain', the acceleration of the electrons towards successive dynodes can be varied; higher accelerations mean there is an increased likelihood that the collision of the electrons with the dynode will produce a higher number of electrons moving into the next stage. The charge of the electrons is then quantified at the end ({numref}`fig-pmt`). Because the (possibly very small) number of original detected photons have now been amplified to a (possibly much) larger number electrons by the successive collisions with dynodes, the effect of read noise is usually minor for a PMT."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:208
msgid "Diagram showing the detection of a photon by a PMT. Each photon can be 'multiplied' to produce many electrons by accelerating the first produced electron towards a dynode, and repeating the process for all electrons produced along a succession of dynodes. The charge of the electrons reaching the end of the process can then be quantified, and ought to be proportional to the number of photons that arrived at the PMT."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:214
msgid "More problematically, PMTs can suffer from the problem of having a low **Quantum Efficiency (QE)**. The QE is a measure of the proportion of photons striking the detector which then produce electrons, and values for a conventional PMT may be as low as 10–15%: the majority of the photons reaching the PMT are simply wasted. Thus photon noise can be a major issue, especially if there is a low amount of light available to detect in the first place."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:219
msgid "Converting electrons to pixels"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:222
msgid "It's important to keep in mind that the final pixel values are not _equal_ to numbers of detected photons -- nor even numbers of counted electrons. They are rather proportional, often with an offset added."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:225
msgid "It's essential to estimate this offset (perhaps from a background region or an image acquired without using any excitation light) and subtract it if you need to compare pixel values in different images, in addition to using identical acquisition settings."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:228
msgid "CCDs: fast imaging when there are a lot of photons"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:230
msgid "A **Charged Coupled Device (CCD)** is a detector with a region devoted to sensing photons, and which is subdivided into different 'physical pixels' that correspond to pixels in the final image. Thus the image size cannot be changed arbitrarily, but it's possible to record photons for many pixels in parallel."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:233
msgid "When a photon strikes a pixel in the sensing part of the CCD, this often releases an electron -- the QE is typically high (perhaps 90%). After a certain exposure time, different 'electron clouds' have then formed at each physical pixel on the sensor, each of which has a charge related to the number of colliding photons. This charge is then measured by passing the electrons through a charge amplifier, and the results used to assign an intensity value to the pixel in the final image ({numref}`fig-ccd`)."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:253
msgid "An illustration of the basic operation of a CCD camera (using frame transfer). First, photons strike a sense register, which is divided into pixels. This causes small clouds of electrons to be released and gather behind the pixels (A). These are then rapidly shifted downwards into another register of the same size, thereby freeing the sense register to continue detecting photons (B). The electron clouds are then shifted downwards again, one row at a time, with each row finally being shifted sequentially through a charge amplifier \\(C). This quantifies the charge of the electron clouds, from which pixel values for the final image are determined."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:262
msgid "The electron clouds for each pixel might be larger than in the PMT case, both because of the higher QE and because more time can be spent detecting photons (since this is carried out for all pixels simultaneously). However, the step of amplifying the numbers of electrons safely above the read noise before quantification is missing. Consequently, read noise is potentially more problematic, and in some cases can even dominate the result."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:266
msgid "Pixel binning"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:268
msgid "One way to address the issue of CCD read noise is to use **pixel binning**. In this case, the electrons from 4 (i.e. 2×2) pixels of the CCD are added together before being quantified: the electron clouds are approximately 4 times bigger relative to the read noise ({numref}`fig-ccd_binning`), and readout can be faster because fewer electron clouds need to be quantified. The obvious disadvantage of this is that one cannot then put the electrons from the 4 pixels 'back where they belong'. As a result, the binned measurement is simply treated as a single (bigger) pixel. The recorded image contains 25% of the pixels in the unbinned image, while still covering the same field of view, so spatial information is lost. Larger bins may also be used, with a correspondingly more dramatic impact upon image size ({numref}`fig-ccd_binning`D)."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:327
msgid "Illustration of the effect of binning applied to an image suffering from photon and (severe) read noise. As the bin size increases, the photons from neighboring pixels are combined into a single (larger) pixel before the read noise is added. As a consequence, the image becomes brighter relative to the read noise -- but at a cost of spatial information."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:333
msgid "EMCCDs: fast imaging with low light levels"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:335
msgid "And so you might wonder whether it is possible to increase the electron clouds (like with the PMT) with an CCD, and so get its advantages without the major inconvenience of read noise. **Electron Multiplying CCDs (EMCCDs)** achieve this to some extent. Here, the electrons are first passed through an additional 'gain register' before quantification. At every stage of this gain register, each electron has a small probability -- perhaps only 1% -- of being amplified (through 'impact ionisation') and giving rise to two electrons entering the next stage. Despite the small probability, by incorporating > 500 such stages, the size of the electron cloud arising from even a single photon may be amplified safely above the read noise."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:341
msgid "However, the randomness of the amplification process itself introduces a new source of uncertainty, so that the final outcome can be thought of as having the same precision as if perhaps only around half as many photons were detected (see {ref}`chap_formation_noise` for the relationship between noise and the number of photons). Therefore read noise is effectively overcome at the cost of more photon noise."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:359
msgid "A simplified diagram comparing a conventional CCD (with and without binning) and an EMCCD. While each has the same physical number of pixels, when binning is used electrons from several pixels are combined before readout -- thereby making the 'logical' pixels in the final image bigger. For the EMCCD, the electrons are shifted through a 'gain register' prior to quantification. See {numref}`fig-ccd` for additional labels; the sense register has been omitted for simplicity."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:370
msgid "From a practical point of view, an EMCCD is rather like having a CCD with no read noise, but with half the QE. Under what circumstances (i.e. high or low numbers of photons) is an EMCCD preferable to a CCD?"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:377
msgid "The gain register of EMCCDs offers benefits primarily when few photons are available (i.e. when read-noise is the main problem, such as in SDCM). CCDs are preferable when many photons are available (e.g. in widefield)."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:380
msgid "If you are skeptical about this, consider an image in which your read noise standard deviation is 10 electrons and you detect on average 9 electrons (originally photons). The photon noise then has a standard deviation of 3. The read noise is much larger and will completely dominate the image: nothing interesting will be visible. It's then worth the cost of even more photon noise to be able to eliminate the read noise. The final image will still look pretty bad, but at least interpreting it is not hopeless."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:386
msgid "But suppose you happen to have 90000 detected photons instead, in which case the standard deviation of the photon noise is now 300. The read noise of 10 is comparatively insignificant, and there is nothing to gain from electron multiplication and making the photon noise situation worse."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:399
msgid "Based upon the above descriptions, which detectors seem most appropriate (generally!) for (a) widefield microscopy, (b) SDCM and (c) LSCM?"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:405
msgid "The following are reasonable rules of thumb:"
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:408
msgid "_Widefield microscopy:_ A CCD is suitable because of its ability to record many pixels simultaneously. The large number of photons normally detected means that read noise is not usually a big issue, and an EMCCD can make the problem of noise worse instead of better."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:410
msgid "_Spinning Disk Confocal Microscopy:_ A CCD may be used, but an EMCCD (or other CCD variant) is often preferable. This is because SDCM usually gives lower photon counts (certainly lower than in a comparable widefield image), which can mean that read noise would dominate the result unless the photons are somehow amplified."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:412
msgid "_Laser Scanning Confocal Microscopy:_ PMTs are suitable, since the image is built up one pixel at a time."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:424
msgid "Previously we explored how CCDs can use 2×2 binning to combine the electrons corresponding to multiple pixels together into a single pixel, which is then 'less noisy'. A similar effect can be achieved by just acquiring an image without binning and applying a 2×2 filter, in which all the coefficients have values of one. Both techniques result in images that have roughly four times as many photons contributing to each pixel, and thus a better SNR."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:428
msgid "Think of one major advantage and one disadvantage of using filtering _after_ acquisition, rather than binning _during_ acquisition."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:434
msgid "A 2×2 binned image contains 1/4 the number of pixels of the original image. This represents a considerable loss of spatial information, and you would get a different result if you were to start binning at the first or second row or column, since different pixels would be combined in each case. On the other hand, filtering has the advantage of giving you an image that is exactly the same size as the original. This is like getting all four possible binned images for the price of one (i.e. all four different ways to split the image into 2×2 pixel blocks, instead of just one way), so less spatial information is lost. With filtering you also have much more flexibility: you might choose a 3×3 filter instead, or a Gaussian filter, or a range of different filtering options to see which is best. With binning, you need to choose one option during acquisition and stick with it."
msgstr ""

#: ../../chapters/3-fluorescence/4-microscope_types/microscope_types.md:441
msgid "_However_, if _read noise_ is a major problem then filtering might not be such a good choice. This is because read noise is added to every acquired pixel once, and it does not matter if you have a few photons or many -- its standard deviation remains the same. Therefore, if the electrons from four pixels are combined by binning during acquisition, then only one 'unit' of read noise appears in the image corresponding to those pixels. But an unbinned image would have read noise added four times, and even after 2×2 filtering this is still more read noise than in a comparable binned image. Sometimes this extra noise is too high a cost for the flexibility of filtering, and binning is better. (In this regard, remember that read noise is typically worse for CCD cameras, but not such a problem for EMCCDs or PMTs.)"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:36
msgid "[Difference of Gaussians (DoG) filtering](sec_filters_dog) is a very useful technique for enhancing the appearance of small spots and edges in an image. It's quite straightforward, but time consuming to apply manually very often -- and you might need to experiment with different filter sizes to get good results. This makes it an excellent candidate for a macro."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:40
msgid "Recording a macro"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:45
#: ../../chapters/appendices/macros/macro_simulating.md:84
msgid "Example input image"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:51
msgid "Result of DoG filter"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:54
msgid "Rather than diving into writing the code, the fastest way to get started is to have ImageJ do most of the hard work itself. Then you only need to fix up the result. The procedure is as follows:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:58
msgid "Open up an example (2D, non-color) image to use, ideally one including small spot-like or otherwise round objects. I have used {menuselection}`File --> Open samples --> HeLa Cells`, after extracting the red channel only."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:60
msgid "Start the _Macro Recorder_ by choosing {menuselection}`Plugins --> Macros --> Record`. Make sure that {guilabel}`Record: Macro` appears at the top of this window (see the drop-down list). Every subsequent click you make that has a corresponding macro command will result in the command being added to the window."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:62
msgid "Convert your image to 32-bit. This will reduce inaccuracies due to rounding whenever the filtering is applied."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:63
msgid "Duplicate the image."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:64
msgid "Apply {menuselection}`Process --> Filters --> Gaussian Blur...` to one of the images (it doesn't matter if it's the original or the duplicate), using a small sigma (e.g. 1) for noise suppression."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:65
msgid "Apply {menuselection}`Process --> Filters --> Gaussian Blur...` to the other image, using a larger sigma (e.g. 2)."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:66
msgid "Run {menuselection}`Process --> Image Calculator...` and subtract the second filtered image from the first. This produces the 'difference of Gaussians' filtered image, in which small features should appear prominently and the background is removed."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:68
msgid "Be careful to choose the correct image titles and subtraction operation in the *Image Calculator*!"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:69
msgid "Press the {guilabel}`Create` button on the macro recorder. This should cause a text file containing the recorded macro to be opened in Fiji's  {menuselection}`Script Editor` (which you can find under {menuselection}`File --> New --> Script...`)."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:71
msgid "Save the text file. The file name should end with the extension `.ijm` (for 'ImageJ Macro'), and include an underscore character somewhere within it."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:75
msgid "**Now you have a macro!**"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:77
msgid "You *could* try it out by pressing the tempting {guilabel}`Run` button, but this isn't guaranteed to work (yet). Our macro remains quite brittle: it depends upon exact image names and might become easily confused. We will fix this soon."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:81
msgid "As an alternative,"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:82
msgid "Close Fiji completely (to ensure nothing remains from this session)"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:83
msgid "Reopen Fiji"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:84
msgid "Open the original image you used"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:85
msgid "Open the macro (you can just drag it onto the ImageJ toolbar)"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:87
msgid "Now the {guilabel}`Run` button will hopefully give you the same result as when you applied the commands manually. If not, keep reading anyway and the following steps should fix it."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:90
msgid "Cleaning up the code"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:92
msgid "Now reopen your macro in the *Script Editor*. It should look something like mine:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:100
msgid "For easier copy-and-paste, the content is below:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:114
msgid "Your code is probably not identical, and may well be better. One problem with automatically generated macros is that they contain (almost) _everything_ -- often including a lot of errant clicking, or other non-essential steps. For example, I changed the contrast of an image, but this was only to look at it -- and it does not need to be included in the macro."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:118
msgid "After deleting the unnecessary lines, I get:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:130
msgid "Understanding the code"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:132
msgid "You can most likely work out what the macro is doing, if not necessarily the terminology, just by looking at it. Taking the first line, `run` is a **function_ that tells ImageJ to execute a command, while `32-bit` is a piece of text (called a **string**) that tells it which command. Functions always tell ImageJ to do something or give you information, and can be recognized because they are normally followed by parentheses. Strings are recognizable both because they are inside double inverted commas and the script editor shows them in a different color. Notice also that each line needs to end with a semicolon so that the macro interpreter knows the line is over."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:138
msgid "Functions can require different numbers of pieces of information to do their work. At a minimum, `run` needs to know the name of the command and the image to which it should be applied -- which here is taken to be whichever image is currently active, i.e. the one that was selected most recently. But if the command being used by `run` requires extra information of its own, then this is included as an extra string. Therefore"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:147
msgid "informs the {menuselection}`Duplicate` command that the image it creates should be called *C1-hela-cells-1.tif*, and"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:153
msgid "ensures that {menuselection}`Process --> Filters --> Gaussian Blur...` is executed with a sigma value of 1."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:156
msgid "`selectWindow` is another function, added to the macro whenever you click on a particular window to activate it, and which requires the name of the image window to make active. From this you can see that my example file name was *C1-hela-cells.tif*. Without this line, the duplicated image would be filtered twice -- and the original not at all."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:160
msgid "Finally, the {menuselection}`Image Calculator` command is special enough to get its own function in the macro language, `imageCalculator`. The first string it is given tells it both what sort of calculation to do, and that it should `create` a new image for the result -- rather than replacing one of the existing images. The next two strings give it the titles of the images needed for the calculation."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:164
msgid "Removing title dependancies"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:166
msgid "The fact that the original image title appears in the above macro is a problem: if you try to run it on another image, you are likely to find that it does not work because `selectWindow` cannot find what it's looking for. So the next step is to remove this title dependency so that the macro can be applied to any (2D) image."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:169
msgid "There are two ways to go about this. One is to insert a line that tells the macro the title of the image being processed at the start, e.g."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:176
msgid "where `getTitle()` is an example of a function that asks for information. The result is then stored as a **variable**, so that any time we type `titleOrig` later this will be replaced by the string corresponding to the original title [^fn_6]. Then we just find anywhere the title appears and replace the text with our new variable name, i.e. in this case by writing"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:185
msgid "If we do this, the window we want will _probably_ be activated as required. However, there is a subtle potential problem. It's possible that we have two images open at the same time with identical titles -- in which case it's not clear which window should be selected, and so the results could be unpredictable. A safer approach is to get a reference to the **image ID** rather than its title. The ID is a number that should be unique for each image, which is useful for ImageJ internally but which we do not normally care about unless we are programming. Using IDs, the updated macro code then becomes:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:203
msgid "We had to change `selectWindow` to `selectImage` for the IDs to work. I also changed the title of the duplicated image to something more meaninglessly general -- which required square brackets, because it includes spaces that would otherwise mess things up [^fn_7]. Also, because the duplicated image will be active immediately after it was created, I ask ImageJ for its ID at that point. This lets me then pass the two IDs (rather than titles) to the  `imageCalculator` command when necessary."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:208
msgid "Adding comments"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:210
msgid "Whenever macros become more complicated, it can be hard to remember exactly what all the parts do and why. It's then a _very_ good idea to add in some extra notes and explanations. This is done by prefixing a line with `//`, after which we can write whatever we like because the macro interpreter will ignore it. These extra notes are called **comments**, and I will add them from now on."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:215
msgid "Customizing sigma values"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:217
msgid "By changing the size of the Gaussian filters, the macro can be tailored to detecting structures of different sizes. It would be relatively easy to find the `Gaussian Blur` lines and change the sigma values accordingly here, but adjusting settings like this in longer, more complex macros can be awkward. In such cases, it's helpful to extract the settings you might wish to change and include them at the start of the macro."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:221
msgid "To do this here, insert the following lines at the very beginning:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:230
msgid "Then, update the later commands to:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:238
msgid "This creates two new variables, which represent the sigma values to use. Now any time you want to change `sigma1` or `sigma2` you do not need to hunt through the macro for the correct lines: you can just update the lines at the top [^fn_8]."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:240
msgid "Adding interactivity"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:242
msgid "Usually I would stop at this point. Still, you might wish to share your macro with someone lacking your macro modification skills, in which case it would be useful to give this person a dialog box into which they could type the Gaussian sigma values that they wanted. An easy way to do this is to remove the sigma value information from the `run` command lines, giving"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:254
msgid "Since {menuselection}`Process --> Filters --> Gaussian Blur` will not then know what size of filters to use, it will ask. The disadvantage of this is that the user is prompted to enter sigma values at two different times as the macro runs, which is slightly more annoying than necessary."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:257
msgid "The alternative is to create a dialog box that asks for all the required settings in one go. To do this, update the beginning of your macro to include something like the following:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:273
msgid "The first line generates a dialog box with the title you specify. Each of the next two lines state that the required user input should be a number with the specified prompts and default values. The other lines simply show the dialog box and then read out whatever the user typed and puts it into variables. This is documented in ImageJ's [list of built-in macro functions](https://imagej.nih.gov/ij/developer/macro/functions.html)."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:278
msgid "You can download the complete example macro [here](https://gist.github.com/petebankhead/53c0651dd1ad4f455622fc8eeefdc21e)."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:281
msgid "Installing the macro"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:283
msgid "If you'd like the macro to appear as an entry in ImageJ's menus, you have a couple of options."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:285
msgid "One is the tempting {menuselection}`Plugins --> Macros --> Install...`. This works, but whenever I tested it I found that it only retains the macro until ImageJ is restarted."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:288
msgid "More usefully, {menuselection}`Plugins --> Install...` will prompt you to first select the file containing your macro, and then to save it within the *Plugins* directory of ImageJ itself. As long as the macro file you choose has an underscore in its name, it should appear as its own entry towards the bottom of the {menuselection}`Plugins` menu -- and be retained even when ImageJ is relaunched."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:292
msgid "Suggested improvements"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:294
msgid "You should now have a macro that does something vaguely useful, and which will work on most 2D images. It could nevertheless still be enhanced in many ways. For example,"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:299
msgid "You could close any unwanted images (e.g. the original and its duplicate) by selecting their IDs, and then inserting `close();` commands afterwards."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:300
msgid "You could make the macro work on entire image stacks. If you want it to process each plane separately, this involves only inserting the words  `stack` and `duplicate` in several places -- by recording a new macro in the same way, but using a stack as your example image, you can see where to do this. If you want the filtering to be applied in 3D, you can use the {menuselection}`Process --> Filters --> Gaussian Blur 3D...` command instead of {menuselection}`Process --> Filters --> Gaussian Blur...`"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:303
msgid "You could create a log of which images you have processed, possibly including the settings used. The log is output by including a `log(text);` line, where `text` is some string you have created, e.g. `text = Image name:  + getTitle()`."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:305
msgid "More impressively, you could turn the macro into a full spot-detector by thresholding the DoG filtered image, and then running the {menuselection}`Analyze --> Analyze Particles...` command. If you want to measure original spot intensities, you should remember to go to {menuselection}`Analyze --> Set Measurements...` to make sure the measurements are redirected to the original image -- which you should possibly have duplicated at the beginning. Without the duplication, the original image will have been Gaussian filtered by the time your macro reaches the measurement stage."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:309
msgid "In any case, the process of developing a macro is usually the same:"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:311
msgid "Record a macro that does basically the right thing"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:312
msgid "Remove all the superfluous lines (contrast adjustment, errant clicking etc.)"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:313
msgid "Replace the image titles with image ID references"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:314
msgid "Add comments to describe what the macro is doing"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:315
msgid "Track down bugs and make improvements"
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:320
msgid "There is nothing special about `titleOrig` -- this text can be changed to any variable name you like, so long as it's one word and does not contain special characters."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:322
msgid "In ImageJ's macro language, spaces in the string telling a command what to do are used to indicate that a separate piece of information is being given. So titles or file names that require spaces need to be put inside square brackets."
msgstr ""

#: ../../chapters/appendices/macros/macro_dog.md:325
msgid "Note that `+` is used to join multiple strings into one, converting numbers into strings as needed. Therefore in this case the lines `sigma=+2` and `sigma=+sigma2` would each give us the same result: one longer string with the extra part appended at the end, i.e.`sigma=2`."
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:16
msgid "ImageJ: Writing macros"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:21
msgid "Processing & analysis steps in ImageJ can be automated by writing **macros**"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:22
msgid "Straightforward macros can be produced without any programming using the **Macro Recorder**"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:23
msgid "Recorded macros can be modified to make them more robust & suitable for a wider range of images"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:44
msgid "It's one thing to figure out steps that enable you to analyze an image, it's quite another to implement these steps for several -- and perhaps many -- different images. Without automation, the analysis might never happen; all the mouse-moving and clicking would just be too time-consuming, error-prone or boring, and momentarily lapses in concentration could require starting over again."
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:48
msgid "Even a brief effort to understand how to automate analysis can produce vast, long-lasting improvements in personal productivity and sanity by reducing the time spent on mind-numbingly repetitive tasks. In some straightforward cases (e.g. converting file formats, applying projections or filters, or making measurements across entire images), this can already be done in ImageJ using the commands in the {menuselection}`Process --> Batch -->` submenu and no programming whatsoever. But it's also very worthwhile to get some experience in producing macros, scripts or plugins, after which you can add your own new commands to the menus and carry out customized algorithms with a single click of a button or press of a key."
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:53
msgid "What's a macro?"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:55
msgid "Macros are basically sequences of commands, written in some programming language (here ImageJ's own macro language), which can be run automatically to make processing faster and easier."
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:57
msgid "The following sections are far from an extensive introduction to macro-writing, but rather aim to introduce the main ideas quickly using two worked examples. Should you wish to delve deeper into the subject, there's an [introduction to the language on the ImageJ website](https://imagej.net/developer/macro/macros.html) [^fn_1], and a [very helpful tutorial on the ImageJ wiki](https://imagej.net/Introduction_into_Macro_Programming) [^fn_2], while the list of [built-in macro functions](https://imagej.net/developer/macro/functions.html) is an indispensable reference [^fn_3]."
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:60
msgid "Use Fiji's 'Script editor'"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:63
msgid "Although it's possible to use ImageJ rather than Fiji to create macros, Fiji's script editor makes the process *much* easier by coloring text according to what it does. I will assume that you are using this."
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:67
msgid "From macros to scripts"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:68
msgid "Once confident with macros, the next step would be to enter the world of scripts and plugins. These can be somewhat more difficult to learn, but reward the effort with the ability to do more complicated things. Links to help with this are available at https://imagej.net/Scripting."
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:74
msgid "<https://imagej.net/developer/macro/macros.html>"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:76
msgid "<https://imagej.net/Introduction_into_Macro_Programming>"
msgstr ""

#: ../../chapters/appendices/macros/macro_intro.md:78
msgid "<https://imagej.net/developer/macro/functions.html>"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:16
msgid "Simulating image formation"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:36
msgid "The Difference of Gaussians macro developed in {ref}`chap_macro_intro` was useful, but quite simple. This section contains an extended practical, the goal of which is to develop a somewhat more sophisticated macro that takes an 'ideal' image, and then simulates how it would look after being recorded by a fluorescence microscope. It can be used not only to get a better understanding of the image formation process, but also to generate test data for analysis algorithms. By creating simulations with different settings, we can investigate how our results might be affected by changes in image acquisition and quality."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:41
msgid "Image formation summary"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:43
msgid "The following is a summary of the aspects of image formation discussed in this book:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:45
msgid "Images are composed of pixels, each of which has a **single numeric value** (not a color!)."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:46
msgid "The value of a pixel in fluorescence microscopy relates to a number of detected **photons** -- or, more technically, the charge of the electrons produced by the photons striking a detector."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:47
msgid "Images can have many **dimensions**. The number of dimensions is essentially the number of things you need to know to identify each pixel (e.g. time point, channel number, _x_ coordinate, _y_ coordinate, _z_ slice)."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:48
msgid "The two main factors that limit image quality are **blur** and **noise**. Both are inevitable, and neither can be completely overcome."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:49
msgid "Blur is characterized by the **point spread function (PSF)** of the microscope, which is the 3D volume that would be the result of imaging a single light-emitting point. It acts as a **convolution**."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:51
msgid "In the focal plane, the image of a point is an **Airy pattern**. Most of the light is contained within a central region, the **Airy disk**."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:52
msgid "The **spatial resolution** is a measure of the separation that must exist between structures before they can adequately be distinguished as separate, and relates to the size of the PSF (or Airy disk in 2D)."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:53
msgid "The two main types of noise are **photon noise** and **read noise**. The former is caused by the randomness of photon emission, while the latter arises from imprecisions in quantifying numbers of detected photons."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:54
msgid "**Detecting more photons** helps to overcome the problems caused by _both_ types of noise."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:55
msgid "Different types of microscope have different advantages and costs in terms of **spatial information**, **temporal resolution** and **noise**."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:56
msgid "**PMTs** are used to detect photons for single pixels, while **CCDs** and **EMCCDs** are used to detect photons for many pixels in parallel."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:58
msgid "The macro in this chapter will work for 2D images, and simulate the three main components:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:60
msgid "the blur of the PSF"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:61
msgid "photon noise"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:62
msgid "read noise"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:64
msgid "Furthermore, the macro will ultimately be written in such a way that allows us to investigate the effects of changing some additional parameters:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:66
msgid "the size of the PSF (related to the objective lens NA and microscope type)"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:67
msgid "the amount of fluorescence being emitted from the brightest region"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:68
msgid "the amount of background (from stray light and other sources)"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:69
msgid "the exposure time (and therefore number of detected photons)"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:70
msgid "the detector's offset"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:71
msgid "the detector's gain"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:72
msgid "the detector's read noise"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:73
msgid "camera binning"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:74
msgid "bit-depth"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:76
msgid "Recording the main steps"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:78
msgid "It doesn't really matter which image you use for this, but I recommend a single-channel 2D image that starts out without any obvious noise (e.g. the *Happy cell.tif* image). After starting the macro recorder, complete the following steps to create the main structure for the macro:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:90
msgid "Example output image"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:93
msgid "Ensure the starting image is 32-bit."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:94
msgid "Run {menuselection}`Process --> Filters --> Gaussian Blur...` using a sigma value of 2 to simulate the convolution with the PSF."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:95
msgid "Here, we will assume that there are some background photons from other sources, but around the same number at every pixel in the image. So we can simply add a constant to this image using {menuselection}`Add...`. The value should be small, perhaps 10."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:98
msgid "The image now contains the 'average rates of photon emission' that we would normally like to have for one particular exposure time (i.e. it is noise-free). If we change the exposure time, we should change the pixel values similarly so that the rates remain the same. Because adjusting the exposure works like a multiplication, we can use the {menuselection}`Process --> Math --> Multiply...` command. Set it to a 'default' value of 1 for now."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:101
msgid "To convert the photon emission rates into actual photon counts that we could potentially detect, we need to simulate photon noise by replacing each pixel by a random value from a Poisson distribution that that has the same $\\lambda$ as the rate itself. At the time of writing, there's no built-in command in ImageJ or Fiji to simulate Poisson noise but we can install *RandomJ* using the instructions at https://imagescience.org/meijering/software/randomj/. Then add noise by calling {menuselection}`Plugins --> RandomJ --> RandomJ Poisson`, making sure to set the {guilabel}`Insertion:` value to {guilabel}`Modulatory`. The {guilabel}`Mean` value will be ignored, so its setting does not matter."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:103
msgid "Notice that all the pixels should now have integer values: you cannot detect parts of photons."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:104
msgid "The detector gain scales up the number of electrons produced by detected photons. Make room for it by including another multiplication, although for now set the value to 1 (i.e. no extra gain)."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:107
msgid "Simulate the detector offset by adding another constant, e.g. 100."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:108
msgid "Add read noise with {menuselection}`Process --> Noise --> Add Specified Noise...`, setting the standard deviation to 5."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:109
msgid "Clip any negative values, by running {menuselection}`Process --> Math --> Min...` and setting the value to 0."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:110
msgid "Clip any positive values that exceed the bit-depth, by running {menuselection}`Process --> Math --> Max...`. To assume an a 8-bit image, set the value to 255."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:112
msgid "Now is a good time to clean up the code by removing any unnecessary lines, adding suitable comments, and bringing any interesting variables up to the top of the macro so that they can be easily modified later (as in {ref}`chap_macro_dog`). We should also duplicate the image to avoid accidentally modifying the original. The end result should look something like this:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:166
msgid "You would have a perfectly respectable macro if you stopped now, but the following section contains some ways in which it may be improved."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:168
msgid "Making improvements"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:170
msgid "Normalizing the image"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:172
msgid "The results you get from running the above macro will change depending upon the original range of the image that you use: that is, an image that starts off with high-valued pixels will end up having much less noise. To compensate for this somewhat, we can first normalize the image so that all pixels fall into the range 0–1. To do this, we need to determine the current range of pixel values, which can be found out using the macro function:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:180
msgid "After running this, four variables are created giving the `mean`,  `minimum` and `maximum` pixel values in the image, along with the total image `area`. Normalization is now possible using {menuselection}`Subtract` and {menuselection}`Divide` commands, and adjusting their values. In the end this gives us"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:191
msgid "Varying the fluorescence emission rate"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:193
msgid "The new problem we will have after normalization is that there will be a maximum photon emission rate of 1 in the brightest part of the image, which will give us a image dominated completely by noise. We can change this by multiplying the pixels again, and so define what we want the emission rate to be in the brightest part of the image. I suggest creating a variable for this, and setting its value to 10. Then add the following line immediately after normalization:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:202
msgid "Modifying this value allows you to change between simulating samples that are fluorescing more or less brightly. For a less bright sample, you will most likely need to increase the exposure time to get a similar amount of signal -- but beware that increasing the exposure time also involves collecting more unhelpful background photons, so is not quite so good as having a sample where the important parts are intrinsically brighter."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:205
msgid "Simulating binning"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:207
msgid "The main idea of [binning](sec_detectors_binning) is that the electrons from multiple pixels are added together prior to readout, so that the number of electrons being quantified is bigger relative to the read noise. For  2×2 binning this involves splitting the image into distinct 2×2 pixel blocks, and creating another image in which the value of each pixel is the sum of the values within the corresponding block."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:211
msgid "This could be done using the {menuselection}`Image --> Transform --> Bin` command, with a {guilabel}`shrink factor` of 2 and the {guilabel}`Sum` bin method. The macro recorder can again be used to get the main code that is needed. After some modification, this becomes"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:221
msgid "By enclosing the line within a _code block_ (limit by the curly brackets) and beginning the block with `if (doBinning)`, it's easy to control whether binning is applied or not. You simply add an extra variable to your list at the start of the macro"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:228
msgid "to turn binning on, or"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:234
msgid "to turn it off. The lines of code that perform the binning should be inserted _before_ the addition of read noise."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:237
msgid "Varying bit-depths"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:239
msgid "Varying the simulated bit-depths by changing the maximum value allowed in the image takes a little work: you need to know that the maximum value in an 8-bit image is 255, while for a 12-bit image it is 4095 and so on. It is more intuitive to just change the image bit-depth and have the macro do the calculation for you. To do this, you can replace the `maxVal = 255;` variable at the start of the macro with `nBits = 8;` and then update the later clipping code to become"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:248
msgid "Here, `pow(2, nBits)` is a function that gives you the value of 2<sup>nBits</sup>. Now it's easier to explore the difference between 8-bit, 12-bit and 14-bit images (which are the main bit-depths normally associated with microscope detectors, even if the resulting image is stored as 16-bit)."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:251
msgid "Rounding to integer values"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:253
msgid "The macro has already clipped the image to a specified bit-depth, but it still contains 32-bit data and so potentially has non-integer values that could not be stored in the 8 or 16-bit images a microscope typically provides as output. Therefore it remains to round the values to the nearest integer."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:256
msgid "There are a few ways to do this: we can convert the image using {menuselection}`Image --> Type -->` commands, though then we need to be careful about whether there will be any scaling applied. However, we can avoid thinking about this if we just apply the rounding ourselves. To do it we need to visit each pixel, extract its value, round the value to the nearest whole number, and put it back in the image. This requires using **loops**. The code, which should be added at the end of the macro, looks like this:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:277
msgid "This creates two variables, `x` and `y`, which are used to store the horizontal and vertical coordinates of a pixel. Each starts off set to 0 (so we begin with the pixel at 0,0, i.e. in the top left of the image). The code in the middle is run to set the first pixel value, then the variable `x` is incremented to become 1 -- because `x++` means `add 1 to x`. This process is repeated so long as `x` is less than the image width, `x < width`. When `x` eventually becomes equal to the width, it means that all pixel values on the first row of the image have been rounded. Then `y` is incremented and `x` is reset to zero, before the process repeats and the next row is rounded as well. This continues until `y` is equal to the image height -- at which point the processing is complete [^fn_loops]."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:289
msgid "Final code"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:291
msgid "The final code of my version of the macro is given below:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:385
msgid "Uses & limitations"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:387
msgid "Of course, the above macro is based on some assumptions and simplifications. For example, it treats gain as a simple multiplication of the photon counts -- but the gain amplification process also involves some randomness, which introduces extra noise. Because this noise behaves statistically quite like photon noise, the effect can be thought of as decreasing the number of photons that were detected. Also, we have treated the background as a constant that is the same everywhere in an image. In practice, the background usually consists primarily of out-of-focus light from other image planes, and so really should change in different parts of the image, particularly in the widefield case."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:393
msgid "Nevertheless, quite a lot of factors have been taken into consideration. By exploring different combinations of settings, you can get a feeling for how they affect overall image quality. For example, you could try:"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:397
msgid "Increasing the background, while keeping the maximum photon emission the same"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:398
msgid "Removing the detector offset, or setting it to a negative value"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:399
msgid "Comparing the effects of binning for images with low and high photon counts"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:400
msgid "Creating multiple images from the same source data, and then averaging them together to see how the noise is changed"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:402
msgid "When planning to implement some analysis strategy -- particularly if fluorescence intensity measurements are being made -- it may also be useful to test its effectiveness using this macro. To do so, you would need to"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:405
msgid "Somehow create a 'perfect', noise and blur-free example image, either manually or by deconvolving a suitably similar sample image"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:406
msgid "Apply your algorithm to this perfect image to find out what it detects and what conclusions you could draw"
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:407
msgid "Apply the exact same algorithm to a version of the image that has passed through the simulator, and see how different your measurements and conclusions would be."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:409
msgid "Ideally, the results should be the same in both cases: this would suggest your analysis method is robust and can handle images with different levels of quality. It's more likely that the results are different, however. In that case, the comparison gives you some idea of how affected by the imaging process your measurements are -- and therefore how reliably they relate to the 'real' underlying sample."
msgstr ""

#: ../../chapters/appendices/macros/macro_simulating.md:285
msgid "If you're unfamiliar with programming, the syntax of loops may look quite strange. Reading through some online tutorials for the ImageJ macro language or for-loops in Java should help demystify what is happening here"
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:15
msgid "Beyond this book"
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:17
msgid "Starting out in image analysis can feel a bit like learning a language."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:24
msgid "Initially, everything seems incomprehensible. If you can immerse yourself in the language sufficiently, patterns start to emerge and parts begin to make sense. But even so, speaking it fluently can still feel a long way away."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:28
msgid "This book tries to accelerate the process by systematically teaching the basic grammar and core vocabulary of image analysis: the rules, concepts, and tools that (bio)image analysts use every day. It aims to go beyond a superficial overview by describing many of the exceptions, pitfalls and messy realities encountered when working with images: the things I wish I had learned sooner when I started out myself. The things I didn't know that I needed to know, or didn't know even existed."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:32
msgid "The book also covers a couple of major dialects (ImageJ and Python), in case you want to hang out in areas where they are spoken."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:34
msgid "If you've worked through the chapters, I hope that they could help you develop a solid basis to understand the language of image analysis. If you want to go further, my advice would be to start using it to communicate with others whenever you can."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:37
msgid "The **Scientific Community Image Forum** at **https://forum.image.sc** is an *extremely* active and friendly discussion forum, populated by people who speak image analysis with varying levels of fluency. My own career has been shaped by the things I learned on the forum, and the mailing lists that predated it."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:40
msgid "For that reason, I'd suggest participating in in the forum is the best next step. There, you'll find thousands of discussions on many topics related to scientific imaging in general."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:43
msgid "One of the most common uses of image.sc is to ask the community for advice on how to solve a particular image analysis problem. As a result, the forum also contains thousands of searchable discussions that delve into the details of specific problems."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:46
msgid "image.sc also acts as the primary discussion channel for more than 50 open-source software projects, listed as 'Community partners', including ImageJ, Fiji, CellProfiler, scikit-image and QuPath."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:53
msgid "Community partners at image.sc in January 2022. <br /> There may well be more by the time you read this."
msgstr ""

#: ../../chapters/appendices/next_steps/next_steps.md:57
msgid "It's possible to learn a lot just by lurking (as I did for years...), absorbing new ideas and ways of thinking from the people who post. But I hope that, in the end, you might actively participate: posting your own questions, and also your own insights, opinions and answers."
msgstr ""

#: ../../chapters/appendices/python/python.md:15
msgid "Python Primer"
msgstr ""

#: ../../chapters/appendices/python/python.md:22
msgid "This section isn't complete yet."
msgstr ""

#: ../../chapters/appendices/python/python.md:27
msgid "This section aims to provide *just enough* info to demystify the weird symbols and to get started with the Python [Python](https://www.python.org) programming language."
msgstr ""

#: ../../chapters/appendices/python/python.md:29
msgid "To make sense of the code throughout this handbook see, it helps to be familiar with four main things:"
msgstr ""

#: ../../chapters/appendices/python/python.md:31
msgid "**Comments** - which help explain what's happening"
msgstr ""

#: ../../chapters/appendices/python/python.md:32
msgid "**Variables** - which store values"
msgstr ""

#: ../../chapters/appendices/python/python.md:33
msgid "**Functions** - which do stuff with variables"
msgstr ""

#: ../../chapters/appendices/python/python.md:34
msgid "**Modules** - which need to be imported to use the useful stuff (like functions) they contain"
msgstr ""

#: ../../chapters/appendices/python/python.md:36
msgid "This is far from everything you need to know to master programming, but it might just be enough to get started - and getting started if often the hardest part."
msgstr ""

#: ../../chapters/appendices/python/python.md:38
msgid "I think it's fair to say that experienced programmers pick up most of what they know as they go along: aided by a great deal of googling* along the way."
msgstr ""

#: ../../chapters/appendices/python/python.md:40
msgid "*-Or the use of some other preferred search engine."
msgstr ""

#: ../../chapters/appendices/python/python.md:44
msgid "Comments"
msgstr ""

#: ../../chapters/appendices/python/python.md:46
msgid "Comments are explanations added to code that help explain what is going on. They aren't essential for the code to *run*, but often are essential to make sense of it. It's a very good idea to add comments to your own code - either for others to read, or for yourself in the future."
msgstr ""

#: ../../chapters/appendices/python/python.md:50
msgid "In Python, a typical comment starts with a `#`"
msgstr ""

#: ../../chapters/appendices/python/python.md:58
msgid "Variables"
msgstr ""

#: ../../chapters/appendices/python/python.md:60
msgid "Variables provide a place to store stuff: numbers, text, images and so on."
msgstr ""

#: ../../chapters/appendices/python/python.md:62
msgid "You can think of it as a bit like algebra. If you see"
msgstr ""

#: ../../chapters/appendices/python/python.md:65
msgid "\n"
"x + 5\n"
""
msgstr ""

#: ../../chapters/appendices/python/python.md:69
msgid "then *x* is the variable."
msgstr ""

#: ../../chapters/appendices/python/python.md:71
msgid "When programming, you'll likely use variables all the time for different purposes and to represent different things. The type of the variable will determine what you can do with it. Some examples are given below."
msgstr ""

#: ../../chapters/appendices/python/python.md:77
msgid "Numbers"
msgstr ""

#: ../../chapters/appendices/python/python.md:79
msgid "A variable might be used to represent a number. You *assign* the number to the variable using `=`."
msgstr ""

#: ../../chapters/appendices/python/python.md:94
msgid "It's important to note that `=` doesn't really mean 'is equal to' in this case. Rather, when I see"
msgstr ""

#: ../../chapters/appendices/python/python.md:99
msgid "in my mind I read *'x becomes 10'* or alternatively *'set x to 10'*."
msgstr ""

#: ../../chapters/appendices/python/python.md:101
msgid "The order is important: the variable being set is on the left and the value it is being set to is on the right. Switching the order can give an error - or a result you might not expect."
msgstr ""

#: ../../chapters/appendices/python/python.md:120
msgid "If you want to test if a variable is equal to something, you need to use `==` instead. The output of that will be either `True` or `False`."
msgstr ""

#: ../../chapters/appendices/python/python.md:133
msgid "Note that, when using `==`, the order doesn't matter like it does with `=`."
msgstr ""

#: ../../chapters/appendices/python/python.md:140
msgid "You aren't restricted to testing whether a variable itself is equal to a specific value. Rather, you can incorporate extra calculations and compare the results of these calculations to other values or variables."
msgstr ""

#: ../../chapters/appendices/python/python.md:149
msgid "Strings"
msgstr ""

#: ../../chapters/appendices/python/python.md:151
msgid "In computer parlance, a piece of text tends to be called a *string*."
msgstr ""

#: ../../chapters/appendices/python/python.md:153
msgid "You can create a string by enclosing the text in some quotation marks."
msgstr ""

#: ../../chapters/appendices/python/python.md:160
msgid "In Python, both single and double quotation marks can be used."
msgstr ""

#: ../../chapters/appendices/python/python.md:162
msgid "You can then do things like add strings together using the `+` symbol, which has the effect of concatenating them to create a new string."
msgstr ""

#: ../../chapters/appendices/python/python.md:171
msgid "It doesn't *usually* matter whether you use single or double quotes, but it can matter if you want to include the other kind of quotation mark *within* the string."
msgstr ""

#: ../../chapters/appendices/python/python.md:178
msgid "In the example above, the `'` within 'wouldn't' was misinterpreted as the end of the string, and an error is the result."
msgstr ""

#: ../../chapters/appendices/python/python.md:180
msgid "There are two ways to get around that:"
msgstr ""

#: ../../chapters/appendices/python/python.md:181
msgid "Use double-quotes"
msgstr ""

#: ../../chapters/appendices/python/python.md:182
msgid "Use `\\'` to 'escape' the first quotation mark"
msgstr ""

#: ../../chapters/appendices/python/python.md:189
msgid "Another way to generate an error is to try to create a string that spans multiple lines."
msgstr ""

#: ../../chapters/appendices/python/python.md:197
msgid "One way to get around that is to define the string using *3* double quotation marks `\"\"\"`."
msgstr ""

#: ../../chapters/appendices/python/python.md:199
msgid "You can use multiline strings like this as an alternative to comments, to avoid needing to add `#` at the beginning."
msgstr ""

#: ../../chapters/appendices/python/python.md:209
msgid "Lists"
msgstr ""

#: ../../chapters/appendices/python/python.md:213
msgid "Tuples"
msgstr ""

#: ../../chapters/appendices/python/python.md:217
msgid "Numpy arrays"
msgstr ""

#: ../../chapters/appendices/python/python.md:221
msgid "Dictionaries"
msgstr ""

#: ../../chapters/appendices/python/python.md:225
msgid "Functions"
msgstr ""

#: ../../chapters/appendices/python/python.md:229
msgid "Defining functions"
msgstr ""

#: ../../chapters/appendices/python/python.md:233
msgid "Modules"
msgstr ""
