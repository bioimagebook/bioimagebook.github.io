
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Thresholding &#8212; Introduction to Bioimage Analysis</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mycss.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="ImageJ: Thresholding" href="imagej.html" />
    <link rel="prev" title="ImageJ: Point operations" href="../2-point_operations/imagej.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
<script defer data-domain="bioimagebook.github.io" src="https://plausible.io/js/plausible.js"></script>
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../../_static/book-logo-smaller.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Introduction to Bioimage Analysis</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../README.html">
                    Introduction to Bioimage Analysis
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Front matter
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../0-preamble/acknowledgements/acknowledgements.html">
   Acknowledgements
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../0-preamble/license.html">
   License
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../0-preamble/disclaimer.html">
   Disclaimer
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Before we begin
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../0-preamble/preface/preface.html">
   Preface
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../0-preamble/reading/reading.html">
   How to read this book
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introducing images
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../1-concepts/1-images_and_pixels/images_and_pixels.html">
   Images &amp; pixels
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/1-images_and_pixels/imagej.html">
     ImageJ: Images &amp; pixels
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/1-images_and_pixels/python.html">
     Python: Images &amp; pixels
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../1-concepts/2-measurements/measurements.html">
   Measurements &amp; histograms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/2-measurements/imagej.html">
     ImageJ: Measurements &amp; histograms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/2-measurements/python.html">
     Python: Measurements &amp; histograms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../1-concepts/3-bit_depths/bit_depths.html">
   Types &amp; bit-depths
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/3-bit_depths/imagej.html">
     ImageJ: Types &amp; bit-depths
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/3-bit_depths/python.html">
     Python: Types &amp; bit-depths
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../1-concepts/4-colors/colors.html">
   Channels &amp; colors
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/4-colors/imagej.html">
     ImageJ: Channels &amp; colors
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/4-colors/python.html">
     Python: Channels &amp; colors
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../1-concepts/5-pixel_size/pixel_size.html">
   Pixel size &amp; dimensions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/5-pixel_size/imagej.html">
     ImageJ:  Pixel size &amp; dimensions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/5-pixel_size/python.html">
     Python:  Pixel size &amp; dimensions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../1-concepts/6-files/files.html">
   Files &amp; file formats
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/6-files/imagej.html">
     ImageJ: Files &amp; file formats
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../1-concepts/6-files/python.html">
     Python: Files &amp; file formats
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Processing &amp; analysis
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../1-processing_and_analysis/processing_and_analysis.html">
   Image processing &amp; analysis
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../2-point_operations/point_operations.html">
   Point operations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../2-point_operations/imagej.html">
     ImageJ: Point operations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="current reference internal" href="#">
   Thresholding
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="imagej.html">
     ImageJ: Thresholding
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../4-filters/filters.html">
   Filters
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../4-filters/imagej.html">
     ImageJ: Filters
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../5-morph/morph.html">
   Morphological operations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../5-morph/imagej.html">
     ImageJ: Morphological operations
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../6-transforms/transforms.html">
   Image transforms
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../6-transforms/imagej.html">
     ImageJ: Image transforms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../7-multidimensional_processing/multidimensional_processing.html">
   Multidimensional processing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
  <label for="toctree-checkbox-12">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../7-multidimensional_processing/imagej.html">
     ImageJ: Multidimensional processing
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fluorescence microscopy
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../3-fluorescence/1-formation_overview/formation_overview.html">
   From photons to pixels
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3-fluorescence/2-formation_spatial/formation_spatial.html">
   Blur &amp; the PSF
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3-fluorescence/3-formation_noise/formation_noise.html">
   Noise
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../3-fluorescence/4-microscope_types/microscope_types.html">
   Microscopes &amp; detectors
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Appendices
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../appendices/next_steps/next_steps.html">
   Beyond this book
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../appendices/python/python.html">
   Python Primer
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../appendices/macros/macro_intro.html">
   ImageJ: Writing macros
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
  <label for="toctree-checkbox-13">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendices/macros/macro_dog.html">
     Difference of Gaussians
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../appendices/macros/macro_simulating.html">
     Simulating image formation
    </a>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/bioimagebook/bioimagebook.github.io/main?urlpath=tree/chapters/2-processing/3-thresholding/thresholding.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../../_sources/chapters/2-processing/3-thresholding/thresholding.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download notebook file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-code"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        <a href="../../../_sources/chapters/2-processing/3-thresholding/thresholding.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binary-labeled-images">
   Binary &amp; labeled images
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#global-thresholding">
   Global thresholding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#thresholding-using-histograms">
     Thresholding using histograms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-importance-of-the-threshold-choice">
     The importance of the threshold choice
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#automated-thresholds">
   Automated thresholds
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otsu-s-method">
     Otsu’s method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimum-method">
     Minimum method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#triangle-method">
     Triangle method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-method">
     Mean method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-standard-deviation">
     Mean &amp; Standard deviation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#median-median-absolute-deviation">
     Median &amp; Median Absolute Deviation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#thresholding-difficult-data">
   Thresholding difficult data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#thresholding-noisy-data">
     Thresholding noisy data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#local-thresholding">
     Local thresholding
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Thresholding</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#binary-labeled-images">
   Binary &amp; labeled images
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#global-thresholding">
   Global thresholding
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#thresholding-using-histograms">
     Thresholding using histograms
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-importance-of-the-threshold-choice">
     The importance of the threshold choice
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#automated-thresholds">
   Automated thresholds
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#otsu-s-method">
     Otsu’s method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#minimum-method">
     Minimum method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#triangle-method">
     Triangle method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-method">
     Mean method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#mean-standard-deviation">
     Mean &amp; Standard deviation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#median-median-absolute-deviation">
     Median &amp; Median Absolute Deviation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#thresholding-difficult-data">
   Thresholding difficult data
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#thresholding-noisy-data">
     Thresholding noisy data
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#local-thresholding">
     Local thresholding
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="thresholding">
<span id="chap-thresholding"></span><h1>Thresholding<a class="headerlink" href="#thresholding" title="Permalink to this headline">#</a></h1>
<div class="tip admonition">
<p class="admonition-title">Chapter outline</p>
<ul class="simple">
<li><p><strong>Image segmentation</strong> is the process of detecting <strong>objects</strong> in an image</p></li>
<li><p><strong>Global thresholding</strong> identifies pixel values above or below a particular threshold</p></li>
<li><p>The choice of threshold can introduce <strong>bias</strong></p></li>
<li><p><strong>Automated thresholding methods</strong> can often determine a good threshold based upon the <strong>image histogram</strong> and <strong>statistics</strong> – but only if certain assumptions are met</p></li>
<li><p>Thresholding is more powerful when combined with <strong>filtering &amp; subtraction</strong></p></li>
</ul>
</div>
<div class="cell tag_hide-cell tag_thebe-init docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>%load_ext autoreload
%autoreload 2

# Default imports
import sys
sys.path.append(&#39;../../../&#39;)
from helpers import *
from matplotlib import pyplot as plt
from myst_nb import glue
import numpy as np
from scipy import ndimage
</pre></div>
</div>
</div>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">#</a></h2>
<p>Before we can measure anything in an image, we first need to detect it.</p>
<p>Sometimes, ‘detection’ might involve <a class="reference internal" href="../../1-concepts/2-measurements/imagej.html#chap-rois"><span class="std std-ref">manually drawing regions of interest (ROIs)</span></a>.
However, this laborious process does not scale very well.
It can also be rather subjective.</p>
<p>In this chapter, we will begin to explore alternative ways to identify <strong>objects</strong> within images.
An ‘object’ is something we want to detect; depending upon the application, an object might be a nucleus, a cell, a vessel, a person, a bird, a car, a helicopter… more or less anything we might find in an image.</p>
<p>This process of detecting objects is called <strong>image segmentation</strong>.
If we can automate image segmentation, this is not only likely to be much faster than manually annotating regions but should also give more reproducible results.</p>
</section>
<section id="binary-labeled-images">
<span id="sec-binary-labeled"></span><h2>Binary &amp; labeled images<a class="headerlink" href="#binary-labeled-images" title="Permalink to this headline">#</a></h2>
<p>Image objects are commonly represented using <strong>binary images</strong>.</p>
<p>Each pixel in a binary image can have one of two values.
Usually, these values are 0 and 1.
In some software (including ImageJ) a binary image has the values 0 and 255, but this doesn’t really make any difference to how it is used: the key point for our purposes is that one of the values represents the foreground (i.e. pixels that are part of an object), and the other value represents the background.</p>
<p>For the rest of this chapter, we will assume that our binary images use 0 for the background (shown as black) and 1 for the foreground (shown as white).</p>
<p>This is important: if we can generate a binary image in which all our objects of interest are in the foreground, we can then use this binary image to help us make measurements of those objects.</p>
<p>One way to do this involves identifying individual objects in the binary image by labeling <strong>connected components</strong>.
A connected component is really just a connected group of foreground pixels, which together represent a distinct object.
By labeling connected components, we get a <strong>labeled image</strong> in which the pixels belonging to each object have a unique integer value.
All the pixels with the same value belong either to the background (if the value is 0) or to the same object.</p>
<p>If required, we can then trace the boundaries of each labeled object to create <strong>regions of interest (ROIs)</strong>, such as those used to make measurement in ImageJ and other software.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>&quot;&quot;&quot;
Show binary image, ROIs and labelled image.
&quot;&quot;&quot;

from skimage.filters import threshold_otsu, threshold_triangle
from skimage.color import label2rgb
from skimage.segmentation import mark_boundaries

im = 255 - load_image(&#39;blobs.gif&#39;)
bw = im &gt; threshold_otsu(im)
lab, n = ndimage.label(bw)

fig = create_figure(figsize=(8, 4))

show_image(im, title=&quot;(A) Original blobs&quot;, pos=141)
show_image(bw, title=&quot;(B) Binary image&quot;, pos=142)
show_image(label2rgb(lab, bg_label=0), title=&quot;(C) Labeled image&quot;, pos=143)
show_image(mark_boundaries(im, lab, mode=&#39;thick&#39;, color=(1, 0, 0)), title=&quot;(D) Original + ROIs&quot;, pos=144)
glue_fig(&#39;fig_blobs_binary_label&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-blobs-binary-label">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_4_0.png" src="../../../_images/thresholding_4_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 61 </span><span class="caption-text">Examples of a grayscale (blobs.gif), binary and labelled image.
In (C), each label has been assigned a unique color for display.
In (D), ROIs have been generated from (C) and superimposed on top of (A).
It is common to use a LUT for labeled images that assigns a different color to each pixel value.</span><a class="headerlink" href="#fig-blobs-binary-label" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>For that reason, a lot of image analysis workflows involve binary images along the way.
Most of this chapter will explore the most common way of generating a binary image: <strong>thresholding</strong>.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>&quot;&quot;&quot;
Compare 4-connectivity and 8-connectivity
&quot;&quot;&quot;

from skimage.color import label2rgb

bw = load_image(&quot;images/connectivity_binary.png&quot;)

lab4, n = ndimage.label(bw)
lab8, n = ndimage.label(bw, structure=np.ones((3, 3)))

fig = create_figure(figsize=(2, 4))
show_image(label2rgb(lab4, bg_label=0), title=&quot;4-connectivity&quot;, pos=211)
show_image(label2rgb(lab8, bg_label=0), title=&quot;8-connectivity&quot;, pos=212)
# plt.tight_layout()
glue_fig(&#39;fig_thresholding_connectivity&#39;, fig)
</pre></div>
</div>
</div>
</div>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<figure class="align-center" style="width: 60%">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_6_0.png" src="../../../_images/thresholding_6_0.png" />
</div>
</figure>
</aside>
<div class="info admonition" id="sec-thresholds-connectivity">
<p class="admonition-title">Connectivity</p>
<p>Identifying multiple objects in a binary image involves separating distinct groups of pixels that are considered ‘connected’ to one another, and then creating a ROI or label for each group.
Connectivity in this sense can be defined in different ways.
For example, if two pixels have the same value and are immediately beside one another (above, below, to the left or right, or diagonally adjacent) then they are said to be <em>8-connected</em>, because there are 8 different neighboring locations involved.
Pixels are <em>4-connected</em> if they are horizontally or vertically adjacent, but <em>not</em> only diagonally.</p>
<p>The choice of connectivity can make a big difference in the number and sizes of objects found, as the example on the right shows (distinct objects are shown in different colors).</p>
</div>
<div class="sd-tab-set docutils">
<input checked="checked" id="b32cc4ed-992b-4268-bfe9-3243c032f528" name="d435c4c5-9cbe-4dfb-9801-7c8eeb6ca716" type="radio">
</input><label class="sd-tab-label" for="b32cc4ed-992b-4268-bfe9-3243c032f528">
Question</label><div class="sd-tab-content docutils">
<p>What do you suppose <em>6-connectivity</em> and <em>26-connectivity</em> refer to?</p>
</div>
<input id="182af473-a01f-49e6-b903-3e9f14ca50c0" name="d435c4c5-9cbe-4dfb-9801-7c8eeb6ca716" type="radio">
</input><label class="sd-tab-label" for="182af473-a01f-49e6-b903-3e9f14ca50c0">
Answer</label><div class="sd-tab-content docutils">
<p>6-connectivity is similar to 4-connectivity, but in 3D.
If all 3D diagonals are considered, we end up with each pixel having 26 neighbors.</p>
</div>
</div>
</section>
<section id="global-thresholding">
<h2>Global thresholding<a class="headerlink" href="#global-thresholding" title="Permalink to this headline">#</a></h2>
<p>The easiest way to segment an image is by applying a <strong>global threshold</strong>.
This identifies pixels that are above or below a fixed threshold value, giving a binary image as the output.</p>
<p>Global thresholding can be thought of as a <a class="reference internal" href="../2-point_operations/point_operations.html#chap-point-operations"><span class="std std-ref">point operation</span></a> because the output is based solely on the value of each pixel, and not its location or its neighbors.
For a global threshold to work, the pixels inside objects need to have higher or lower values than the other pixels.
We will look at image processing tricks to overcome this limitation later, but for now we will focus on examples where we want to detect objects have values that are clearly distinct from the background – and so global thresholding could potentially work.</p>
<section id="thresholding-using-histograms">
<h3>Thresholding using histograms<a class="headerlink" href="#thresholding-using-histograms" title="Permalink to this headline">#</a></h3>
<p>It’s possible to tell quite a lot about an image just by looking at its histogram.</p>
<p>Take the following example:</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def convert_to_uint8(im: np.ndarray):
    im = im - im.min()
    im = im / im.max()
    return (im * 255).astype(np.uint8)    

def load_nuclei(to_uint8=True, noise_sigma=None, do_square=False):
    if do_square:
        im = load_image(&#39;hela-cells.zip&#39;)[10:330, 210:530, 2].astype(np.float32)
    else:
        im = load_image(&#39;hela-cells.zip&#39;)[80:280, 210:530, 2].astype(np.float32)
    if noise_sigma:
        im = im + np.random.default_rng(100).normal(scale=noise_sigma, size=im.shape)
    if to_uint8:
        return convert_to_uint8(im)
    return im

# Load image &amp; show histogram
im = load_nuclei()

fig = create_figure(figsize=(4, 4))
show_histogram(im, bins=np.arange(0, 256))

glue_fig(&#39;fig_thresholds_nuclei_histogram_only&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-nuclei-histogram-only" style="width: 50%">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_11_0.png" src="../../../_images/thresholding_11_0.png" />
</div>
</figure>
<p>Even without seeing the image, we can make some educated guesses about its contents.</p>
<p>Firstly, there is a large peak to the left and a much shallower peak to the right.
This suggests that there are at least two distinct regions in the image.
Since the background of an image tends to contain many pixes with similar values, I would guess that we might have an image with a dark background.</p>
<p>In any case, a threshold around 20-25 looks like it would be a good choice to separate the regions… whatever they may be.</p>
<p>If we then look at the image, we can see that we have in fact got a fluorescence image depicting two nuclei.
Applying a threshold of 20 does achieve a good separation of the nuclei from the background: a successful segmentation.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Load image &amp; set threshold
im = load_nuclei()
thresh = 20

# Show results
fig = create_figure(figsize=(8, 2.2))
show_image(im, title=&quot;(A) Image&quot;, clip_percentile=0.5, pos=131)
show_histogram(im[im &lt;= thresh], title=&quot;(B) Histogram&quot;, bins=np.arange(0, 256), color=(0.5, 0.6, 0.8), pos=132)
plt.hist(im[im &gt; thresh].flatten(), bins=np.arange(0, 256), color=(0.8, 0.4, 0.6))
plt.annotate(&#39;Threshold&#39;, (thresh, 0), xytext=(80, 3400), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;))
show_image(im &gt; thresh, title=&quot;(C) Thresholded&quot;, pos=133)

plt.tight_layout()

glue_fig(&#39;fig_thresholds_nuclei_histogram&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-nuclei-histogram">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_13_0.png" src="../../../_images/thresholding_13_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 62 </span><span class="caption-text">A simple fluorescence image containing two nuclei. We could determine a potentially useful threshold based only on looking at the histogram.</span><a class="headerlink" href="#fig-thresholds-nuclei-histogram" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Admittedly, that was a particularly easy example.
We should try a slightly harder one.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def load_leaf():
    im = load_image(&#39;leaf.jpg&#39;)[80:, ...]
    im = im.mean(axis=-1).astype(np.uint8)
    return im

# Load image &amp; show histogram
im = load_leaf()
fig = create_figure(figsize=(4, 4))
show_histogram(im, bins=np.arange(0, 256))

glue_fig(&#39;fig_thresholds_leaf_histogram_only&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-leaf-histogram-only" style="width: 40%">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_16_0.png" src="../../../_images/thresholding_16_0.png" />
</div>
</figure>
<p>We still have a large peak, but this time it is towards the right.
So I would guess a light background rather than a dark one.</p>
<p>But the problem is that we seem to have <em>two</em> shallower peaks to the left.
That suggests at least three different classes of pixels in the image.</p>
<p>From visual inspection, we might suppose a threshold of 140 would make sense.
Or perhaps around 220.
It isn’t clear.</p>
<p>This time, we <em>do</em> need to look at the image to decide.
Even then, there is no unambiguously ‘correct’ threshold.
Rather, the one we choose depends upon whether our goal is to identify the entire leaf or rather just the darkest region.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span># Load image &amp; set threshold
im = load_leaf()
thresh1 = 140
thresh2 = 220

# Show results
fig = create_figure(figsize=(9, 7.5))
show_image(im, title=&quot;(A) Image&quot;, clip_percentile=0.5, pos=221)
show_histogram(im[im &lt;= thresh1], title=&quot;(B) Histogram&quot;, bins=np.arange(0, 256), color=(0.5, 0.6, 0.8), pos=222)
plt.hist(im[(im &gt; thresh1) &amp; (im &lt;= thresh2)].flatten(), bins=np.arange(0, 256), color=(0.4, 0.8, 0.6))
plt.hist(im[im &gt; thresh2].flatten(), bins=np.arange(0, 256), color=(0.8, 0.4, 0.6))
plt.annotate(&#39;Thresholds&#39;, (thresh1, 0), xytext=(40, 10000), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;))
plt.annotate(&#39;Thresholds&#39;, (thresh2, 0), xytext=(40, 10000), arrowprops=dict(arrowstyle=&#39;-&gt;&#39;))
show_image(im &lt; thresh1, title=f&quot;(C) Thresholded {thresh1}&quot;, pos=223)
show_image(im &lt; thresh2, title=f&quot;(D) Thresholded {thresh2}&quot;, pos=224)

plt.tight_layout()

glue_fig(&#39;fig_thresholds_leaf_histogram&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-leaf-histogram">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_18_0.png" src="../../../_images/thresholding_18_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 63 </span><span class="caption-text">An image where evaluating the histogram suggests two candidate thresholds.
The ‘correct’ threshold depends upon the desired outcome. Note that here we identify pixels <em>below</em> the threshold value, rather than above, because the background is ligher.</span><a class="headerlink" href="#fig-thresholds-leaf-histogram" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="tip admonition">
<p class="admonition-title">Histograms can help us choose thresholds</p>
<p>Histograms can be really useful when choosing threshold values – but we need to also incorporate knowledge of <em>why</em> we are thresholding.</p>
</div>
</section>
<section id="the-importance-of-the-threshold-choice">
<h3>The importance of the threshold choice<a class="headerlink" href="#the-importance-of-the-threshold-choice" title="Permalink to this headline">#</a></h3>
<p>We’ve seen that histograms can help us identify suitable thresholds, but they don’t absolve us of the need to think.
This is particularly evident when objects are not very distinct.
The exact choice of threshold can then be crucial.</p>
<p><a class="reference internal" href="#fig-thresholds-manual"><span class="std std-numref">Fig. 64</span></a> shows an example where the goal is to detect the bright spots (lysosomes).
No single global threshold can give us perfect results, but at first glance many different thresholds can appear to give <em>somewhat</em> sensible results.
The histogram gives, at best, a vague hint where a good threshold may lurk.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from scipy import ndimage
from myst_nb import glue

# Load image
im = load_image(&#39;hela-cells.zip&#39;)[50:400, 50:450, 0].astype(np.float32)
# im = im - ndimage.median_filter(im, size=25)
im -= im.min()
im = im / im.max()
im = (im * 255).astype(np.uint8)

# Define thresholds
thresholds = (50, 60, 70)

# Show results
fig = create_figure(figsize=(8, 5))
show_image(im, title=&quot;Image&quot;, clip_percentile=0.5, pos=231)
ax2 = plt.subplot2grid((2, 3), (0, 1), colspan=2)
show_histogram(im, title=&quot;Histogram&quot;, bins=256)
pos = 234
labeled_images = []
for t in thresholds:
    bw = im &gt; t
    lab, n = ndimage.label(bw)
    hist = np.histogram(lab, bins=range(n+2))[0]
    mean_area = hist[1:].mean()
    median_area = np.median(hist[1:])
    title = f&quot;Threshold: {t}\nNum spots: {n}\nMean area: {mean_area:.1f}px²\nMedian area: {median_area:.1f}px²&quot;
    show_image(bw, title=title, pos=pos)
    # Store image for later
    labeled_images.append((title, lab))
    pos += 1

plt.tight_layout()
plt.show()
glue_fig(&#39;fig_thresholds_manual&#39;, fig)

# Create a second figure with boundaries
# Create a clipped image for display using mark_boundaries
im2 = im.astype(np.float32) - np.percentile(im, 0.5)
im2 = im2 / np.percentile(im2, 99.5)
im2 = np.clip(im2, 0, 1)

fig2 = create_figure(figsize=(8, 3))
pos = 131
for title, lab in labeled_images:
    show_image(mark_boundaries(im2, lab, mode=&#39;thick&#39;, color=(1, 0, 0)), title=title, pos=pos)
    pos += 1
plt.tight_layout()
plt.show()
glue_fig(&#39;fig_thresholds_manual_overlays&#39;, fig2)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-manual">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_21_1.png" src="../../../_images/thresholding_21_1.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 64 </span><span class="caption-text">Applying different manually-chosen thresholds to the same image can give quite different results.</span><a class="headerlink" href="#fig-thresholds-manual" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>I would like to convey three main messages from <a class="reference internal" href="#fig-thresholds-manual"><span class="std std-numref">Fig. 64</span></a>:</p>
<ul class="simple">
<li><p>The <strong>choice of threshold is crucial</strong>, influencing the numbers <em>and</em> areas of spots</p>
<ul>
<li><p>A <strong>threshold that is too low</strong> tends to <strong>make structures bigger &amp; merge some together</strong></p></li>
<li><p>A <strong>threshold that is too high</strong> tends to <strong>make structures smaller &amp; miss some</strong></p></li>
</ul>
</li>
<li><p>Choosing a threshold manually gives a <strong>huge opportunity to introduce bias</strong></p></li>
<li><p>We should <strong>consider our errors when selecting output metrics</strong>. For example, if we needed to estimate the size of a spot from any of these results then the median is likely to be preferable, because it is less impacted by artificially large spots caused by merging.</p></li>
</ul>
<p>A fourth point I would like to make is that <strong>visualization matters too</strong>.
Looking only at the binary images, it is difficult to really evaluate <em>any</em> of the results.
It helps enormously to overlay the detected regions on top of the original image (<a class="reference internal" href="#fig-thresholds-manual-overlays"><span class="std std-numref">Fig. 65</span></a>).
From this we can see much more clearly that none of the results are terribly good: every threshold we tried misses some spots and merges others.</p>
<figure class="align-center" id="fig-thresholds-manual-overlays">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_21_3.png" src="../../../_images/thresholding_21_3.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 65 </span><span class="caption-text">The binary images of <a class="reference internal" href="#fig-thresholds-manual"><span class="std std-numref">Fig. 64</span></a> viewed as overlays instead.</span><a class="headerlink" href="#fig-thresholds-manual-overlays" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="danger admonition">
<p class="admonition-title">Beware summary plots!</p>
<p>I sometimes sit in lab meetings where people discuss their image analysis results without showing a single image.
I don’t approve of this at all.</p>
<p>It’s easy to generate summary data with image analysis.
In fact, it’s disturbingly easy to generate vastly different – even conflicting – summary data by analyzing the same images in different ways.
But, most worryingly of all, one can often concoct a biologically-plausible-sounding story around almost any results.</p>
<p>It’s crucial to visualize <em>what</em> is being detected and measured in each image, not just a spreadsheet or plot of the results.
This is especially important when applying batch processing to many images at once.
It’s tempting to check a few images and then trust the summary spreadsheet for the next 10,000, but I think there is no substitute for visualizing all (or at least a large proportion) of the images themselves.</p>
<p><strong>For that reason, I would argue that devising an efficient visualization strategy is every bit as important as devising an analysis strategy.</strong></p>
<p>Image overlays are often a good way to do this: for each image you analyze, create an RGB copy that outlines everything that was detected and measured.
Ideally, this would have brightness and contrast settings defined in such a way that you can see at a glance when something has gone wrong.
You might only look at each image for a fraction of a second through <em>Windows Explorer</em> or <em>Mac Finder</em>, but that can be enough to spot issues that would otherwise be missed.</p>
</div>
<p>In <a class="reference internal" href="#sec-thresholding-difficult"><span class="std std-ref">the last section</span></a> we’ll see how applying preprocessing steps to the image can allow us to reduce the proportion of spots that are merged or missed.
But first we’ll consider how to automate the threshold choice.</p>
</section>
</section>
<section id="automated-thresholds">
<h2>Automated thresholds<a class="headerlink" href="#automated-thresholds" title="Permalink to this headline">#</a></h2>
<p>We don’t want to choose thresholds manually if we can avoid it, because it affords so much room for bias.
On the other hand, there’s no always-applicable strategy to determine a threshold automatically; images vary too much.</p>
<p>Nevertheless, there are some widely-used techniques capable of determining reasonable thresholds for many images based upon the histogram.
Each one is based upon some underlying assumptions about the histogram shape or image statistics.
If these assumptions are met, the method often performs well; if not, it may perform well <em>sometimes</em> and disastrously at other times.</p>
<p>In this section, we’ll look at several of the most common automated thresholding methods using three images.
Each image exhibits a different kind of histogram that is commonly found in bioimages:</p>
<ul class="simple">
<li><p><strong>Bimodal:</strong> with two distinct peaks, corresponding to foreground and background</p></li>
<li><p><strong>Unimodal:</strong> mostly background noise, with some interesting signal at one end</p></li>
<li><p><strong>Dominant background:</strong> one large background peak, with a long tail of foreground pixels</p></li>
</ul>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def create_spots(shape=(400, 400), n_spots=10, spot_sigma=4, spot_intensity=5, seed=1024, to_uint8=True):
    im = np.zeros(shape, dtype=np.float32)
    rng = np.random.default_rng(seed)
    rows = rng.integers(0, high=im.shape[0], size=n_spots)
    cols = rng.integers(0, high=im.shape[1], size=n_spots)
    im[rows, cols] = 100
    im = ndimage.gaussian_filter(im, sigma=spot_sigma)
    im = im / im.max() * spot_intensity
    im = im + rng.normal(size=im.shape)
    if to_uint8:
        return convert_to_uint8(im)
    else:
        return im

def load_cell(noise_sigma=None, seed=2048, to_uint8=True):
    im = load_image(&#39;happy_cell.tif&#39;)[:, 5:-5]
    if noise_sigma:
        rng = np.random.default_rng(seed)
        im = im + rng.normal(scale=noise_sigma, size=im.shape)
    if to_uint8:
        return convert_to_uint8(im)
    else:
        return im

def create_threshold_images():
    im_cell = load_cell(noise_sigma=5)
    im_spots = create_spots()
    im_nuclei = load_nuclei(do_square=True)
    return im_cell, im_spots, im_nuclei

im_cell, im_spots, im_nuclei = create_threshold_images()

fig = create_figure(figsize=(8, 5))
show_image(im_cell, title=&#39;Cell (Bimodal histogram)&#39;, pos=231)
show_histogram(im_cell, bins=np.arange(0, 256), pos=234)

show_image(im_spots, title=&#39;Spots (Unimodal histogram)&#39;, pos=232)
show_histogram(im_spots, bins=np.arange(0, 256), pos=235)

show_image(im_nuclei, title=&#39;Nuclei (Dominant background histogram)&#39;, pos=233)
show_histogram(im_nuclei, bins=np.arange(0, 256), pos=236)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_histogram_types&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-histogram-types">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_25_0.png" src="../../../_images/thresholding_25_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 66 </span><span class="caption-text">Images with three different types of histogram.</span><a class="headerlink" href="#fig-thresholds-histogram-types" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<section id="otsu-s-method">
<span id="sec-thresholds-otsu"></span><h3>Otsu’s method<a class="headerlink" href="#otsu-s-method" title="Permalink to this headline">#</a></h3>
<p>By its nature, global thresholding assumes that there are two classes of pixel in the image – those that belong to interesting objects, and those that do not – and pixels in each class have different intensity values <a class="footnote-reference brackets" href="#fn-2" id="id1">1</a>.
In principle, if we could identify the pixels for each of the two classes, we could calculate statistics such as the mean and variance (i.e. standard deviation squared) for them both separately.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>Nobuyuki Otsu (1979). “A threshold selection method from gray-level histograms”. <em>IEEE Trans. Sys. Man. Cyber.</em> 9 (1): 62–66. <a class="reference external" href="https://doi.org/10.1109/TSMC.1979.4310076">https://doi.org/10.1109/TSMC.1979.4310076</a></p>
</aside>
<p><strong>Otsu’s method</strong>, introduced in 1979, has become an extremely popular approach to determining a threshold.
It’s commonly described, somewhat intimidatingly, as <em>‘minimizing the intra-class intensity variance’</em>.
In essence, calculating a threshold using Otsu’s method involves adding the variance of the background pixels to the variance of the foreground pixels, for all possible thresholds.
The threshold that is selected is the one for which the sum of the variances is smallest.</p>
<p>We can think of this as trying to keep the distributions of foreground and background pixels ‘compact’: two peaks that spread as little as possible.</p>
<p>Otsu’s method performs very well on data with a bimodal histogram, with a deep valley in between.
Unfortunately, a lot of microscopy images don’t have clearly bimodal histograms, and so the method may not be such a good choice.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>im_cell, im_spots, im_nuclei = create_threshold_images()

fig = create_figure(figsize=(8, 5))
thresh_cell = threshold_otsu(im_cell)
show_image(im_cell, title=f&quot;Otsu&#39;s method (threshold = {thresh_cell:.1f})&quot;, pos=231)
show_image(im_cell &gt; thresh_cell, pos=234)

thresh_spots = threshold_otsu(im_spots)
show_image(im_spots, title=f&quot;Otsu&#39;s method (threshold = {thresh_spots:.1f})&quot;, pos=232)
show_image(im_spots &gt; thresh_spots, pos=235)

thresh_nuclei = threshold_otsu(im_nuclei)
show_image(im_nuclei, title=f&quot;Otsu&#39;s method (threshold = {thresh_nuclei:.1f})&quot;, pos=233)
show_image(im_nuclei &gt; thresh_nuclei, pos=236)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_method_otsu&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-method-otsu">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_28_0.png" src="../../../_images/thresholding_28_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 67 </span><span class="caption-text">Thresholding using Otsu’s method. This performs best on the cell image with a bimodal histogram. For the spots image, there is no separation between peaks to find; as a result, approximately half the pixels are identified as foreground. The method also performs quite poorly for the nucleus image, despite this previously being identified as an ‘easier’ image for thresholding.</span><a class="headerlink" href="#fig-thresholds-method-otsu" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="minimum-method">
<h3>Minimum method<a class="headerlink" href="#minimum-method" title="Permalink to this headline">#</a></h3>
<p>The <strong>Minimum method</strong> provides an alternative threshold that also assumes a bimodal histogram.</p>
<p>The starting point is the image histogram.
As can be seen in <a class="reference internal" href="#fig-thresholds-histogram-types"><span class="std std-numref">Fig. 66</span></a>, the counts tend to be somewhat ‘noisy’ with lots of tiny spurious peaks.
The Minimum method operates by smoothing the histogram, replacing each count value with the average of itself and the neighboring counts.
By repeating this process, eventually the spurious peaks are removed until (hopefully) precisely two peaks remain.
The threshold is then the location of the deepest point in the valley between those peaks.</p>
<p>The result of this process is illustrated in <a class="reference internal" href="#fig-thresholds-method-minimum"><span class="std std-numref">Fig. 68</span></a>.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def plot_minimum_threshold(im, bins, thresh, pos=None, max_iters=100):
    if pos:
        plt.subplot(pos)

    def find_local_maxima_idx(hist):
        # This code is taken from scikit-image because it is not publicly accessible
        # https://github.com/scikit-image/scikit-image/blob/v0.19.0/skimage/filters/thresholding.py#L821

        # We can&#39;t use scipy.signal.argrelmax
        # as it fails on plateaus
        maximum_idxs = list()
        direction = 1

        for i in range(hist.shape[0] - 1):
            if direction &gt; 0:
                if hist[i + 1] &lt; hist[i]:
                    direction = -1
                    maximum_idxs.append(i)
            else:
                if hist[i + 1] &gt; hist[i]:
                    direction = 1

        return maximum_idxs

    # Create a histogram with bin centers
    hist, bin_edges = np.histogram(im.ravel(), bins=bins)
    hist = hist.astype(np.float64)
    centers = (bin_edges[1:] + bin_edges[:-1])/2.0
    smooth_hist = hist.copy()

    # Smooth histogram until there are &lt;=2 peaks
    for ii in range(max_iters):
        smooth_hist = ndimage.uniform_filter1d(smooth_hist, 3)
        max_inds = find_local_maxima_idx(smooth_hist)
        if len(max_inds) &lt; 3:
            break

    # Check this worked
    if len(max_inds) != 2:
        raise RuntimeError(&#39;Unable to find 2 maxima in smoothed histogram!&#39;)

    plt.hist(centers, bins=len(hist), weights=hist, color=(0.1, 0.1, 0.2, 0.1))
    plt.hist(centers, bins=len(smooth_hist), weights=smooth_hist, color=(0.6, 0.2, 0.2, 0.4))
    plt.plot(centers[max_inds], smooth_hist[max_inds], color=(0.2, 0.2, 0.6, 0.4))
    plt.plot(centers[thresh], smooth_hist[thresh], marker=&#39;.&#39;)



from skimage.filters import threshold_minimum

im_cell, im_spots, im_nuclei = create_threshold_images()

fig = create_figure(figsize=(8, 7.5))
thresh_cell = threshold_minimum(im_cell)
show_image(im_cell, title=f&quot;Minimum method (threshold = {thresh_cell:.1f})&quot;, pos=331)
show_image(im_cell &gt; thresh_cell, pos=334)
plot_minimum_threshold(im_cell, bins=np.arange(256), thresh=thresh_cell, pos=337)

thresh_spots = threshold_minimum(im_spots)
show_image(im_spots, title=f&quot;Minimum method (threshold = {thresh_spots:.1f})&quot;, pos=332)
show_image(im_spots &gt; thresh_spots, pos=335)
plot_minimum_threshold(im_spots, bins=np.arange(256), thresh=thresh_spots, pos=338)

thresh_nuclei = threshold_minimum(im_nuclei)
show_image(im_nuclei, title=f&quot;Minimum method (threshold = {thresh_nuclei:.1f})&quot;, pos=333)
show_image(im_nuclei &gt; thresh_nuclei, pos=336)
plot_minimum_threshold(im_nuclei, bins=np.arange(256), thresh=thresh_nuclei, pos=339)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_method_minimum&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-method-minimum">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_31_0.png" src="../../../_images/thresholding_31_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 68 </span><span class="caption-text">Thresholding using the Minimum method. The smoothed histograms used in the calculation are shown in red, with the original histograms shown (faintly) in gray. A line connecting the two final peaks is also included, and the threshold marked with a dot. <br/>
This works well on the cells image and quite well on the nuclei image. However it fails badly on the spots image, where almost everything is detected as foreground. This is a case where the method converges (due to the image being noisy, so having lots of small peaks in the histogram) even though we might prefer it had not.</span><a class="headerlink" href="#fig-thresholds-method-minimum" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>One ‘feature’ of the Minimum method is that <em>it is not guaranteed to converge</em>.
It is entirely possible that no amount of smoothing will result in a histogram with 2 peaks: perhaps there is only 1 peak, or none at all if all pixels are just a constant value.</p>
<p>This could potentially be an advantage: it may be better to return no threshold than to return a really bad one.
However, in most real images we cannot count on the method not converging: it often <em>does</em> converge, even if it does not necessarily converge to any desirable value.</p>
</section>
<section id="triangle-method">
<span id="sec-thresholds-triangle"></span><h3>Triangle method<a class="headerlink" href="#triangle-method" title="Permalink to this headline">#</a></h3>
<p>The ‘triangle method’ is a popular approach to determining a threshold that works especially well in images where there is one dominant background peak, and the ideal threshold should be at the base of that peak.</p>
<p>The general idea is that a a line is drawn from the peak of the histogram to the last bin that contains any pixels.
Then a perpendicular line is plotted to the histogram itself, and the distance to the histogram maximized.
The direction of the line depends upon whether the peak is toward the left or the right of the histogram; all counts on the other side are ignored.</p>
<p>The width and height of the histogram are normalized to deal with the fact that pixel values and intensity counts are in completely different units, and therefore in completely different scales.</p>
<p>The explanation is confusing, but hopefully <a class="reference internal" href="#fig-thresholds-method-triangle"><span class="std std-numref">Fig. 69</span></a> depicts it more clearly – and provides an intuition for when and why it might be appropriate.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from skimage.filters import threshold_triangle

im_cell, im_spots, im_nuclei = create_threshold_images()

bins = np.arange(0, 256)

def plot_triangle_threshold(im, bins, thresh, pos=None):
    if pos:
        plt.subplot(pos)

    # Create a histogram, identify peak and normalize counts between 0 and 1
    # Note: here we assume the peak is always to the left and we threshold to the right!
    # The proper triangle threshold flips sometimes
    hist, bin_edges = np.histogram(im.ravel(), bins=bins)
    peak_ind = np.argmax(hist)
    peak_height = hist[peak_ind]
    hist = hist / peak_height

    # Identify bin centers
    # Find last bin with non-zero count
    centers = (bin_edges[1:] + bin_edges[:-1])/2.0
    ind_low, ind_high = np.where(hist &gt; 0)[0][[0, -1]]    

    # Shift bin centers according to peak (simplified plotting)
    centers = centers - centers[peak_ind]

    # Compute &#39;width&#39; of the triangle (base length)
    # Normalize centers so width becomes 1
    width = (centers[ind_high] - centers[peak_ind])
    centers = centers / width

    # Plot histogram with new values
    plt.hist(centers, bins=len(hist), weights=hist, color=(0.1, 0.1, 0.2, 0.6))

    # Plot from peak to base
    x1 = centers[peak_ind]
    y1 = hist[peak_ind]
    x2 = centers[-1]
    y2 = hist[-1]
    plt.plot([x1, x2], [y1, y2])

    # Plot from threshold to peak line
    x3 = centers[int(thresh)]
    y3 = hist[int(thresh)]
    n = np.sqrt((y2 - y1)**2 + (x2 - x1)**2)
    x4 = (y2 - y1) / n
    y4 = -(x2 - x1) / n
    # Find intersection
    # Thank you, wikipedia
    # https://en.wikipedia.org/wiki/Line–line_intersection#Given_two_points_on_each_line
    D = (x1 - x2)*(y3 - y4) - (y1 - y2)*(x3 - x4)
    px = ((x1*y2 - y1*x2)*(x3 - x4) - (x1 - x2)*(x3*y4 - y3*x4))/D
    py = ((x1*y2 - y1*x2)*(y3 - y4) - (y1 - y2)*(x3*y4 - y3*x4))/D
    plt.plot([x3, px], [y3, py])

    # Setup display
    plt.xlim([0, 1])
    plt.ylim([0, 1])
    plt.xticks([0, 0.5, 1.0])
    plt.yticks([0, 0.5, 1.0])
    plt.gca().set_aspect(&#39;equal&#39;)


fig = create_figure(figsize=(8, 7))
thresh_cell = threshold_triangle(im_cell)

show_image(im_cell, title=f&quot;Triangle method (threshold = {thresh_cell:.1f})&quot;, pos=331)
show_image(im_cell &gt; thresh_cell, pos=334)
plot_triangle_threshold(im_cell, bins=bins, thresh=thresh_cell, pos=337)

thresh_spots = threshold_triangle(im_spots)
show_image(im_spots, title=f&quot;Triangle method (threshold = {thresh_spots:.1f})&quot;, pos=332)
show_image(im_spots &gt; thresh_spots, pos=335)
plot_triangle_threshold(im_spots, bins=bins, thresh=thresh_spots, pos=338)

thresh_nuclei = threshold_triangle(im_nuclei)
show_image(im_nuclei, title=f&quot;Triangle method (threshold = {thresh_nuclei:.1f})&quot;, pos=333)
show_image(im_nuclei &gt; thresh_nuclei, pos=336)
plot_triangle_threshold(im_nuclei, bins=bins, thresh=thresh_nuclei, pos=339)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_method_triangle&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-method-triangle">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_34_0.png" src="../../../_images/thresholding_34_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 69 </span><span class="caption-text">Thresholding using the Triangle method. Because all example histograms have a dominant peak, this performs quite well in all cases – although tends to detect more foreground pixels in the cell image than other methods (because the threshold is at the base of the peak rather than between the two modes). <br/>
The histograms depict the triangles that give the method its name.
They have been normalized and truncated to include only the relevant part.</span><a class="headerlink" href="#fig-thresholds-method-triangle" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="mean-method">
<h3>Mean method<a class="headerlink" href="#mean-method" title="Permalink to this headline">#</a></h3>
<p>An alternative simple approach is to skip the histogram altogether, and just use the mean of all pixel values.</p>
<p>This can actually give quite good reasons on many real-world images – although this may be more through luck than design.
It’s not a method I typically use myself.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def threshold_mean(im: np.ndarray):
    return im.mean()

im_cell, im_spots, im_nuclei = create_threshold_images()

fig = create_figure(figsize=(8, 5))
thresh_cell = threshold_mean(im_cell)
show_image(im_cell, title=f&quot;Mean method (threshold = {thresh_cell:.1f})&quot;, pos=231)
show_image(im_cell &gt; thresh_cell, pos=234)

thresh_spots = threshold_mean(im_spots)
show_image(im_spots, title=f&quot;Mean method (threshold = {thresh_spots:.1f})&quot;, pos=232)
show_image(im_spots &gt; thresh_spots, pos=235)

thresh_nuclei = threshold_mean(im_nuclei)
show_image(im_nuclei, title=f&quot;Mean method (threshold = {thresh_nuclei:.1f})&quot;, pos=233)
show_image(im_nuclei &gt; thresh_nuclei, pos=236)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_method_mean&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-method-mean">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_37_0.png" src="../../../_images/thresholding_37_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 70 </span><span class="caption-text">Thresholding using the Mean method.</span><a class="headerlink" href="#fig-thresholds-method-mean" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="mean-standard-deviation">
<h3>Mean &amp; Standard deviation<a class="headerlink" href="#mean-standard-deviation" title="Permalink to this headline">#</a></h3>
<p>We can add a bit more to the <em>Mean method</em> by incorporating the standard deviation, scaled by a constant.
The threshold becomes <em>mean + k x standard.deviation</em>, where we can adjust <em>k</em> based upon our attitude towards sensitivity vs. specificity.</p>
<p>The main advantage of this approach is that it should not fail catastropically in cases where we have an image that is mostly just noise (assuming <em>k</em> is large enough), unlike methods that require a bimodal histogram.
However the disadvantage is that it is not robust: the threshold can be pulled higher or lower by outliers, or by foreground values being very different from background values.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def threshold_mean_std(im: np.ndarray, k=4):
    return im.mean() + k * im.std()

im_cell, im_spots, im_nuclei = create_threshold_images()

fig = create_figure(figsize=(8, 5))
k = 3
thresh_cell = threshold_mean_std(im_cell, k=k)
show_image(im_cell, title=f&quot;Mean &amp; std. method (threshold = {thresh_cell:.1f})&quot;, pos=231)
show_image(im_cell &gt; thresh_cell, pos=234)

thresh_spots = threshold_mean_std(im_spots, k=k)
show_image(im_spots, title=f&quot;Mean &amp; std. method (threshold = {thresh_spots:.1f})&quot;, pos=232)
show_image(im_spots &gt; thresh_spots, pos=235)

thresh_nuclei = threshold_mean_std(im_nuclei, k=k)
show_image(im_nuclei, title=f&quot;Mean &amp; std. method (threshold = {thresh_nuclei:.1f})&quot;, pos=233)
show_image(im_nuclei &gt; thresh_nuclei, pos=236)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_method_mean_std&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-method-mean-std">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_40_0.png" src="../../../_images/thresholding_40_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 71 </span><span class="caption-text">Thresholding using the Mean + k x std.dev. method, with k = 3.</span><a class="headerlink" href="#fig-thresholds-method-mean-std" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="median-median-absolute-deviation">
<h3>Median &amp; Median Absolute Deviation<a class="headerlink" href="#median-median-absolute-deviation" title="Permalink to this headline">#</a></h3>
<p>A more robust alternative to using the mean and standard deviation is to use the <strong>median and median absolute deviation (MAD)</strong> to determine a threshold.</p>
<p>If the pixel values of an image were to be sorted, the <strong>median</strong> is the value that would be in the middle.
The <strong>MAD</strong> is calculated as follows:</p>
<ol class="simple">
<li><p>Subtract the median from all pixels</p></li>
<li><p>Compute the absolute value of the result of (1) (i.e. flip the sign of negative values, so that all are positive)</p></li>
<li><p>Compute the median of the result of (2)</p></li>
</ol>
<p>An intriguingly useful property of the MAD is that it can be scaled by 1.482 to resemble a (more robust) standard deviation.
The <a class="reference external" href="https://en.wikipedia.org/wiki/Median_absolute_deviation">Wikipedia article</a> explains this in more detail.</p>
<p>Typically, we would use the <em>median + k x MAD x 1.482</em>, where we can adjust <em>k</em> as if it was used to scale a standard deviation.
This is helpful because standard deviations are easier for (most of) us to tune.</p>
<p>Using the MAD to define a threshold remains fairly uncommon, but I personally like the method a lot when working with very noisy fluorescence images.
The three main requirements for this method to work are:</p>
<ul class="simple">
<li><p>Most of the image should be background, and noisy (a completely constant background will give a MAD of 0, and a bad threshold)</p></li>
<li><p>The noise should (more or less) follow a normal distribution</p></li>
<li><p>The image shouldn’t be too large, because calculating the median exactly is slow</p></li>
</ul>
<p>The last point is not always an issue: we can calculate the median much more quickly if we use a histogram, although we may lose some precision due to the binning required when building the histogram.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>def threshold_mad(im: np.ndarray, k=4):
    med = np.median(im)
    mad = np.median(np.abs(im.astype(np.float32) - med))
    return med + mad * k * 1.4826

im_cell, im_spots, im_nuclei = create_threshold_images()

fig = create_figure(figsize=(8, 5))
k = 3
thresh_cell = threshold_mad(im_cell, k=k)
show_image(im_cell, title=f&quot;Median &amp; MAD method (threshold = {thresh_cell:.1f})&quot;, pos=231)
show_image(im_cell &gt; thresh_cell, pos=234)

thresh_spots = threshold_mad(im_spots, k=k)
show_image(im_spots, title=f&quot;Median &amp; MAD method (threshold = {thresh_spots:.1f})&quot;, pos=232)
show_image(im_spots &gt; thresh_spots, pos=235)

thresh_nuclei = threshold_mad(im_nuclei, k=k)
show_image(im_nuclei, title=f&quot;Median &amp; MAD method (threshold = {thresh_nuclei:.1f})&quot;, pos=233)
show_image(im_nuclei &gt; thresh_nuclei, pos=236)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_method_mad&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-method-mad">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_43_0.png" src="../../../_images/thresholding_43_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 72 </span><span class="caption-text">Thresholding using the MAD method, with <em>k = 3</em>. This is a strong candiate to be my preferred method for the ‘spots’ image, because it is effective when looking for small signals buried in noise.</span><a class="headerlink" href="#fig-thresholds-method-mad" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="danger admonition">
<p class="admonition-title">Clipping confounds automated thresholds</p>
<p>If the data is <a class="reference internal" href="../../1-concepts/3-bit_depths/bit_depths.html#chap-bit-depths"><span class="std std-ref">clipped</span></a>, then the statistics of the pixel values and shape of the image histogram are changed.
This means that the theory underlying why an automated threshold should work might well no longer apply.</p>
<p><em>This is another reason why clipping should always be avoided!</em></p>
</div>
<div class="admonition-are-automated-thresholds-less-biased admonition">
<p class="admonition-title">Are automated thresholds less biased?</p>
<p>I sometimes see the use of automated thresholding methods justified because they are <em>‘less biased than manual thresholds’</em>.</p>
<p>I am unconvinced.</p>
<p>I <em>do</em> agree that automated thresholds are strongly preferable to subjectively picking a threshold by eye – but only if they can be shown to work reliably for a particular dataset.
A bad automated threshold can easily introduce a systematic bias that is much worse than manually setting a threshold for each image.</p>
</div>
</section>
</section>
<section id="thresholding-difficult-data">
<span id="sec-thresholding-difficult"></span><h2>Thresholding difficult data<a class="headerlink" href="#thresholding-difficult-data" title="Permalink to this headline">#</a></h2>
<p>Applying global thresholds is all well and good in easy images for which a threshold clearly exists, but in practice things are rarely so straightforward – and often no threshold, manual or automatic, produces useable results.
This section anticipates the next chapter on filters by showing that, with some extra processing, thresholding can be redeemed even if it initially seems to perform badly.</p>
<section id="thresholding-noisy-data">
<h3>Thresholding noisy data<a class="headerlink" href="#thresholding-noisy-data" title="Permalink to this headline">#</a></h3>
<p>Noise is one problem that affects thresholds, especially in live cell imaging.</p>
<p>The top half of <a class="reference internal" href="#fig-thresholds-noisy"><span class="std std-numref">Fig. 73</span></a> reproduces the nuclei from <a class="reference internal" href="#fig-thresholds-nuclei-histogram"><span class="std std-numref">Fig. 62</span></a> but with extra noise added to simulate less than ideal imaging conditions.
Although the nuclei are still clearly visible in the image (A), the two classes of pixels (which were previously easy to separate) have now been merged together in the histogram (B).
The triangle threshold method, which had performed well before, now gives less attractive results (C), because the noise has caused the ranges of background and nuclei pixels to overlap.</p>
<p><em>However,</em> if we apply a Gaussian filter to smooth the image, a lot of the the random noise is reduced (see <a class="reference internal" href="../4-filters/filters.html#chap-filters"><span class="std std-ref">Filters</span></a>).
This results in a histogram dramatically more similar to that in the original, (almost) noise-free image, and the threshold is again quite successful (F).</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>fig = create_figure(figsize=(8, 4))

from scipy.ndimage import gaussian_filter

# Read image
im = load_nuclei(to_uint8=False).astype(np.float32)

# Add noise (and a constant to avoid clipping)
rng = np.random.default_rng(100)
im_noisy = im + 500 + rng.normal(size=im.shape) * 300

# Apply triangle threshold
bw_noisy_triangle = im_noisy &gt; threshold_triangle(im_noisy)

# Filter to reduce noise, then threshold again
sigma = 2.0
im_filtered = gaussian_filter(im_noisy, sigma)

# Apply triangle threshold
bw_filtered_triangle = im_filtered &gt; threshold_triangle(im_filtered)

show_image(im_noisy, title=&quot;(A) Noisy image&quot;, clip_percentile=2, pos=231)
show_histogram(im_noisy.flatten(), bins=256, title=&quot;(B) Histogram of (A)&quot;, pos=232)
plt.xlim([0, 2500])
show_image(bw_noisy_triangle, title=&quot;(C) Threshold applied to (A)&quot;, pos=233)

show_image(im_filtered, title=&quot;(D) Gaussian filtered image&quot;, clip_percentile=2, pos=234)
show_histogram(im_filtered, bins=256, title=&quot;(E) Histogram of (D)&quot;, pos=235)
plt.xlim([0, 2500])
show_image(bw_filtered_triangle, title=&quot;(F) Threshold applied to (D)&quot;, pos=236)

plt.tight_layout()

glue_fig(&#39;fig_thresholds_noisy&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-noisy">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_47_0.png" src="../../../_images/thresholding_47_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 73 </span><span class="caption-text">Noise can affect thresholding. After the addition of simulated noise to the image in <a class="reference internal" href="#fig-thresholds-nuclei-histogram"><span class="std std-numref">Fig. 62</span></a>, the distinction between nuclei and non-nuclei pixels is much harder to identify in the histogram (B). Any threshold would result in a large number of incorrectly-identified pixels. However, applying a Gaussian filter (here, <span class="math notranslate nohighlight">\(\sigma = 2\)</span>) to reduce noise can dramatically improve the situation (E). Thresholds in (C) and (F) were computed using the triangle method.</span><a class="headerlink" href="#fig-thresholds-noisy" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="local-thresholding">
<h3>Local thresholding<a class="headerlink" href="#local-thresholding" title="Permalink to this headline">#</a></h3>
<p>Another common problem is that the structures that should be detected appear on top of a background that itself varies in brightness.
This was the reason no threshold performed very well in <a class="reference internal" href="#fig-thresholds-manual"><span class="std std-numref">Fig. 64</span></a>.</p>
<p>Ideally, we would like to apply a threshold that varies relative to the local background.</p>
<aside class="margin sidebar">
<p class="sidebar-title"></p>
<p>W. Niblack, An introduction to Digital Image Processing, Prentice-Hall, 1986.</p>
</aside>
<p>There are a variety of <strong>local thresholding</strong> methods available, many of which are variations on the <strong>Niblack method</strong>.
This calculates the mean and standard deviation of pixels <em>in a local window around each pixel</em>, for example a square of 25 x 25 pixels.</p>
<p>A separate threshold is then generated for every pixel,defined as <em>local_mean - k x local_std.dev</em>.
Note the sign: <em>-k</em> is used, because the original definition was focussed on recognizing dark text on a light background, but <em>k</em> itself can be a negative number if needed.</p>
<p>An example is shown in <a class="reference internal" href="#fig-thresholds-local-niblack"><span class="std std-numref">Fig. 74</span></a>.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from skimage.filters import threshold_niblack
from skimage.morphology import disk
from matplotlib import cm

# Load image
im = load_image(&#39;hela-cells.zip&#39;)[50:400, 50:450, 0].astype(np.float32)
# im = im - ndimage.median_filter(im, size=25)
im -= im.min()
im = im / im.max()
im = (im * 255).astype(np.uint8)

# Apply local Niblack threshold
bw_niblack = im &gt; threshold_niblack(im, window_size=25, k=-1.5)

# Show, using an alternative colormap to boost contrast
fig = create_figure(figsize=(8, 2.5))
cmap = cm.get_cmap(&#39;magma&#39;)

show_image(im, title=&quot;(A) Original image&quot;, clip_percentile=0.5, cmap=cmap, pos=131)
show_histogram(im, title=&quot;(B) Histogram of (A)&quot;, bins=np.arange(0, 100), pos=132)
plt.xlim([0, 100])
show_image(bw_niblack, title=&quot;(C) Niblack threshold applied to (A)&quot;, pos=133)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_local_niblack&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-local-niblack">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_49_0.png" src="../../../_images/thresholding_49_0.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 74 </span><span class="caption-text">Local thresholding to detect spots using Niblack’s method.</span><a class="headerlink" href="#fig-thresholds-local-niblack" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>To be honest, I don’t tend to use this approach for bioimages.
I find the window size and <em>k</em> parameters difficult to tune, and it suffers the problem of the mean and standard deviation not being robust.</p>
<p>However, local thresholding becomes more interesting and powerful if we take matters into our own hands by thinking about the problem from a slightly different angle.</p>
<p>Suppose we had a second image that contained values equal to the thresholds we want to apply at each pixel.
If we simply <em>subtract</em> this second image from the first, we can then apply a global threshold of 0 to detect what we want.</p>
<p>Alternatively, we could subtract an image with values that aren’t exactly equal to the local thresholds, but similar enough to effectively flatten out the background so that a global threshold can be applied.
This then provides us access to all global automated thresholding methods, and an intuition of how the histograms ought to look for the methods to be appropriate.
<a class="reference internal" href="#fig-thresholds-local"><span class="std std-numref">Fig. 75</span></a> shows this in action.</p>
<div class="cell tag_hide-cell tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from skimage.filters import threshold_triangle, median
from skimage.morphology import disk
from matplotlib import cm

# Load image
im = load_image(&#39;hela-cells.zip&#39;)[50:400, 50:450, 0].astype(np.float32)
# im = im - ndimage.median_filter(im, size=25)
im -= im.min()
im = im / im.max()
im = (im * 255).astype(np.uint8)

# Apply triangle threshold
bw_triangle = im &gt; threshold_triangle(im)

# Apply large median filter
im_median = median(im, selem=disk(8))

# Subtract median-filtered image and now try triangle threshold again
im_diff = im.astype(np.float32) - im_median
bw_diff = im_diff &gt; threshold_triangle(im_diff)

# Show, using an alternative colormap to boost contrast
fig = create_figure(figsize=(8, 5))
cmap = cm.get_cmap(&#39;magma&#39;)

show_image(im, title=&quot;(A) Original image&quot;, clip_percentile=0.5, cmap=cmap, pos=231)
show_histogram(im, title=&quot;(B) Histogram of (A)&quot;, bins=np.arange(0, 100), pos=232)
plt.xlim([0, 100])
show_image(bw_triangle, title=&quot;(C) Triangle threshold applied to (A)&quot;, pos=233)

# show_image(im_median, title=&quot;(D) Median filtered image&quot;, clip_percentile=0.5, cmap=cmap, pos=234)
show_image(im_diff, title=&quot;(D) &#39;Background&#39; subtracted image&quot;, clip_percentile=2, cmap=cmap, pos=234)
show_histogram(im_diff, title=&quot;(E) Histogram of (A)&quot;, bins=np.arange(-10, 10), pos=235)
show_image(bw_diff, title=&quot;(F) Triangle threshold applied to (D)&quot;, pos=236)

plt.tight_layout()
glue_fig(&#39;fig_thresholds_local&#39;, fig)
</pre></div>
</div>
</div>
</div>
<figure class="align-center" id="fig-thresholds-local">
<div class="cell_output docutils container">
<img alt="../../../_images/thresholding_51_1.png" src="../../../_images/thresholding_51_1.png" />
</div>
<figcaption>
<p><span class="caption-number">Fig. 75 </span><span class="caption-text">Thresholding to detect structures appearing on a varying background. No global threshold may be sufficiently selective <em>(top row)</em>. However, if a ‘background image’ can be created, (here using a large median filter), and then subtracted, a single threshold can give much better results <em>(bottom row)</em>. This is equivalent to applying a varying threshold to the original image.</span><a class="headerlink" href="#fig-thresholds-local" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The difficult part is creating the second image.
Filters are the key, and the subject of the <a class="reference internal" href="../4-filters/filters.html#chap-filters"><span class="std std-ref">next chapter</span></a>.</p>
<hr class="footnotes docutils" />
<dl class="footnote brackets">
<dt class="label" id="fn-2"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Of course there may be multiple classes for different kinds of objects, and perhaps multiple thresholds would make more sense. There is a variation of Otsu’s method for identifying multiple thresholds.</p>
</dd>
</dl>
</section>
</section>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "bioimagebook/bioimagebook.github.io",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/2-processing/3-thresholding"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../2-point_operations/imagej.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">ImageJ: Point operations</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="imagej.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">ImageJ: Thresholding</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Pete Bankhead<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>